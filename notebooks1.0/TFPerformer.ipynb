{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFPerformer.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM-Kr0B3NPhv",
        "outputId": "036a3330-64e3-4ab7-c796-19c62911b6e5"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "print(\"Tensorflow version \" + tf.__version__)\r\n",
        "\r\n",
        "try:\r\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\r\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\r\n",
        "  use_tpu = True\r\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\r\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\r\n",
        "  tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\r\n",
        "except ValueError:\r\n",
        "  use_tpu = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu6zw4lzKskS",
        "outputId": "56c30052-9763-4b1c-9f26-bcf8bce03f90"
      },
      "source": [
        "!git clone https://github.com/xl402/performer.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'performer'...\n",
            "remote: Enumerating objects: 182, done.\u001b[K\n",
            "remote: Counting objects: 100% (182/182), done.\u001b[K\n",
            "remote: Compressing objects: 100% (111/111), done.\u001b[K\n",
            "remote: Total 691 (delta 64), reused 148 (delta 37), pack-reused 509\u001b[K\n",
            "Receiving objects: 100% (691/691), 691.80 KiB | 16.09 MiB/s, done.\n",
            "Resolving deltas: 100% (340/340), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZeNOrnVLdTK"
      },
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "module_path = os.path.abspath(os.path.join('./performer'))\r\n",
        "if module_path not in sys.path:\r\n",
        "    sys.path.append(module_path)\r\n",
        "\r\n",
        "from performer.networks.linear_attention import Performer    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NaeI3KuLRKp"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\r\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\r\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\r\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\r\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\r\n",
        "\r\n",
        "    def call(self, x):\r\n",
        "        maxlen = tf.shape(x)[-1]\r\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\r\n",
        "        positions = self.pos_emb(positions)\r\n",
        "        x = self.token_emb(x)\r\n",
        "        return x + positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afHHqyTeMVdd"
      },
      "source": [
        "# We could split this up into an attention class; intermediate class; output class\r\n",
        "# This effectively replaces one BERT-Layer - We can stack multiple of them & build any model (Roberta, Albert..)\r\n",
        "class TransformerBlock(layers.Layer):\r\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, method, supports, rate=0.1):\r\n",
        "        super(TransformerBlock, self).__init__()\r\n",
        "        self.att = Performer(num_heads=num_heads, key_dim=embed_dim,\r\n",
        "                             attention_method=method, supports=supports)\r\n",
        "        self.ffn = keras.Sequential(\r\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\r\n",
        "        )\r\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\r\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\r\n",
        "        self.dropout1 = layers.Dropout(rate)\r\n",
        "        self.dropout2 = layers.Dropout(rate)\r\n",
        "\r\n",
        "    def call(self, inputs, training):\r\n",
        "        attn_output = self.att([inputs, inputs])\r\n",
        "        attn_output = self.dropout1(attn_output, training=training)\r\n",
        "        out1 = self.layernorm1(inputs + attn_output)\r\n",
        "        ffn_output = self.ffn(out1)\r\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\r\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-zwCwtoMYaG",
        "outputId": "ecebd0bf-2f17-44cb-d7e3-1b871ed26e00"
      },
      "source": [
        "    vocab_size = 20000  # Only consider the top 20k words\r\n",
        "    maxlen = 200  # Only consider the first 200 words of each movie review\r\n",
        "    (x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\r\n",
        "    print(len(x_train), \"Training sequences\")\r\n",
        "    print(len(x_val), \"Validation sequences\")\r\n",
        "    x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\r\n",
        "    x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\r\n",
        "\r\n",
        "    embed_dim = 32  # Embedding size for each token\r\n",
        "    num_heads = 2  # Number of attention heads\r\n",
        "    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\r\n",
        "    method = 'linear'\r\n",
        "    supports = 10\r\n",
        "\r\n",
        "    inputs = layers.Input(shape=(maxlen,))\r\n",
        "    embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\r\n",
        "    x = embedding_layer(inputs)\r\n",
        "    transformer_block = TransformerBlock(embed_dim, num_heads,\r\n",
        "                                         ff_dim, method, supports)\r\n",
        "    x = transformer_block(x)\r\n",
        "    x = layers.GlobalAveragePooling1D()(x)\r\n",
        "    x = layers.Dropout(0.1)(x)\r\n",
        "    x = layers.Dense(20, activation=\"relu\")(x)\r\n",
        "    x = layers.Dropout(0.1)(x)\r\n",
        "    outputs = layers.Dense(2, activation=\"softmax\")(x)\r\n",
        "\r\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\r\n",
        "    model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\r\n",
        "    history = model.fit(\r\n",
        "        x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val)\r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 Training sequences\n",
            "25000 Validation sequences\n",
            "Epoch 1/2\n",
            "782/782 [==============================] - 102s 125ms/step - loss: 0.5136 - accuracy: 0.7086 - val_loss: 0.2920 - val_accuracy: 0.8778\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 97s 124ms/step - loss: 0.1859 - accuracy: 0.9327 - val_loss: 0.3410 - val_accuracy: 0.8684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F7OtuXtGmHO"
      },
      "source": [
        "# Below is Work in Progress & does not all work yet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHwn7VL4QYxZ"
      },
      "source": [
        "## Trying to implement Performer block with the huggingface library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKww7lSoGyCa"
      },
      "source": [
        "Currently we need to swap out their SelfAttention for the PerformerAttention but it sill fails at training due to some incompatibilities. If we wan't to make use of the huggingface library, it's porbably best to wait for this PR, which might be merged in the next 1,2 weeks: https://github.com/huggingface/transformers/pull/9325"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTjxN5i7Qemm",
        "outputId": "0ea958f6-15e7-429d-f6a9-1e24d91c66ef"
      },
      "source": [
        "!mkdir ./packages; cd packages; git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 59213 (delta 27), reused 42 (delta 12), pack-reused 59142\u001b[K\n",
            "Receiving objects: 100% (59213/59213), 44.39 MiB | 22.64 MiB/s, done.\n",
            "Resolving deltas: 100% (41672/41672), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r7qxhyjKsgG"
      },
      "source": [
        "# Setup transformers in subpackage\r\n",
        "import os\r\n",
        "import sys\r\n",
        "module_path = os.path.abspath(os.path.join('./packages/transformers/src/transformers'))\r\n",
        "if module_path not in sys.path:\r\n",
        "    sys.path.append(module_path)\r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYxtHf2DTrRj",
        "outputId": "98e77f0b-3497-44ca-ef7f-d92523a9b054"
      },
      "source": [
        "!cd ./packages/transformers; pip install -e '.[dev]'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/packages/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (3.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (20.8)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.8)\n",
            "Requirement already satisfied: unidic>=1.0.2; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.0.3)\n",
            "Requirement already satisfied: faiss-cpu; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.6.5)\n",
            "Requirement already satisfied: recommonmark; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.7.1)\n",
            "Requirement already satisfied: tensorflow>=2.3; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: flake8>=3.8.3; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (3.8.4)\n",
            "Requirement already satisfied: jaxlib==0.1.55; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.1.55)\n",
            "Requirement already satisfied: jax>=0.2.0; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.2.7)\n",
            "Requirement already satisfied: onnxconverter-common; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.7.0)\n",
            "Requirement already satisfied: ipadic<2.0,>=1.0.0; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.0.0)\n",
            "Requirement already satisfied: sphinx-copybutton; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.3.1)\n",
            "Requirement already satisfied: fugashi>=1.0; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.0.5)\n",
            "Requirement already satisfied: sentencepiece==0.1.91; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.1.91)\n",
            "Requirement already satisfied: sphinx==3.2.1; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (3.2.1)\n",
            "Requirement already satisfied: black>=20.8b1; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (20.8b1)\n",
            "Requirement already satisfied: timeout-decorator; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.5.0)\n",
            "Requirement already satisfied: scikit-learn; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.22.2.post1)\n",
            "Requirement already satisfied: psutil; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (5.4.8)\n",
            "Requirement already satisfied: protobuf; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (3.12.4)\n",
            "Requirement already satisfied: isort>=5.5.4; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (5.7.0)\n",
            "Requirement already satisfied: flax>=0.2.2; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.3.0)\n",
            "Requirement already satisfied: torch>=1.0; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.7.0+cu101)\n",
            "Requirement already satisfied: cookiecutter==1.7.2; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.7.2)\n",
            "Requirement already satisfied: unidic-lite>=1.0.7; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.0.7)\n",
            "Requirement already satisfied: datasets; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.2.1)\n",
            "Requirement already satisfied: sphinx-markdown-tables; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.0.15)\n",
            "Requirement already satisfied: parameterized; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.8.1)\n",
            "Requirement already satisfied: keras2onnx; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.7.0)\n",
            "Requirement already satisfied: pytest-xdist; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (2.2.0)\n",
            "Requirement already satisfied: sphinx-rtd-theme==0.4.3; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.4.3)\n",
            "Requirement already satisfied: pytest; extra == \"dev\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (3.6.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.0.dev0) (3.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.3.0.dev0) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.3.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.3.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.3.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.3.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.3.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.3.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.3.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: plac<2.0.0,>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from unidic>=1.0.2; extra == \"dev\"->transformers==4.3.0.dev0) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.0.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from unidic>=1.0.2; extra == \"dev\"->transformers==4.3.0.dev0) (0.8.0)\n",
            "Requirement already satisfied: commonmark>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from recommonmark; extra == \"dev\"->transformers==4.3.0.dev0) (0.9.1)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from recommonmark; extra == \"dev\"->transformers==4.3.0.dev0) (0.16)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (1.32.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (1.12)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (0.36.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (2.10.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (0.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (1.6.3)\n",
            "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /usr/local/lib/python3.6/dist-packages (from flake8>=3.8.3; extra == \"dev\"->transformers==4.3.0.dev0) (2.6.0)\n",
            "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from flake8>=3.8.3; extra == \"dev\"->transformers==4.3.0.dev0) (0.6.1)\n",
            "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from flake8>=3.8.3; extra == \"dev\"->transformers==4.3.0.dev0) (2.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from jaxlib==0.1.55; extra == \"dev\"->transformers==4.3.0.dev0) (1.4.1)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.6/dist-packages (from onnxconverter-common; extra == \"dev\"->transformers==4.3.0.dev0) (1.8.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (2.11.2)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (1.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (51.1.1)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (2.9.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (1.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (1.1.4)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (0.7.12)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (2.6.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.6/dist-packages (from sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (1.0.3)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.6/dist-packages (from black>=20.8b1; extra == \"dev\"->transformers==4.3.0.dev0) (1.4.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.6/dist-packages (from black>=20.8b1; extra == \"dev\"->transformers==4.3.0.dev0) (0.4.3)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from black>=20.8b1; extra == \"dev\"->transformers==4.3.0.dev0) (0.10.2)\n",
            "Requirement already satisfied: typed-ast>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from black>=20.8b1; extra == \"dev\"->transformers==4.3.0.dev0) (1.4.2)\n",
            "Requirement already satisfied: pathspec<1,>=0.6 in /usr/local/lib/python3.6/dist-packages (from black>=20.8b1; extra == \"dev\"->transformers==4.3.0.dev0) (0.8.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from flax>=0.2.2; extra == \"dev\"->transformers==4.3.0.dev0) (1.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from flax>=0.2.2; extra == \"dev\"->transformers==4.3.0.dev0) (3.2.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0; extra == \"dev\"->transformers==4.3.0.dev0) (0.16.0)\n",
            "Requirement already satisfied: poyo>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from cookiecutter==1.7.2; extra == \"dev\"->transformers==4.3.0.dev0) (0.5.0)\n",
            "Requirement already satisfied: MarkupSafe<2.0.0 in /usr/local/lib/python3.6/dist-packages (from cookiecutter==1.7.2; extra == \"dev\"->transformers==4.3.0.dev0) (1.1.1)\n",
            "Requirement already satisfied: jinja2-time>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from cookiecutter==1.7.2; extra == \"dev\"->transformers==4.3.0.dev0) (0.2.0)\n",
            "Requirement already satisfied: python-slugify>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from cookiecutter==1.7.2; extra == \"dev\"->transformers==4.3.0.dev0) (4.0.1)\n",
            "Requirement already satisfied: binaryornot>=0.4.4 in /usr/local/lib/python3.6/dist-packages (from cookiecutter==1.7.2; extra == \"dev\"->transformers==4.3.0.dev0) (0.4.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets; extra == \"dev\"->transformers==4.3.0.dev0) (0.3.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets; extra == \"dev\"->transformers==4.3.0.dev0) (0.70.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets; extra == \"dev\"->transformers==4.3.0.dev0) (1.1.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets; extra == \"dev\"->transformers==4.3.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets; extra == \"dev\"->transformers==4.3.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: markdown>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from sphinx-markdown-tables; extra == \"dev\"->transformers==4.3.0.dev0) (3.3.3)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.6/dist-packages (from keras2onnx; extra == \"dev\"->transformers==4.3.0.dev0) (0.3.1)\n",
            "Requirement already satisfied: execnet>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytest-xdist; extra == \"dev\"->transformers==4.3.0.dev0) (1.7.1)\n",
            "Requirement already satisfied: pytest-forked in /usr/local/lib/python3.6/dist-packages (from pytest-xdist; extra == \"dev\"->transformers==4.3.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest; extra == \"dev\"->transformers==4.3.0.dev0) (8.6.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest; extra == \"dev\"->transformers==4.3.0.dev0) (1.10.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest; extra == \"dev\"->transformers==4.3.0.dev0) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest; extra == \"dev\"->transformers==4.3.0.dev0) (20.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest; extra == \"dev\"->transformers==4.3.0.dev0) (1.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (1.7.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.6/dist-packages (from babel>=1.3->sphinx==3.2.1; extra == \"dev\"->transformers==4.3.0.dev0) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax>=0.2.2; extra == \"dev\"->transformers==4.3.0.dev0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax>=0.2.2; extra == \"dev\"->transformers==4.3.0.dev0) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->flax>=0.2.2; extra == \"dev\"->transformers==4.3.0.dev0) (2.8.1)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.6/dist-packages (from jinja2-time>=0.2.0->cookiecutter==1.7.2; extra == \"dev\"->transformers==4.3.0.dev0) (0.17.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify>=4.0.0->cookiecutter==1.7.2; extra == \"dev\"->transformers==4.3.0.dev0) (1.3)\n",
            "Requirement already satisfied: apipkg>=1.4 in /usr/local/lib/python3.6/dist-packages (from execnet>=1.1->pytest-xdist; extra == \"dev\"->transformers==4.3.0.dev0) (1.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3; extra == \"dev\"->transformers==4.3.0.dev0) (3.1.0)\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 4.3.0.dev0\n",
            "    Can't uninstall 'transformers'. No files were found to uninstall.\n",
            "  Running setup.py develop for transformers\n",
            "Successfully installed transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En3v9kTfVNQo"
      },
      "source": [
        "from performer.networks.linear_attention import Performer   \r\n",
        "# Replaces the \"BertSelfAttention\"-module for Performer Attention in transformers-repo style\r\n",
        "class TFPerformerWrapper(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\r\n",
        "            raise ValueError(\r\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number \"\r\n",
        "                f\"of attention heads ({config.num_attention_heads})\"\r\n",
        "            )\r\n",
        "\r\n",
        "        self.num_heads = config.num_attention_heads\r\n",
        "        self.key_dim = config.hidden_size\r\n",
        "\r\n",
        "        attention_method = 'linear' # linear or quadratic\r\n",
        "        supports = 2 # only used in 'linear' attention, number of random features\r\n",
        "\r\n",
        "        self.att = Performer(num_heads=self.num_heads, key_dim=self.key_dim,\r\n",
        "                                attention_method=method, supports=supports)\r\n",
        "    \r\n",
        "    def call(self, hidden_states, attention_mask=None, head_mask=None, output_attentions=False, training=False):\r\n",
        "\r\n",
        "\r\n",
        "        attn_output = self.att([hidden_states, hidden_states])\r\n",
        "\r\n",
        "        # We need to reshape (3, 5, 768) to (3, 5, 12, 64), as transformers library splits up the 768 into the 12 heads & 64 headsize\r\n",
        "        shape = attn_output.get_shape().as_list() \r\n",
        "        new_shape = [shape[0], shape[1], self.num_heads, int(self.key_dim / self.num_heads)]\r\n",
        "        attn_output = tf.reshape(attn_output, new_shape) \r\n",
        "\r\n",
        "        # Attention Mask does not work yet! In the test:  Mask: (3, 1, 1, 5); attn_output: (3, 5, 12, 64)\r\n",
        "        #if attention_mask is not None:\r\n",
        "            # Apply the attention mask is (precomputed for all layers in TFBertModel call() function)\r\n",
        "        #    attn_output = attn_output + attention_mask\r\n",
        "\r\n",
        "        # No probabilities, as we apply the FAVOR+ algorithm\r\n",
        "        attention_probs = None\r\n",
        "\r\n",
        "        # Mask heads if we want to # WIP (Don't need them anyways probably)\r\n",
        "        #if head_mask is not None:\r\n",
        "        #    attn_output = attn_output * head_mask\r\n",
        "\r\n",
        "\r\n",
        "        outputs = (attn_output, attention_probs) if output_attentions else (attn_output,)\r\n",
        " \r\n",
        "\r\n",
        "        #print(\"OUT:\", outputs[0].shape)\r\n",
        "\r\n",
        "        return outputs     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY2_4JaeUmH1"
      },
      "source": [
        "from transformers.models.bert.modeling_tf_bert import (\r\n",
        "    TFBertSelfOutput, \r\n",
        "    TFBertIntermediate, \r\n",
        "    TFBertOutput, \r\n",
        "    TFBertEmbeddings,\r\n",
        "    TFBertPooler,\r\n",
        "    BertConfig,\r\n",
        "    TFBertPreTrainedModel,\r\n",
        "    TFSequenceClassificationLoss,\r\n",
        "    get_initializer,\r\n",
        "    input_processing,\r\n",
        "    shape_list,\r\n",
        "    TFSequenceClassifierOutput,\r\n",
        "    TFBaseModelOutput,\r\n",
        "    TFBaseModelOutputWithPooling\r\n",
        ")\r\n",
        "\r\n",
        "#from transformers.models.bert.modeling_tf_bert import TFBertSelfAttention\r\n",
        "\r\n",
        "\r\n",
        "# Same as in transformers, but swapped attention\r\n",
        "\r\n",
        "class TFBertAttention(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.self_attention = TFPerformerWrapper(config, name=\"self\")\r\n",
        "        self.dense_output = TFBertSelfOutput(config, name=\"output\")\r\n",
        "\r\n",
        "    def prune_heads(self, heads):\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "    def call(self, input_tensor, attention_mask, head_mask, output_attentions, training=False):\r\n",
        "        self_outputs = self.self_attention(\r\n",
        "            input_tensor, attention_mask, head_mask, output_attentions, training=training\r\n",
        "        )\r\n",
        "        attention_output = self.dense_output(self_outputs[0], input_tensor, training=training)\r\n",
        "        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\r\n",
        "\r\n",
        "        return outputs\r\n",
        "\r\n",
        "class TFBertLayer(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.attention = TFBertAttention(config, name=\"attention\")\r\n",
        "        self.intermediate = TFBertIntermediate(config, name=\"intermediate\")\r\n",
        "        self.bert_output = TFBertOutput(config, name=\"output\")\r\n",
        "\r\n",
        "    def call(self, hidden_states, attention_mask, head_mask, output_attentions, training=False):\r\n",
        "        attention_outputs = self.attention(\r\n",
        "            hidden_states, attention_mask, head_mask, output_attentions, training=training\r\n",
        "        )\r\n",
        "        attention_output = attention_outputs[0]\r\n",
        "        intermediate_output = self.intermediate(attention_output)\r\n",
        "        layer_output = self.bert_output(intermediate_output, attention_output, training=training)\r\n",
        "        outputs = (layer_output,) + attention_outputs[1:]  # add attentions if we output them\r\n",
        "\r\n",
        "        return outputs\r\n",
        "\r\n",
        "class TFBertEncoder(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.layer = [TFBertLayer(config, name=\"layer_._{}\".format(i)) for i in range(config.num_hidden_layers)]\r\n",
        "\r\n",
        "    def call(\r\n",
        "        self,\r\n",
        "        hidden_states,\r\n",
        "        attention_mask,\r\n",
        "        head_mask,\r\n",
        "        output_attentions,\r\n",
        "        output_hidden_states,\r\n",
        "        return_dict,\r\n",
        "        training=False,\r\n",
        "    ):\r\n",
        "        all_hidden_states = () if output_hidden_states else None\r\n",
        "        all_attentions = () if output_attentions else None\r\n",
        "\r\n",
        "        for i, layer_module in enumerate(self.layer):\r\n",
        "            if output_hidden_states:\r\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\r\n",
        "\r\n",
        "            layer_outputs = layer_module(\r\n",
        "                hidden_states, attention_mask, head_mask[i], output_attentions, training=training\r\n",
        "            )\r\n",
        "            hidden_states = layer_outputs[0]\r\n",
        "\r\n",
        "            if output_attentions:\r\n",
        "                all_attentions = all_attentions + (layer_outputs[1],)\r\n",
        "\r\n",
        "        # Add last layer\r\n",
        "        if output_hidden_states:\r\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\r\n",
        "\r\n",
        "        if not return_dict:\r\n",
        "            return tuple(v for v in [hidden_states, all_hidden_states, all_attentions] if v is not None)\r\n",
        "\r\n",
        "        return TFBaseModelOutput(\r\n",
        "            last_hidden_state=hidden_states, hidden_states=all_hidden_states, attentions=all_attentions\r\n",
        "        )\r\n",
        "\r\n",
        "\r\n",
        "class TFBertMainLayer(tf.keras.layers.Layer):\r\n",
        "    config_class = BertConfig\r\n",
        "\r\n",
        "    def __init__(self, config, add_pooling_layer=True, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.config = config\r\n",
        "        self.num_hidden_layers = config.num_hidden_layers\r\n",
        "        self.initializer_range = config.initializer_range\r\n",
        "        self.output_attentions = config.output_attentions\r\n",
        "        self.output_hidden_states = config.output_hidden_states\r\n",
        "        self.return_dict = config.use_return_dict\r\n",
        "        self.embeddings = TFBertEmbeddings(config, name=\"embeddings\")\r\n",
        "        self.encoder = TFBertEncoder(config, name=\"encoder\")\r\n",
        "        self.pooler = TFBertPooler(config, name=\"pooler\") if add_pooling_layer else None\r\n",
        "\r\n",
        "    def get_input_embeddings(self):\r\n",
        "        return self.embeddings\r\n",
        "\r\n",
        "    def set_input_embeddings(self, value):\r\n",
        "        self.embeddings.word_embeddings = value\r\n",
        "        self.embeddings.vocab_size = shape_list(value)[0]\r\n",
        "\r\n",
        "    def _prune_heads(self, heads_to_prune):\r\n",
        "        \"\"\"\r\n",
        "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\r\n",
        "        class PreTrainedModel\r\n",
        "        \"\"\"\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "    def call(\r\n",
        "        self,\r\n",
        "        input_ids=None,\r\n",
        "        attention_mask=None,\r\n",
        "        token_type_ids=None,\r\n",
        "        position_ids=None,\r\n",
        "        head_mask=None,\r\n",
        "        inputs_embeds=None,\r\n",
        "        output_attentions=None,\r\n",
        "        output_hidden_states=None,\r\n",
        "        return_dict=None,\r\n",
        "        training=False,\r\n",
        "        **kwargs,\r\n",
        "    ):\r\n",
        "        inputs = input_processing(\r\n",
        "            func=self.call,\r\n",
        "            config=self.config,\r\n",
        "            input_ids=input_ids,\r\n",
        "            attention_mask=attention_mask,\r\n",
        "            token_type_ids=token_type_ids,\r\n",
        "            position_ids=position_ids,\r\n",
        "            head_mask=head_mask,\r\n",
        "            inputs_embeds=inputs_embeds,\r\n",
        "            output_attentions=output_attentions,\r\n",
        "            output_hidden_states=output_hidden_states,\r\n",
        "            return_dict=return_dict,\r\n",
        "            training=training,\r\n",
        "            kwargs_call=kwargs,\r\n",
        "        )\r\n",
        "\r\n",
        "        if inputs[\"input_ids\"] is not None and inputs[\"inputs_embeds\"] is not None:\r\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\r\n",
        "        elif inputs[\"input_ids\"] is not None:\r\n",
        "            input_shape = shape_list(inputs[\"input_ids\"])\r\n",
        "        elif inputs[\"inputs_embeds\"] is not None:\r\n",
        "            input_shape = shape_list(inputs[\"inputs_embeds\"])[:-1]\r\n",
        "        else:\r\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\r\n",
        "\r\n",
        "        if inputs[\"attention_mask\"] is None:\r\n",
        "            inputs[\"attention_mask\"] = tf.fill(input_shape, 1)\r\n",
        "\r\n",
        "        if inputs[\"token_type_ids\"] is None:\r\n",
        "            inputs[\"token_type_ids\"] = tf.fill(input_shape, 0)\r\n",
        "\r\n",
        "        embedding_output = self.embeddings(\r\n",
        "            inputs[\"input_ids\"],\r\n",
        "            inputs[\"position_ids\"],\r\n",
        "            inputs[\"token_type_ids\"],\r\n",
        "            inputs[\"inputs_embeds\"],\r\n",
        "            training=inputs[\"training\"],\r\n",
        "        )\r\n",
        "\r\n",
        "        # We create a 3D attention mask from a 2D tensor mask.\r\n",
        "        # Sizes are [batch_size, 1, 1, to_seq_length]\r\n",
        "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\r\n",
        "        # this attention mask is more simple than the triangular masking of causal attention\r\n",
        "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\r\n",
        "        extended_attention_mask = inputs[\"attention_mask\"][:, tf.newaxis, tf.newaxis, :]\r\n",
        "\r\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\r\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\r\n",
        "        # positions we want to attend and -10000.0 for masked positions.\r\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\r\n",
        "        # effectively the same as removing these entirely.\r\n",
        "        extended_attention_mask = tf.cast(extended_attention_mask, embedding_output.dtype)\r\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\r\n",
        "\r\n",
        "        # Prepare head mask if needed\r\n",
        "        # 1.0 in head_mask indicate we keep the head\r\n",
        "        # attention_probs has shape bsz x n_heads x N x N\r\n",
        "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\r\n",
        "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\r\n",
        "        if inputs[\"head_mask\"] is not None:\r\n",
        "            raise NotImplementedError\r\n",
        "        else:\r\n",
        "            inputs[\"head_mask\"] = [None] * self.num_hidden_layers\r\n",
        "\r\n",
        "        encoder_outputs = self.encoder(\r\n",
        "            embedding_output,\r\n",
        "            extended_attention_mask,\r\n",
        "            inputs[\"head_mask\"],\r\n",
        "            inputs[\"output_attentions\"],\r\n",
        "            inputs[\"output_hidden_states\"],\r\n",
        "            inputs[\"return_dict\"],\r\n",
        "            training=inputs[\"training\"],\r\n",
        "        )\r\n",
        "\r\n",
        "        sequence_output = encoder_outputs[0]\r\n",
        "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\r\n",
        "\r\n",
        "        if not inputs[\"return_dict\"]:\r\n",
        "            return (\r\n",
        "                sequence_output,\r\n",
        "                pooled_output,\r\n",
        "            ) + encoder_outputs[1:]\r\n",
        "\r\n",
        "        return TFBaseModelOutputWithPooling(\r\n",
        "            last_hidden_state=sequence_output,\r\n",
        "            pooler_output=pooled_output,\r\n",
        "            hidden_states=encoder_outputs.hidden_states,\r\n",
        "            attentions=encoder_outputs.attentions,\r\n",
        "        )\r\n",
        "\r\n",
        "\r\n",
        "class TFBertForSequenceClassification(TFBertPreTrainedModel, TFSequenceClassificationLoss):\r\n",
        "    # names with a '.' represents the authorized unexpected/missing layers when a TF model is loaded from a PT model\r\n",
        "    _keys_to_ignore_on_load_unexpected = [r\"mlm___cls\", r\"nsp___cls\", r\"cls.predictions\", r\"cls.seq_relationship\"]\r\n",
        "    _keys_to_ignore_on_load_missing = [r\"dropout\"]\r\n",
        "\r\n",
        "    def __init__(self, config, *inputs, **kwargs):\r\n",
        "        super().__init__(config, *inputs, **kwargs)\r\n",
        "\r\n",
        "        self.num_labels = config.num_labels\r\n",
        "        self.bert = TFBertMainLayer(config, name=\"bert\")\r\n",
        "        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\r\n",
        "        self.classifier = tf.keras.layers.Dense(\r\n",
        "            config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"classifier\"\r\n",
        "        )\r\n",
        "\r\n",
        "    def call(\r\n",
        "        self,\r\n",
        "        input_ids=None,\r\n",
        "        attention_mask=None,\r\n",
        "        token_type_ids=None,\r\n",
        "        position_ids=None,\r\n",
        "        head_mask=None,\r\n",
        "        inputs_embeds=None,\r\n",
        "        output_attentions=None,\r\n",
        "        output_hidden_states=None,\r\n",
        "        return_dict=None,\r\n",
        "        labels=None,\r\n",
        "        training=False,\r\n",
        "        **kwargs,\r\n",
        "    ):\r\n",
        "        r\"\"\"\r\n",
        "        labels (:obj:`tf.Tensor` of shape :obj:`(batch_size,)`, `optional`):\r\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\r\n",
        "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\r\n",
        "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\r\n",
        "        \"\"\"\r\n",
        "        inputs = input_processing(\r\n",
        "            func=self.call,\r\n",
        "            config=self.config,\r\n",
        "            input_ids=input_ids,\r\n",
        "            attention_mask=attention_mask,\r\n",
        "            token_type_ids=token_type_ids,\r\n",
        "            position_ids=position_ids,\r\n",
        "            head_mask=head_mask,\r\n",
        "            inputs_embeds=inputs_embeds,\r\n",
        "            output_attentions=output_attentions,\r\n",
        "            output_hidden_states=output_hidden_states,\r\n",
        "            return_dict=return_dict,\r\n",
        "            labels=labels,\r\n",
        "            training=training,\r\n",
        "            kwargs_call=kwargs,\r\n",
        "        )\r\n",
        "        outputs = self.bert(\r\n",
        "            inputs[\"input_ids\"],\r\n",
        "            attention_mask=inputs[\"attention_mask\"],\r\n",
        "            token_type_ids=inputs[\"token_type_ids\"],\r\n",
        "            position_ids=inputs[\"position_ids\"],\r\n",
        "            head_mask=inputs[\"head_mask\"],\r\n",
        "            inputs_embeds=inputs[\"inputs_embeds\"],\r\n",
        "            output_attentions=inputs[\"output_attentions\"],\r\n",
        "            output_hidden_states=inputs[\"output_hidden_states\"],\r\n",
        "            return_dict=inputs[\"return_dict\"],\r\n",
        "            training=inputs[\"training\"],\r\n",
        "        )\r\n",
        "        pooled_output = outputs[1]\r\n",
        "        pooled_output = self.dropout(pooled_output, training=inputs[\"training\"])\r\n",
        "        logits = self.classifier(pooled_output)\r\n",
        "        loss = None if inputs[\"labels\"] is None else self.compute_loss(inputs[\"labels\"], logits)\r\n",
        "\r\n",
        "        if not inputs[\"return_dict\"]:\r\n",
        "            output = (logits,) + outputs[2:]\r\n",
        "            return ((loss,) + output) if loss is not None else output\r\n",
        "\r\n",
        "        return TFSequenceClassifierOutput(\r\n",
        "            loss=loss,\r\n",
        "            logits=logits,\r\n",
        "            hidden_states=outputs.hidden_states,\r\n",
        "            attentions=outputs.attentions,\r\n",
        "        )\r\n",
        "\r\n",
        "    def serving_output(self, output):\r\n",
        "        hs = tf.convert_to_tensor(output.hidden_states) if self.config.output_hidden_states else None\r\n",
        "        attns = tf.convert_to_tensor(output.attentions) if self.config.output_attentions else None\r\n",
        "\r\n",
        "        return TFSequenceClassifierOutput(logits=output.logits, hidden_states=hs, attentions=attns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShICYsZVRjW6",
        "outputId": "1ea7c338-83c6-443b-e4c7-2154a27d74ad"
      },
      "source": [
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Performer._get_random_features at 0x7f79a904f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Performer._get_random_features at 0x7f79a8feeea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 7 calls to <function Performer._get_random_features at 0x7f79a8f67620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 8 calls to <function Performer._get_random_features at 0x7f79a8f83d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 9 calls to <function Performer._get_random_features at 0x7f79a8f3a488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 10 calls to <function Performer._get_random_features at 0x7f79a8f54b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Performer._get_random_features at 0x7f79a8e8c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Performer._get_random_features at 0x7f79a8ea58c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['bert/encoder/layer_._11/attention/self/key/kernel:0', 'bert/encoder/layer_._10/attention/self/key/kernel:0', 'bert/encoder/layer_._3/attention/self/value/bias:0', 'bert/encoder/layer_._8/attention/self/value/kernel:0', 'bert/encoder/layer_._6/attention/self/key/kernel:0', 'bert/encoder/layer_._2/attention/self/key/kernel:0', 'bert/encoder/layer_._2/attention/self/query/kernel:0', 'bert/encoder/layer_._2/attention/self/key/bias:0', 'bert/encoder/layer_._7/attention/self/value/kernel:0', 'bert/encoder/layer_._3/attention/self/key/kernel:0', 'bert/encoder/layer_._4/attention/self/value/kernel:0', 'bert/encoder/layer_._7/attention/self/key/kernel:0', 'bert/encoder/layer_._5/attention/self/value/kernel:0', 'bert/encoder/layer_._6/attention/self/key/bias:0', 'bert/encoder/layer_._6/attention/self/value/bias:0', 'bert/encoder/layer_._0/attention/self/value/kernel:0', 'bert/encoder/layer_._2/attention/self/value/bias:0', 'bert/encoder/layer_._1/attention/self/key/bias:0', 'bert/encoder/layer_._1/attention/self/query/kernel:0', 'bert/encoder/layer_._1/attention/self/value/bias:0', 'bert/encoder/layer_._9/attention/self/query/kernel:0', 'bert/encoder/layer_._8/attention/self/query/kernel:0', 'bert/encoder/layer_._0/attention/self/key/kernel:0', 'bert/encoder/layer_._5/attention/self/key/kernel:0', 'bert/encoder/layer_._4/attention/self/key/bias:0', 'bert/encoder/layer_._11/attention/self/query/kernel:0', 'bert/encoder/layer_._1/attention/self/value/kernel:0', 'bert/encoder/layer_._4/attention/self/value/bias:0', 'bert/encoder/layer_._11/attention/self/value/kernel:0', 'bert/encoder/layer_._7/attention/self/value/bias:0', 'bert/encoder/layer_._10/attention/self/query/kernel:0', 'bert/encoder/layer_._0/attention/self/key/bias:0', 'bert/encoder/layer_._6/attention/self/query/bias:0', 'bert/encoder/layer_._1/attention/self/query/bias:0', 'bert/encoder/layer_._10/attention/self/query/bias:0', 'bert/encoder/layer_._1/attention/self/key/kernel:0', 'bert/encoder/layer_._8/attention/self/key/kernel:0', 'bert/encoder/layer_._6/attention/self/value/kernel:0', 'bert/encoder/layer_._3/attention/self/query/bias:0', 'bert/encoder/layer_._3/attention/self/value/kernel:0', 'bert/encoder/layer_._5/attention/self/key/bias:0', 'bert/encoder/layer_._8/attention/self/value/bias:0', 'bert/encoder/layer_._0/attention/self/value/bias:0', 'bert/encoder/layer_._10/attention/self/key/bias:0', 'bert/encoder/layer_._4/attention/self/query/kernel:0', 'bert/encoder/layer_._5/attention/self/query/kernel:0', 'bert/encoder/layer_._4/attention/self/key/kernel:0', 'bert/encoder/layer_._2/attention/self/query/bias:0', 'bert/encoder/layer_._3/attention/self/key/bias:0', 'bert/encoder/layer_._7/attention/self/key/bias:0', 'bert/encoder/layer_._0/attention/self/query/kernel:0', 'bert/encoder/layer_._7/attention/self/query/bias:0', 'bert/encoder/layer_._2/attention/self/value/kernel:0', 'bert/encoder/layer_._10/attention/self/value/kernel:0', 'bert/encoder/layer_._9/attention/self/query/bias:0', 'bert/encoder/layer_._3/attention/self/query/kernel:0', 'bert/encoder/layer_._10/attention/self/value/bias:0', 'bert/encoder/layer_._9/attention/self/key/kernel:0', 'bert/encoder/layer_._11/attention/self/query/bias:0', 'bert/encoder/layer_._8/attention/self/query/bias:0', 'bert/encoder/layer_._9/attention/self/key/bias:0', 'bert/encoder/layer_._5/attention/self/value/bias:0', 'bert/encoder/layer_._5/attention/self/query/bias:0', 'bert/encoder/layer_._8/attention/self/key/bias:0', 'bert/encoder/layer_._11/attention/self/key/bias:0', 'bert/encoder/layer_._0/attention/self/query/bias:0', 'bert/encoder/layer_._4/attention/self/query/bias:0', 'bert/encoder/layer_._9/attention/self/value/bias:0', 'bert/encoder/layer_._7/attention/self/query/kernel:0', 'bert/encoder/layer_._11/attention/self/value/bias:0', 'bert/encoder/layer_._9/attention/self/value/kernel:0', 'bert/encoder/layer_._6/attention/self/query/kernel:0']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier', 'bert/encoder/layer_._1/attention/self/performer_2/value/bias:0', 'bert/encoder/layer_._4/attention/self/performer_5/value/kernel:0', 'bert/encoder/layer_._3/attention/self/performer_4/attention_output/bias:0', 'bert/encoder/layer_._5/attention/self/performer_6/query/bias:0', 'bert/encoder/layer_._2/attention/self/performer_3/key/kernel:0', 'bert/encoder/layer_._0/attention/self/performer_1/query/kernel:0', 'bert/encoder/layer_._8/attention/self/performer_9/query/kernel:0', 'bert/encoder/layer_._3/attention/self/performer_4/value/bias:0', 'bert/encoder/layer_._5/attention/self/performer_6/attention_output/bias:0', 'bert/encoder/layer_._10/attention/self/performer_11/key/kernel:0', 'bert/encoder/layer_._6/attention/self/performer_7/key/kernel:0', 'bert/encoder/layer_._3/attention/self/performer_4/query/bias:0', 'bert/encoder/layer_._8/attention/self/performer_9/attention_output/bias:0', 'bert/encoder/layer_._8/attention/self/performer_9/attention_output/kernel:0', 'bert/encoder/layer_._5/attention/self/performer_6/key/bias:0', 'bert/encoder/layer_._3/attention/self/performer_4/key/bias:0', 'bert/encoder/layer_._11/attention/self/performer_12/attention_output/kernel:0', 'bert/encoder/layer_._4/attention/self/performer_5/query/kernel:0', 'bert/encoder/layer_._6/attention/self/performer_7/key/bias:0', 'bert/encoder/layer_._10/attention/self/performer_11/value/bias:0', 'bert/encoder/layer_._2/attention/self/performer_3/attention_output/bias:0', 'bert/encoder/layer_._0/attention/self/performer_1/key/kernel:0', 'bert/encoder/layer_._7/attention/self/performer_8/value/kernel:0', 'bert/encoder/layer_._9/attention/self/performer_10/key/kernel:0', 'bert/encoder/layer_._3/attention/self/performer_4/query/kernel:0', 'bert/encoder/layer_._1/attention/self/performer_2/value/kernel:0', 'bert/encoder/layer_._5/attention/self/performer_6/key/kernel:0', 'bert/encoder/layer_._9/attention/self/performer_10/value/kernel:0', 'bert/encoder/layer_._2/attention/self/performer_3/key/bias:0', 'bert/encoder/layer_._2/attention/self/performer_3/attention_output/kernel:0', 'bert/encoder/layer_._0/attention/self/performer_1/query/bias:0', 'bert/encoder/layer_._1/attention/self/performer_2/key/kernel:0', 'bert/encoder/layer_._3/attention/self/performer_4/value/kernel:0', 'bert/encoder/layer_._9/attention/self/performer_10/query/kernel:0', 'bert/encoder/layer_._3/attention/self/performer_4/key/kernel:0', 'bert/encoder/layer_._4/attention/self/performer_5/attention_output/kernel:0', 'bert/encoder/layer_._9/attention/self/performer_10/key/bias:0', 'bert/encoder/layer_._10/attention/self/performer_11/attention_output/kernel:0', 'bert/encoder/layer_._1/attention/self/performer_2/key/bias:0', 'bert/encoder/layer_._10/attention/self/performer_11/attention_output/bias:0', 'bert/encoder/layer_._5/attention/self/performer_6/query/kernel:0', 'bert/encoder/layer_._5/attention/self/performer_6/value/kernel:0', 'bert/encoder/layer_._6/attention/self/performer_7/query/bias:0', 'bert/encoder/layer_._4/attention/self/performer_5/attention_output/bias:0', 'bert/encoder/layer_._7/attention/self/performer_8/attention_output/kernel:0', 'bert/encoder/layer_._7/attention/self/performer_8/attention_output/bias:0', 'bert/encoder/layer_._4/attention/self/performer_5/value/bias:0', 'bert/encoder/layer_._4/attention/self/performer_5/key/bias:0', 'bert/encoder/layer_._11/attention/self/performer_12/key/kernel:0', 'bert/encoder/layer_._7/attention/self/performer_8/key/kernel:0', 'bert/encoder/layer_._9/attention/self/performer_10/value/bias:0', 'bert/encoder/layer_._1/attention/self/performer_2/attention_output/bias:0', 'bert/encoder/layer_._7/attention/self/performer_8/key/bias:0', 'bert/encoder/layer_._6/attention/self/performer_7/attention_output/kernel:0', 'bert/encoder/layer_._10/attention/self/performer_11/value/kernel:0', 'bert/encoder/layer_._0/attention/self/performer_1/key/bias:0', 'bert/encoder/layer_._10/attention/self/performer_11/query/kernel:0', 'bert/encoder/layer_._10/attention/self/performer_11/query/bias:0', 'bert/encoder/layer_._2/attention/self/performer_3/query/bias:0', 'bert/encoder/layer_._9/attention/self/performer_10/attention_output/bias:0', 'bert/encoder/layer_._9/attention/self/performer_10/attention_output/kernel:0', 'bert/encoder/layer_._7/attention/self/performer_8/query/bias:0', 'bert/encoder/layer_._8/attention/self/performer_9/value/kernel:0', 'bert/encoder/layer_._1/attention/self/performer_2/attention_output/kernel:0', 'bert/encoder/layer_._1/attention/self/performer_2/query/kernel:0', 'bert/encoder/layer_._10/attention/self/performer_11/key/bias:0', 'bert/encoder/layer_._0/attention/self/performer_1/value/bias:0', 'bert/encoder/layer_._11/attention/self/performer_12/value/kernel:0', 'bert/encoder/layer_._6/attention/self/performer_7/attention_output/bias:0', 'bert/encoder/layer_._7/attention/self/performer_8/value/bias:0', 'bert/encoder/layer_._11/attention/self/performer_12/query/bias:0', 'bert/encoder/layer_._2/attention/self/performer_3/value/bias:0', 'bert/encoder/layer_._2/attention/self/performer_3/query/kernel:0', 'bert/encoder/layer_._11/attention/self/performer_12/attention_output/bias:0', 'bert/encoder/layer_._6/attention/self/performer_7/query/kernel:0', 'bert/encoder/layer_._0/attention/self/performer_1/value/kernel:0', 'bert/encoder/layer_._11/attention/self/performer_12/value/bias:0', 'bert/encoder/layer_._11/attention/self/performer_12/query/kernel:0', 'bert/encoder/layer_._8/attention/self/performer_9/key/bias:0', 'bert/encoder/layer_._6/attention/self/performer_7/value/kernel:0', 'bert/encoder/layer_._0/attention/self/performer_1/attention_output/kernel:0', 'bert/encoder/layer_._9/attention/self/performer_10/query/bias:0', 'bert/encoder/layer_._5/attention/self/performer_6/value/bias:0', 'bert/encoder/layer_._6/attention/self/performer_7/value/bias:0', 'bert/encoder/layer_._11/attention/self/performer_12/key/bias:0', 'bert/encoder/layer_._1/attention/self/performer_2/query/bias:0', 'bert/encoder/layer_._8/attention/self/performer_9/key/kernel:0', 'bert/encoder/layer_._0/attention/self/performer_1/attention_output/bias:0', 'bert/encoder/layer_._4/attention/self/performer_5/query/bias:0', 'bert/encoder/layer_._3/attention/self/performer_4/attention_output/kernel:0', 'bert/encoder/layer_._4/attention/self/performer_5/key/kernel:0', 'bert/encoder/layer_._8/attention/self/performer_9/value/bias:0', 'bert/encoder/layer_._5/attention/self/performer_6/attention_output/kernel:0', 'bert/encoder/layer_._8/attention/self/performer_9/query/bias:0', 'bert/encoder/layer_._2/attention/self/performer_3/value/kernel:0', 'bert/encoder/layer_._7/attention/self/performer_8/query/kernel:0']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7XYQCDmYX97"
      },
      "source": [
        "## Example Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt_-iywTXbko",
        "outputId": "723044c5-85e0-4bd8-c2a4-97b6284b27bb"
      },
      "source": [
        "# Get IMDB dataset & Tokenizer\r\n",
        "\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "\r\n",
        "(ds_train, ds_test), ds_info = tfds.load('imdb_reviews', \r\n",
        "          split = (tfds.Split.TRAIN, tfds.Split.TEST),\r\n",
        "          as_supervised=True,\r\n",
        "          with_info=True)\r\n",
        "\r\n",
        "print('info', ds_info)\r\n",
        "\r\n",
        "\r\n",
        "from transformers import BertTokenizer\r\n",
        "\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split (Split('train'), Split('test')), from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "info tfds.core.DatasetInfo(\n",
            "    name='imdb_reviews',\n",
            "    version=1.0.0,\n",
            "    description='Large Movie Review Dataset.\n",
            "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
            "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
            "    features=FeaturesDict({\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "        'text': Text(shape=(), dtype=tf.string),\n",
            "    }),\n",
            "    total_num_examples=100000,\n",
            "    splits={\n",
            "        'test': 25000,\n",
            "        'train': 25000,\n",
            "        'unsupervised': 50000,\n",
            "    },\n",
            "    supervised_keys=('text', 'label'),\n",
            "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
            "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
            "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
            "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
            "      month     = {June},\n",
            "      year      = {2011},\n",
            "      address   = {Portland, Oregon, USA},\n",
            "      publisher = {Association for Computational Linguistics},\n",
            "      pages     = {142--150},\n",
            "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAhAmDrvYIGZ"
      },
      "source": [
        "# Hyperparameters:\r\n",
        "\r\n",
        "# can be up to 512 for BERT\r\n",
        "max_length = 512\r\n",
        "batch_size = 6\r\n",
        "\r\n",
        "learning_rate = 2e-5\r\n",
        "number_of_epochs = 1\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exd7McLZXte1",
        "outputId": "9344fb53-24c6-4596-c583-22bf90ac2af0"
      },
      "source": [
        "\r\n",
        "def convert_example_to_feature(review):\r\n",
        "  \r\n",
        "  # combine step for tokenization, WordPiece vector mapping, adding special tokens as well as truncating reviews longer than the max length\r\n",
        "  \r\n",
        "  return tokenizer.encode_plus(review, \r\n",
        "                add_special_tokens = True, # add [CLS], [SEP]\r\n",
        "                max_length = max_length, # max length of the text that can go to BERT\r\n",
        "                pad_to_max_length = True, # add [PAD] tokens\r\n",
        "                return_attention_mask = True, # add attention mask to not focus on pad tokens\r\n",
        "              )\r\n",
        "\r\n",
        "# map to the expected input to TFBertForSequenceClassification, see here \r\n",
        "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\r\n",
        "  return {\r\n",
        "      \"input_ids\": input_ids,\r\n",
        "      \"token_type_ids\": token_type_ids,\r\n",
        "      \"attention_mask\": attention_masks,\r\n",
        "  }, label\r\n",
        "\r\n",
        "def encode_examples(ds, limit=-1):\r\n",
        "\r\n",
        "  # prepare list, so that we can build up final TensorFlow dataset from slices.\r\n",
        "  input_ids_list = []\r\n",
        "  token_type_ids_list = []\r\n",
        "  attention_mask_list = []\r\n",
        "  label_list = []\r\n",
        "\r\n",
        "  if (limit > 0):\r\n",
        "      ds = ds.take(limit)\r\n",
        "    \r\n",
        "  for review, label in tfds.as_numpy(ds):\r\n",
        "\r\n",
        "    bert_input = convert_example_to_feature(review.decode())\r\n",
        "  \r\n",
        "    input_ids_list.append(bert_input['input_ids'])\r\n",
        "    token_type_ids_list.append(bert_input['token_type_ids'])\r\n",
        "    attention_mask_list.append(bert_input['attention_mask'])\r\n",
        "    label_list.append([label])\r\n",
        "\r\n",
        "  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# train dataset\r\n",
        "ds_train_encoded = encode_examples(ds_train).shuffle(10000).batch(batch_size)\r\n",
        "\r\n",
        "# test dataset\r\n",
        "ds_test_encoded = encode_examples(ds_test).batch(batch_size)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/content/packages/transformers/src/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTqJeu06X_Gg"
      },
      "source": [
        "# Training\r\n",
        "\r\n",
        "# optimizer Adam recommended\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\r\n",
        "\r\n",
        "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\r\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\r\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lsh-gV_YWTNS",
        "outputId": "d2bc52cf-c652-46f5-ef64-31355dc90669"
      },
      "source": [
        "# Fails at training\r\n",
        "bert_history = model.fit(ds_train_encoded, epochs=number_of_epochs, validation_data=ds_test_encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-667f08a4c217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fails at training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbert_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_test_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-12-914e11047f50>:291 call  *\n        outputs = self.bert(\n    <ipython-input-12-914e11047f50>:212 call  *\n        encoder_outputs = self.encoder(\n    <ipython-input-12-914e11047f50>:84 call  *\n        layer_outputs = layer_module(\n    <ipython-input-12-914e11047f50>:51 call  *\n        attention_outputs = self.attention(\n    <ipython-input-12-914e11047f50>:34 call  *\n        self_outputs = self.self_attention(\n    <ipython-input-11-d6c1926bbfb8>:30 call  *\n        attn_output = tf.reshape(attn_output, new_shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:195 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:8378 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:525 _apply_op_helper\n        raise err\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:515 _apply_op_helper\n        preferred_dtype=default_dtype)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py:163 wrapped\n        return func(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1540 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:265 constant\n        allow_broadcast=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:283 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:553 make_tensor_proto\n        \"supported type.\" % (type(values), values))\n\n    TypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 512, 12, 64]. Consider casting elements to a supported type.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTdITgf2s_nS"
      },
      "source": [
        "## Trying out the in-progress PR on huggingface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cETSJk0U4t9r"
      },
      "source": [
        "!mkdir ./packages\r\n",
        "!git clone https://github.com/norabelrose/transformers-plus-performers.git\r\n",
        "!cp -r ./trans* ./packages/transformers\r\n",
        "!rm -r ./trans*\r\n",
        "!cd ./packages/transformers; pip install -e '.[dev]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlcorCP12nZ3"
      },
      "source": [
        "# Setup transformers in subpackage\r\n",
        "import os\r\n",
        "import sys\r\n",
        "module_path = os.path.abspath(os.path.join('./packages/transformers/src'))\r\n",
        "\r\n",
        "if module_path not in sys.path:\r\n",
        "    sys.path.append(module_path)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da-S7Xf-2dPH"
      },
      "source": [
        "from transformers.models.bert.modeling_tf_bert import (\r\n",
        "    TFBertForSequenceClassification,\r\n",
        "    BertConfig\r\n",
        ")\r\n",
        "\r\n",
        "from transformers.models.distilbert.modeling_tf_distilbert import (\r\n",
        "    TFDistilBertForSequenceClassification\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCed0B6q0U3H"
      },
      "source": [
        "# We can load the models in, but they still fail at training\r\n",
        "\r\n",
        "config = BertConfig(attention_type=\"performer\")\r\n",
        "model = TFBertForSequenceClassification(config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFwSCtdo6jDI"
      },
      "source": [
        "\r\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', attention_type=\"performer\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}