{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenization_Experiments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c201949db8fe4f089ff07da3e25e3d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_38daeb53c7544378896813e4dfcf3ed0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_334ffde69b7d488192c50752214851d7",
              "IPY_MODEL_7a7f92ae96dc489f909ff2c4ed8eca8f"
            ]
          }
        },
        "38daeb53c7544378896813e4dfcf3ed0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "334ffde69b7d488192c50752214851d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2398e2f59721499e94ef4ea6418e7ffd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 647,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 647,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8d725f13faa488993587befacc2a1bc"
          }
        },
        "7a7f92ae96dc489f909ff2c4ed8eca8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a20fe227938e439a96ab352d41147e63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 647/647 [00:00&lt;00:00, 2.87kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8c0f640a20245808dc0d4c09931afec"
          }
        },
        "2398e2f59721499e94ef4ea6418e7ffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8d725f13faa488993587befacc2a1bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a20fe227938e439a96ab352d41147e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8c0f640a20245808dc0d4c09931afec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e66b3441d54544f49fbe2b4693faa378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b5008e3e0ad04318ab3dbdebca992e1a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9610fc43b6fe4d8f84eaa446ded4aeb8",
              "IPY_MODEL_fd6fadad1e3f4ac0bceb4aab2aa47531"
            ]
          }
        },
        "b5008e3e0ad04318ab3dbdebca992e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9610fc43b6fe4d8f84eaa446ded4aeb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2d5b4f8a44b422b8e5234105c170c63",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f1a9f7f556ce44e18a7a27e6203c0c29"
          }
        },
        "fd6fadad1e3f4ac0bceb4aab2aa47531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_517fe0bb39054fe0a133ac46a517c541",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110k/110k [00:00&lt;00:00, 119kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb44f1208a1a4e45ad4034c3b1fac076"
          }
        },
        "d2d5b4f8a44b422b8e5234105c170c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f1a9f7f556ce44e18a7a27e6203c0c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "517fe0bb39054fe0a133ac46a517c541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb44f1208a1a4e45ad4034c3b1fac076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1568caf6babc4824b25b05b20919b31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b804770634e4aa38f091179e68642e5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_957f29569fdc4cf98e377fa7f18b6f8f",
              "IPY_MODEL_8f35b86920ef40dcad1edbdd1280cad8"
            ]
          }
        },
        "8b804770634e4aa38f091179e68642e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "957f29569fdc4cf98e377fa7f18b6f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_847c5c5f36814508873acc82e1994909",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_709bf89335924fb2affa047a65e8eea0"
          }
        },
        "8f35b86920ef40dcad1edbdd1280cad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dad03117e50348caa7adf148ad2d1dbd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.00/2.00 [00:00&lt;00:00, 3.94B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c28085ebf2674a5e9dae4f5322d291d2"
          }
        },
        "847c5c5f36814508873acc82e1994909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "709bf89335924fb2affa047a65e8eea0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dad03117e50348caa7adf148ad2d1dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c28085ebf2674a5e9dae4f5322d291d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b87902ec6b8d45c18eca4e221d4de627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_670204a4016a41448ae07bef59532179",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_337a843ca48f424e8ce39c88a39e9304",
              "IPY_MODEL_e4165a61c35544c7b6e7f2158ba1f3c5"
            ]
          }
        },
        "670204a4016a41448ae07bef59532179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "337a843ca48f424e8ce39c88a39e9304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_12975d9e13d548178649fb7b46870f56",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d944d21b957f405fbd6f2060a27ceefa"
          }
        },
        "e4165a61c35544c7b6e7f2158ba1f3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e6ad500f4fa442358bf7612ec64148b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 438B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9bf613aa7a94ddb8051455d192b494f"
          }
        },
        "12975d9e13d548178649fb7b46870f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d944d21b957f405fbd6f2060a27ceefa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6ad500f4fa442358bf7612ec64148b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9bf613aa7a94ddb8051455d192b494f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8b5b5044ba2425ca88c81e3344c24b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_04cd621ddf554d39b5a706af147a020a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f90b358d1ee4e21af18f7314fc2e07d",
              "IPY_MODEL_f54b0eac4a3141d1af06b8e123e5de39"
            ]
          }
        },
        "04cd621ddf554d39b5a706af147a020a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f90b358d1ee4e21af18f7314fc2e07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8805a5e81d764b5b9766909702671cee",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 19,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 19,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2b90c50da8c4a819383b1b098bc0b46"
          }
        },
        "f54b0eac4a3141d1af06b8e123e5de39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9323caea0ad34fe695b1e8008d938878",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 19.0/19.0 [00:00&lt;00:00, 225B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da1084520f7c4bb49e80b0295f56ce69"
          }
        },
        "8805a5e81d764b5b9766909702671cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2b90c50da8c4a819383b1b098bc0b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9323caea0ad34fe695b1e8008d938878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da1084520f7c4bb49e80b0295f56ce69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264,
          "referenced_widgets": [
            "c201949db8fe4f089ff07da3e25e3d3c",
            "38daeb53c7544378896813e4dfcf3ed0",
            "334ffde69b7d488192c50752214851d7",
            "7a7f92ae96dc489f909ff2c4ed8eca8f",
            "2398e2f59721499e94ef4ea6418e7ffd",
            "d8d725f13faa488993587befacc2a1bc",
            "a20fe227938e439a96ab352d41147e63",
            "f8c0f640a20245808dc0d4c09931afec",
            "e66b3441d54544f49fbe2b4693faa378",
            "b5008e3e0ad04318ab3dbdebca992e1a",
            "9610fc43b6fe4d8f84eaa446ded4aeb8",
            "fd6fadad1e3f4ac0bceb4aab2aa47531",
            "d2d5b4f8a44b422b8e5234105c170c63",
            "f1a9f7f556ce44e18a7a27e6203c0c29",
            "517fe0bb39054fe0a133ac46a517c541",
            "fb44f1208a1a4e45ad4034c3b1fac076",
            "1568caf6babc4824b25b05b20919b31d",
            "8b804770634e4aa38f091179e68642e5",
            "957f29569fdc4cf98e377fa7f18b6f8f",
            "8f35b86920ef40dcad1edbdd1280cad8",
            "847c5c5f36814508873acc82e1994909",
            "709bf89335924fb2affa047a65e8eea0",
            "dad03117e50348caa7adf148ad2d1dbd",
            "c28085ebf2674a5e9dae4f5322d291d2",
            "b87902ec6b8d45c18eca4e221d4de627",
            "670204a4016a41448ae07bef59532179",
            "337a843ca48f424e8ce39c88a39e9304",
            "e4165a61c35544c7b6e7f2158ba1f3c5",
            "12975d9e13d548178649fb7b46870f56",
            "d944d21b957f405fbd6f2060a27ceefa",
            "e6ad500f4fa442358bf7612ec64148b4",
            "f9bf613aa7a94ddb8051455d192b494f",
            "d8b5b5044ba2425ca88c81e3344c24b1",
            "04cd621ddf554d39b5a706af147a020a",
            "9f90b358d1ee4e21af18f7314fc2e07d",
            "f54b0eac4a3141d1af06b8e123e5de39",
            "8805a5e81d764b5b9766909702671cee",
            "e2b90c50da8c4a819383b1b098bc0b46",
            "9323caea0ad34fe695b1e8008d938878",
            "da1084520f7c4bb49e80b0295f56ce69"
          ]
        },
        "id": "JexxP16DMJwj",
        "outputId": "abcd373f-3f61-455f-ce1a-94e9a4431ae7"
      },
      "source": [
        "### Installs ###\r\n",
        "\r\n",
        "!pip install -q ltp\r\n",
        "!pip install -q transformers\r\n",
        "\r\n",
        "from transformers import AutoTokenizer\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from ltp import LTP\r\n",
        "\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\r\n",
        "\r\n",
        "tokenizer_bert = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\r\n",
        "\r\n",
        "tokenizer_bert_cn = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\r\n",
        "tokenizer_bert_cn = AutoTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\r\n",
        "\r\n",
        "tokenizer_ltp = LTP(\"small\")  # Needs a path? # Small is default"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c201949db8fe4f089ff07da3e25e3d3c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=647.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e66b3441d54544f49fbe2b4693faa378",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1568caf6babc4824b25b05b20919b31d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b87902ec6b8d45c18eca4e221d4de627",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8b5b5044ba2425ca88c81e3344c24b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=19.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtHUqzxnLUeF",
        "outputId": "c5457658-00bc-44cb-c19a-9ae0e63bc27f"
      },
      "source": [
        "text = 'Yangliuqing () is a market town in Xiqing District, in the western suburbs of Tianjin, People\\'s Republic of China.'\r\n",
        "\r\n",
        "print(text)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yangliuqing () is a market town in Xiqing District, in the western suburbs of Tianjin, People's Republic of China.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6EiAt-MuUW7",
        "outputId": "85c38bb7-f673-4867-d62c-5871c3f73e8e"
      },
      "source": [
        "tokens = tokenizer_bert.tokenize(text)\r\n",
        "print(tokens)\r\n",
        "mask = _whole_word_mask(tokens)\r\n",
        "print(mask)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['yang', '##li', '##u', '##qing', '(', ')', 'is', 'a', 'market', 'town', 'in', 'xi', '##qing', 'district', ',', 'in', 'the', 'western', 'suburbs', 'of', 'tianjin', ',', 'people', \"'\", 's', 'republic', 'of', 'china', '.']\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuJrc-Qnssxk",
        "outputId": "c1a9f0c6-0e04-40ef-ff63-9186506ab2ca"
      },
      "source": [
        "tokens = tokenizer.tokenize(text)\r\n",
        "print(tokens)\r\n",
        "mask = _whole_word_mask(tokens)\r\n",
        "print(mask)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁Yan', 'gli', 'u', 'q', 'ing', '▁(', ')', '▁is', '▁', 'a', '▁market', '▁town', '▁in', '▁', 'X', 'i', 'q', 'ing', '▁District', ',', '▁in', '▁the', '▁western', '▁suburb', 's', '▁of', '▁Ti', 'a', 'nji', 'n', ',', '▁People', \"'\", 's', '▁Republic', '▁of', '▁China', '.']\n",
            "gli\n",
            "u\n",
            "q\n",
            "ing\n",
            ")\n",
            "a\n",
            "X\n",
            "i\n",
            "q\n",
            "ing\n",
            ",\n",
            "s\n",
            "a\n",
            "nji\n",
            "n\n",
            ",\n",
            "'\n",
            "s\n",
            ".\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7AdDq1SxTsn",
        "outputId": "8ceccaf0-34a7-4235-8643-5671b8f85ab9"
      },
      "source": [
        "text = '聯邦總理是德意志聯邦共和國的政府首腦。'\r\n",
        "\r\n",
        "tokens = tokenizer_bert_cn.tokenize(text)\r\n",
        "print(tokens)\r\n",
        "print(tokenizer_bert_cn.encode(text))\r\n",
        "mask = _whole_word_mask(tokens)\r\n",
        "print(mask)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['聯', '邦', '總', '理', '是', '德', '意', '志', '聯', '邦', '共', '和', '國', '的', '政', '府', '首', '腦', '。']\n",
            "[101, 5474, 6930, 5244, 4415, 3221, 2548, 2692, 2562, 5474, 6930, 1066, 1469, 1751, 4638, 3124, 2424, 7674, 5582, 511, 102]\n",
            "邦\n",
            "總\n",
            "理\n",
            "是\n",
            "德\n",
            "意\n",
            "志\n",
            "聯\n",
            "邦\n",
            "共\n",
            "和\n",
            "國\n",
            "的\n",
            "政\n",
            "府\n",
            "首\n",
            "腦\n",
            "。\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LQvsVFKKIEm",
        "outputId": "dc01c0a7-d544-46bc-c7a3-c5b626cda432"
      },
      "source": [
        "text = '總理是德意志聯邦共和國的政府首腦。'\r\n",
        "text2 = '余弦相似性，可以被看作是在比较過程中把文件长度正規化的方法。'\r\n",
        "\r\n",
        "txt_list = [[text], [text2]]\r\n",
        "txt_list1 = [text, text2]\r\n",
        "txt_list2 = [text]\r\n",
        "\r\n",
        "print(txt_list)\r\n",
        "\r\n",
        "ref_ids = prepare_ref([text], tokenizer_ltp, tokenizer_bert_cn)\r\n",
        "\r\n",
        "print(\"IDS:\", ref_ids)\r\n",
        "\r\n",
        "\r\n",
        "tokens = tokenizer_bert_cn.tokenize(text)\r\n",
        "print(\"TOKENS: \", tokens)\r\n",
        "mask = cn_whole_word_mask(tokens, ref_ids[0])\r\n",
        "print(\"MASK: \", mask)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['總理是德意志聯邦共和國的政府首腦。'], ['余弦相似性，可以被看作是在比较過程中把文件长度正規化的方法。']]\n",
            "CN WORD INPT: ['總理', '是', '德意志聯邦共和國', '的', '政府', '首腦', '。']\n",
            "LTP RES: [['德意志聯邦共和國', '政府', '首腦', '總理']]\n",
            "B RES: [[101, 5244, 4415, 3221, 2548, 2692, 2562, 5474, 6930, 1066, 1469, 1751, 4638, 3124, 2424, 7674, 5582, 511, 102]]\n",
            "IDS: [[2, 5, 6, 7, 8, 9, 10, 11, 14, 16]]\n",
            "TOKENS:  ['總', '理', '是', '德', '意', '志', '聯', '邦', '共', '和', '國', '的', '政', '府', '首', '腦', '。']\n",
            "IT: ['總', '理', '是', '德', '意', '志', '聯', '邦', '共', '和', '國', '的', '政', '府', '首', '腦', '。']\n",
            "RI: [2, 5, 6, 7, 8, 9, 10, 11, 14, 16]\n",
            "IT adjusted ['總', '##理', '是', '德', '##意', '##志', '##聯', '##邦', '##共', '##和', '##國', '的', '政', '##府', '首', '##腦', '。']\n",
            "MASK:  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJRKF7XAMSh1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPDvJcaE5kZt",
        "outputId": "d485c565-6833-4919-97cb-a5469db3eb0b"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-bert-wwm\")\r\n",
        "\r\n",
        "len(tokenizer.get_vocab())\r\n",
        "\r\n",
        "len(toenizer_bert_cn.get_vocab())"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPKeQhI4eIo2"
      },
      "source": [
        "\r\n",
        "  \r\n"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwhKVUMZzhv2",
        "outputId": "22847932-6981-44d6-e45c-af15c2fb3fc8"
      },
      "source": [
        "### WWM for CN\r\n",
        "\r\n",
        "### >>> Write your own tokenizer class extending HGFace\r\n",
        "### Could take in as argument prepend text for translate etc tasks; returns decoder labels, decoder inputs, encoder inputs\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# 1) Generate ref ids based on LTP tokenizer > prepare_ref\r\n",
        "# 2) Generate mask for whole words\r\n",
        "# 3) Implement the masking\r\n",
        "\r\n",
        "\r\n",
        "text = '總理是德意志聯邦共和國的政府首腦。'\r\n",
        "ref_ids = prepare_ref([text], tokenizer_ltp, tokenizer_bert_cn)\r\n",
        "tokens = tokenizer_bert_cn.tokenize(text)\r\n",
        "ref_ids = cn_whole_word_mask(tokens, ref_ids[0])\r\n",
        "\r\n",
        "print(\"REFIDS:\", ref_ids)\r\n",
        "\r\n",
        "tokens, output = random_word(tokens, ref_ids, tokenizer_bert_cn)\r\n",
        "\r\n",
        "print(\"TOKS, OUT:\", tokens, output)\r\n",
        "\r\n",
        "\r\n",
        "def random_word(tokens, ref_ids, tokenizer):\r\n",
        "    \"\"\"\r\n",
        "    Masking some random tokens for Language Model task with probabilities as in the original BERT paper.\r\n",
        "    :param tokens: list of str, tokenized sentence.\r\n",
        "    :param ref_ids: list of int, 1 is where to place a mask\r\n",
        "    :param tokenizer: Tokenizer, object used for tokenization (we need it's vocab here)\r\n",
        "    :return: (list of str, list of int), masked tokens and related labels for LM prediction\r\n",
        "    \"\"\"\r\n",
        "    output_label = []\r\n",
        "\r\n",
        "    for i, (token, ref_id) in enumerate(zip(tokens, ref_ids)):\r\n",
        "\r\n",
        "        prob = random.random()\r\n",
        "\r\n",
        "        if ref_id == 1:\r\n",
        "\r\n",
        "            # 80% randomly change token to mask token\r\n",
        "            if prob < 0.8:\r\n",
        "                tokens[i] = \"[MASK]\"\r\n",
        "\r\n",
        "            # 10% randomly change token to random token\r\n",
        "            elif prob < 0.9:\r\n",
        "                tokens[i] = random.choice(list(tokenizer.vocab.items()))[0]\r\n",
        "\r\n",
        "            # -> rest 10% randomly keep current token\r\n",
        "\r\n",
        "            # append current token to output (we will predict these later)\r\n",
        "            try:\r\n",
        "                output_label.append(tokenizer.vocab[token])\r\n",
        "            except KeyError:\r\n",
        "                # For unknown words (should not occur with BPE vocab)\r\n",
        "                output_label.append(tokenizer.vocab[\"[UNK]\"])\r\n",
        "        else:\r\n",
        "            # no masking token (will be ignored by loss function later)\r\n",
        "            output_label.append(-1)\r\n",
        "\r\n",
        "    return tokens, output_label\r\n",
        "\r\n",
        "def _is_chinese_char(cp):\r\n",
        "    \"\"\"\r\n",
        "    Checks whether CP is the codepoint of a CJK character.\r\n",
        "    \"\"\"\r\n",
        "    # This defines a \"chinese character\" as anything in the CJK Unicode block:\r\n",
        "    #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\r\n",
        "    #\r\n",
        "    # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\r\n",
        "    # despite its name. The modern Korean Hangul alphabet is a different block,\r\n",
        "    # as is Japanese Hiragana and Katakana. Those alphabets are used to write\r\n",
        "    # space-separated words, so they are not treated specially and handled\r\n",
        "    # like the all of the other languages.\r\n",
        "    if (\r\n",
        "        (cp >= 0x4E00 and cp <= 0x9FFF)\r\n",
        "        or (cp >= 0x3400 and cp <= 0x4DBF)  #\r\n",
        "        or (cp >= 0x20000 and cp <= 0x2A6DF)  #\r\n",
        "        or (cp >= 0x2A700 and cp <= 0x2B73F)  #\r\n",
        "        or (cp >= 0x2B740 and cp <= 0x2B81F)  #\r\n",
        "        or (cp >= 0x2B820 and cp <= 0x2CEAF)  #\r\n",
        "        or (cp >= 0xF900 and cp <= 0xFAFF)\r\n",
        "        or (cp >= 0x2F800 and cp <= 0x2FA1F)  #\r\n",
        "    ):  #\r\n",
        "        return True\r\n",
        "\r\n",
        "    return False\r\n",
        "\r\n",
        "\r\n",
        "def is_chinese(word):\r\n",
        "    \"\"\"\r\n",
        "    Args:\r\n",
        "      word: str\r\n",
        "    \"\"\"\r\n",
        "    # word like '180' or '身高' or '神'\r\n",
        "    for char in word:\r\n",
        "        char = ord(char)\r\n",
        "        if not _is_chinese_char(char):\r\n",
        "            return 0\r\n",
        "    return 1\r\n",
        "\r\n",
        "\r\n",
        "def get_chinese_word(tokens):\r\n",
        "    \"\"\"\r\n",
        "    Args:\r\n",
        "      List[str]\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    print(\"CN WORD INPT:\", tokens)\r\n",
        "    word_set = set()\r\n",
        "\r\n",
        "    for token in tokens:\r\n",
        "        chinese_word = len(token) > 1 and is_chinese(token)\r\n",
        "        if chinese_word:\r\n",
        "            word_set.add(token)\r\n",
        "    word_list = list(word_set)\r\n",
        "    return word_list\r\n",
        "\r\n",
        "\r\n",
        "def add_sub_symbol(bert_tokens, chinese_word_set):\r\n",
        "    \"\"\"\r\n",
        "    Args:\r\n",
        "      bert_tokens: List[str]\r\n",
        "      chinese_word_set: set\r\n",
        "    \"\"\"\r\n",
        "    if not chinese_word_set:\r\n",
        "        return bert_tokens\r\n",
        "    max_word_len = max([len(w) for w in chinese_word_set])\r\n",
        "\r\n",
        "    bert_word = bert_tokens\r\n",
        "    start, end = 0, len(bert_word)\r\n",
        "    while start < end:\r\n",
        "        single_word = True\r\n",
        "        if is_chinese(bert_word[start]):\r\n",
        "            l = min(end - start, max_word_len)\r\n",
        "            for i in range(l, 1, -1):\r\n",
        "                whole_word = \"\".join(bert_word[start : start + i])\r\n",
        "                if whole_word in chinese_word_set:\r\n",
        "                    for j in range(start + 1, start + i):\r\n",
        "                        bert_word[j] = \"##\" + bert_word[j]\r\n",
        "                    start = start + i\r\n",
        "                    single_word = False\r\n",
        "                    break\r\n",
        "        if single_word:\r\n",
        "            start += 1\r\n",
        "    return bert_word\r\n",
        "\r\n",
        "def prepare_ref(lines, ltp_tokenizer, bert_tokenizer):\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    Args:\r\n",
        "      lines: List[str] - e.g. [text1, text2]\r\n",
        "      ltp_tokenizer\r\n",
        "      bert_tokenizer\r\n",
        "\r\n",
        "    Returns:\r\n",
        "      ref_ids: List[List[int], ...]\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    ltp_res = []\r\n",
        "\r\n",
        "    for i in range(0, len(lines), 100):\r\n",
        "        res = ltp_tokenizer.seg(lines[i : i + 100])[0]\r\n",
        "        res = [get_chinese_word(r) for r in res]\r\n",
        "        ltp_res.extend(res)\r\n",
        "    assert len(ltp_res) == len(lines)\r\n",
        "\r\n",
        "    bert_res = []\r\n",
        "    for i in range(0, len(lines), 100):\r\n",
        "        res = bert_tokenizer(lines[i : i + 100], add_special_tokens=True, truncation=True, max_length=512)\r\n",
        "        bert_res.extend(res[\"input_ids\"])\r\n",
        "    assert len(bert_res) == len(lines)\r\n",
        "\r\n",
        "\r\n",
        "    print(\"LTP RES:\", ltp_res)\r\n",
        "    print(\"B RES:\", bert_res)\r\n",
        "\r\n",
        "\r\n",
        "    ref_ids = []\r\n",
        "    for input_ids, chinese_word in zip(bert_res, ltp_res):\r\n",
        "\r\n",
        "        input_tokens = []\r\n",
        "        for id in input_ids:\r\n",
        "            token = bert_tokenizer._convert_id_to_token(id)\r\n",
        "            input_tokens.append(token)\r\n",
        "        input_tokens = add_sub_symbol(input_tokens, chinese_word)\r\n",
        "        ref_id = []\r\n",
        "        # We only save pos of chinese subwords start with ##, which mean is part of a whole word.\r\n",
        "        for i, token in enumerate(input_tokens):\r\n",
        "            if token[:2] == \"##\":\r\n",
        "                clean_token = token[2:]\r\n",
        "                # save chinese tokens' pos\r\n",
        "                if len(clean_token) == 1 and _is_chinese_char(ord(clean_token)):\r\n",
        "                    ref_id.append(i)\r\n",
        "        ref_ids.append(ref_id)\r\n",
        "\r\n",
        "    assert len(ref_ids) == len(bert_res)\r\n",
        "\r\n",
        "    return ref_ids\r\n",
        "\r\n",
        "\r\n",
        "def cn_whole_word_mask(input_tokens, ref_ids, max_predictions=512, mlm_probability=0.15):\r\n",
        "    \"\"\"\r\n",
        "    Masks whole words in CN based on the reference ids & the standard _whole_word_mask for BERT for one individual example.\r\n",
        "\r\n",
        "    Args:\r\n",
        "      input_tokens: List[str]\r\n",
        "      ref_tokens: List[int]\r\n",
        "\r\n",
        "    Returns:\r\n",
        "      input_tokens: List[int]\r\n",
        "\r\n",
        "    TODO:\r\n",
        "      We could save the LTP dependency by copying the function from: https://github.com/HIT-SCIR/ltp/blob/c47b3f455c07c5dcc186f2b674efde8c67612baf/ltp/algorithms/maximum_forward_matching.py#L75\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    print(\"IT:\", input_tokens)\r\n",
        "    print(\"RI:\", ref_ids)\r\n",
        "    \r\n",
        "    for i in range(len(input_tokens)):\r\n",
        "        if i in ref_ids:\r\n",
        "            # We move it back by -1 as the ref_ids start at 1, not 0\r\n",
        "            input_tokens[i-1] = \"##\" + input_tokens[i-1]\r\n",
        "\r\n",
        "    print(\"IT adjusted\", input_tokens)\r\n",
        "\r\n",
        "    input_tokens = _whole_word_mask(input_tokens)\r\n",
        "\r\n",
        "    return input_tokens\r\n",
        "\r\n"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CN WORD INPT: ['總理', '是', '德意志聯邦共和國', '的', '政府', '首腦', '。']\n",
            "LTP RES: [['德意志聯邦共和國', '政府', '首腦', '總理']]\n",
            "B RES: [[101, 5244, 4415, 3221, 2548, 2692, 2562, 5474, 6930, 1066, 1469, 1751, 4638, 3124, 2424, 7674, 5582, 511, 102]]\n",
            "IT: ['總', '理', '是', '德', '意', '志', '聯', '邦', '共', '和', '國', '的', '政', '府', '首', '腦', '。']\n",
            "RI: [2, 5, 6, 7, 8, 9, 10, 11, 14, 16]\n",
            "IT adjusted ['總', '##理', '是', '德', '##意', '##志', '##聯', '##邦', '##共', '##和', '##國', '的', '政', '##府', '首', '##腦', '。']\n",
            "REFIDS: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "TOKS, OUT: ['總', '##理', '是', '德', '##意', '##志', '##聯', '##邦', '##共', '##和', '##國', '[MASK]', '[MASK]', '[MASK]', '首', '##腦', '。'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 4638, 3124, 15481, -1, -1, -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ORPTsxSsu5X"
      },
      "source": [
        "## Whole Word Masking\r\n",
        "\r\n",
        "\r\n",
        "def _whole_word_mask(input_tokens, max_predictions=512, mlm_probability=0.15):\r\n",
        "    \"\"\"\r\n",
        "    Get 0/1 labels for masked tokens with whole word mask proxy\r\n",
        "\r\n",
        "    Args:\r\n",
        "      input_tokens: List[str]\r\n",
        "\r\n",
        "    Outputs:\r\n",
        "      input_tokens: List[int]\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    cand_indexes = []\r\n",
        "    for (i, token) in enumerate(input_tokens):\r\n",
        "        if token == \"[CLS]\" or token == \"[SEP]\":\r\n",
        "            continue\r\n",
        "\r\n",
        "        if len(cand_indexes) >= 1 and token.startswith(\"##\"):\r\n",
        "            cand_indexes[-1].append(i)\r\n",
        "\r\n",
        "        ### T5:\r\n",
        "        #if token == \"<pad>\" or token == \"</s>\":\r\n",
        "        #    continue\r\n",
        "\r\n",
        "        #if len(cand_indexes) >= 1 and (token.startswith(\"▁\") == False):\r\n",
        "        #    print(token)\r\n",
        "        #    cand_indexes[-1].append(i)\r\n",
        "\r\n",
        "        else:\r\n",
        "            cand_indexes.append([i])\r\n",
        "\r\n",
        "    random.shuffle(cand_indexes)\r\n",
        "    num_to_predict = min(max_predictions, max(1, int(round(len(input_tokens) * mlm_probability))))\r\n",
        "    masked_lms = []\r\n",
        "    covered_indexes = set()\r\n",
        "    for index_set in cand_indexes:\r\n",
        "        if len(masked_lms) >= num_to_predict:\r\n",
        "            break\r\n",
        "        # If adding a whole-word mask would exceed the maximum number of\r\n",
        "        # predictions, then just skip this candidate.\r\n",
        "        if len(masked_lms) + len(index_set) > num_to_predict:\r\n",
        "            continue\r\n",
        "        is_any_index_covered = False\r\n",
        "        for index in index_set:\r\n",
        "            if index in covered_indexes:\r\n",
        "                is_any_index_covered = True\r\n",
        "                break\r\n",
        "        if is_any_index_covered:\r\n",
        "            continue\r\n",
        "        for index in index_set:\r\n",
        "            covered_indexes.add(index)\r\n",
        "            masked_lms.append(index)\r\n",
        "\r\n",
        "    assert len(covered_indexes) == len(masked_lms)\r\n",
        "    mask_labels = [1 if i in covered_indexes else 0 for i in range(len(input_tokens))]\r\n",
        "    return mask_labels"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "yqpydsgJzg6O",
        "outputId": "c06deda3-5f8a-429d-e31d-d10774edd3fd"
      },
      "source": [
        "    def mask_tokens(self, inputs: torch.Tensor, mask_labels: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\r\n",
        "        \"\"\"\r\n",
        "        Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. Set\r\n",
        "        'mask_labels' means we use whole word mask (wwm), we directly mask idxs according to it's ref.\r\n",
        "\r\n",
        "        args:\r\n",
        "          inputs: \r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        if self.tokenizer.mask_token is None:\r\n",
        "            raise ValueError(\r\n",
        "                \"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"\r\n",
        "            )\r\n",
        "        labels = inputs.clone()\r\n",
        "        # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)\r\n",
        "\r\n",
        "        probability_matrix = mask_labels\r\n",
        "\r\n",
        "        special_tokens_mask = [\r\n",
        "            self.tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()\r\n",
        "        ]\r\n",
        "        probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)\r\n",
        "        if self.tokenizer._pad_token is not None:\r\n",
        "            padding_mask = labels.eq(self.tokenizer.pad_token_id)\r\n",
        "            probability_matrix.masked_fill_(padding_mask, value=0.0)\r\n",
        "\r\n",
        "        masked_indices = probability_matrix.bool()\r\n",
        "        labels[~masked_indices] = -100  # We only compute loss on masked tokens\r\n",
        "\r\n",
        "        # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])\r\n",
        "        indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices\r\n",
        "        inputs[indices_replaced] = self.tokenizer.convert_tokens_to_ids(self.tokenizer.mask_token)\r\n",
        "\r\n",
        "        # 10% of the time, we replace masked input tokens with random word\r\n",
        "        indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced\r\n",
        "        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\r\n",
        "        inputs[indices_random] = random_words[indices_random]\r\n",
        "\r\n",
        "        # The rest of the time (10% of the time) we keep the masked input tokens unchanged\r\n",
        "        return inputs, labels"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-ef531144741e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mmask_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mPrepare\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmasked\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mMASK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'mask_labels'\u001b[0m \u001b[0mmeans\u001b[0m \u001b[0mwe\u001b[0m \u001b[0muse\u001b[0m \u001b[0mwhole\u001b[0m \u001b[0mword\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwwm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mdirectly\u001b[0m \u001b[0mmask\u001b[0m \u001b[0midxs\u001b[0m \u001b[0maccording\u001b[0m \u001b[0mto\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jta-PJtXzg1j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7ZFjaLqagMu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajhUp0J_agHM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nttx9FiYzgwm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar9uPOitzgs3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "GL2TpiDgN5Rg",
        "outputId": "af9dc814-5a57-4af0-9977-a3286dc59ef0"
      },
      "source": [
        "### MASKING FROM T5 REPO ###\r\n",
        "\r\n",
        "\r\n",
        "random_spans_noise_mask(10)\r\n",
        "\r\n",
        "def random_spans_noise_mask(length,\r\n",
        "                            noise_density=0.15,\r\n",
        "                            seeds=tf.constant([[0, 1], [2, 3]]),\r\n",
        "                            mean_noise_span_length=3.0):\r\n",
        "  \"\"\"Noise mask consisting of random spans of noise tokens.\r\n",
        "  The number of noise tokens and the number of noise spans and non-noise spans\r\n",
        "  are determined deterministically as follows:\r\n",
        "    num_noise_tokens = round(length * noise_density)\r\n",
        "    num_nonnoise_spans = num_noise_spans = round(\r\n",
        "       num_noise_tokens / mean_noise_span_length)\r\n",
        "  Spans alternate between non-noise and noise, beginning with non-noise.\r\n",
        "  Subject to the above restrictions, all masks are equally likely.\r\n",
        "  Args:\r\n",
        "    length: an int32 scalar (length of the incoming token sequence)\r\n",
        "    noise_density: a float - approximate density of output mask\r\n",
        "    seeds: an int32 Tensor, shaped (2, 2)\r\n",
        "    mean_noise_span_length: a number\r\n",
        "  Returns:\r\n",
        "    a boolean tensor with shape [length]\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  orig_length = length\r\n",
        "  # increase length to avoid degeneracy\r\n",
        "  length = tf.maximum(length, 2)\r\n",
        "  def to_int(x):\r\n",
        "    return tf.cast(x, tf.int32)\r\n",
        "  def to_float(x):\r\n",
        "    return tf.cast(x, tf.float32)\r\n",
        "  num_noise_tokens = to_int(tf.round(to_float(length) * noise_density))\r\n",
        "  # avoid degeneracy by ensuring positive numbers of noise and nonnoise tokens.\r\n",
        "  num_noise_tokens = tf.minimum(tf.maximum(num_noise_tokens, 1), length - 1)\r\n",
        "  num_noise_spans = to_int(\r\n",
        "      tf.round(to_float(num_noise_tokens) / mean_noise_span_length))\r\n",
        "  # avoid degeneracy by ensuring positive number of noise spans\r\n",
        "  num_noise_spans = tf.maximum(num_noise_spans, 1)\r\n",
        "  num_nonnoise_tokens = length - num_noise_tokens\r\n",
        "  # pick the lengths of the noise spans and the non-noise spans\r\n",
        "  def _random_segmentation(num_items, num_segments, seed):\r\n",
        "    \"\"\"Partition a sequence of items randomly into non-empty segments.\r\n",
        "    Args:\r\n",
        "      num_items: an integer scalar > 0\r\n",
        "      num_segments: an integer scalar in [1, num_items]\r\n",
        "      seed: an integer seed\r\n",
        "    Returns:\r\n",
        "      a Tensor with shape [num_segments] containing positive integers that add\r\n",
        "      up to num_items\r\n",
        "    \"\"\"\r\n",
        "    first_in_segment = tf.pad(\r\n",
        "        seqio.stateless_shuffle(\r\n",
        "            to_int(tf.range(num_items - 1) < num_segments - 1),\r\n",
        "            seed),\r\n",
        "        [[1, 0]])\r\n",
        "    segment_id = tf.cumsum(first_in_segment)\r\n",
        "    segment_length = tf.math.segment_sum(tf.ones_like(segment_id), segment_id)\r\n",
        "    return segment_length\r\n",
        "  noise_span_lengths = _random_segmentation(\r\n",
        "      num_noise_tokens, num_noise_spans, seeds[0])\r\n",
        "  nonnoise_span_lengths = _random_segmentation(\r\n",
        "      num_nonnoise_tokens, num_noise_spans, seeds[1])\r\n",
        "  interleaved_span_lengths = tf.reshape(\r\n",
        "      tf.stack([nonnoise_span_lengths, noise_span_lengths], axis=1),\r\n",
        "      [num_noise_spans * 2])\r\n",
        "  span_starts = tf.cumsum(interleaved_span_lengths)[:-1]\r\n",
        "  span_start_indicator = tf.math.unsorted_segment_sum(\r\n",
        "      tf.ones_like(span_starts), span_starts, length)\r\n",
        "  span_num = tf.cumsum(span_start_indicator)\r\n",
        "  is_noise = tf.equal(span_num % 2, 1)\r\n",
        "  return is_noise[:orig_length]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0eb628f1fdf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrandom_spans_noise_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m def random_spans_noise_mask(length,\n",
            "\u001b[0;32m<ipython-input-23-39a1c430c254>\u001b[0m in \u001b[0;36mrandom_spans_noise_mask\u001b[0;34m(length, noise_density, seeds, mean_noise_span_length)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msegment_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   noise_span_lengths = _random_segmentation(\n\u001b[0;32m---> 62\u001b[0;31m       num_noise_tokens, num_noise_spans, seeds[0])\n\u001b[0m\u001b[1;32m     63\u001b[0m   nonnoise_span_lengths = _random_segmentation(\n\u001b[1;32m     64\u001b[0m       num_nonnoise_tokens, num_noise_spans, seeds[1])\n",
            "\u001b[0;32m<ipython-input-23-39a1c430c254>\u001b[0m in \u001b[0;36m_random_segmentation\u001b[0;34m(num_items, num_segments, seed)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \"\"\"\n\u001b[1;32m     53\u001b[0m     first_in_segment = tf.pad(\n\u001b[0;32m---> 54\u001b[0;31m         seqio.stateless_shuffle(\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mto_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_items\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_segments\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             seed),\n",
            "\u001b[0;31mNameError\u001b[0m: name 'seqio' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeg78qFkLySY"
      },
      "source": [
        "### Alternative Masking ###\r\n",
        "\r\n",
        "def racha_detection(lista):\r\n",
        "    # It returns a list of lists where each sub-list contains the consecutive tokens in the list\r\n",
        "    rachas = []\r\n",
        "    racha = []\r\n",
        "    for i, element in enumerate(lista):\r\n",
        "        if (i<len(lista)-1) and (lista[i+1] == element+1):\r\n",
        "            racha.append(element)\r\n",
        "        else:\r\n",
        "            if len(racha)>0:\r\n",
        "                rachas.append(racha + [element])          \r\n",
        "            else:# (i!=len(lista)-1):\r\n",
        "                rachas.append([element])\r\n",
        "            racha = []\r\n",
        "    return rachas\r\n",
        "\r\n",
        "def masking(tokenized_sentence, rachas):\r\n",
        "    # Function to mask a tokenized_sentence (token ids) following the rachas described in rachas\r\n",
        "    # Only one sentinel_token per racha\r\n",
        "    sent_token_id = 0\r\n",
        "    enmascared = tokenized_sentence.copy()\r\n",
        "    for racha in rachas:\r\n",
        "        sent_token = f'<extra_id_{sent_token_id}>'\r\n",
        "        sent_id = tokenizer.tokenize(sent_token)[0]\r\n",
        "        for i, idx in enumerate(racha):\r\n",
        "            if i==0:\r\n",
        "                enmascared[idx] = sent_id\r\n",
        "            else:\r\n",
        "                enmascared[idx] = -100\r\n",
        "        sent_token_id += 1\r\n",
        "        \r\n",
        "    enmascared = [t for t in enmascared if t!=-100] \r\n",
        "\r\n",
        "    return enmascared\r\n",
        "\r\n",
        "def add_noise(sentence, tokenizer=tokenizer, percent=0.15):\r\n",
        "    # Function that takes a sentence, tokenizer and a noise percentage and returns\r\n",
        "    # the masked input_ids and masked target_ids accordling with the T5 paper and HuggingFace docs\r\n",
        "    # To see the process working uncomment all the prints ;)\r\n",
        "    #sentence = sentence['text']\r\n",
        "\r\n",
        "\r\n",
        "    tokenized_sentence = tokenizer.tokenize(sentence)\r\n",
        "    #print('PRE-MASKED:')\r\n",
        "    #print('INPUT: {}'.format(tokenizer.convert_ids_to_tokens(tokenized_sentence)))\r\n",
        "   \r\n",
        "    idxs_2_mask = sorted(random.sample(range(len(tokenized_sentence)), \r\n",
        "                                       int(len(tokenized_sentence)*percent)))\r\n",
        "    rachas = racha_detection(idxs_2_mask)\r\n",
        "    enmascared_input = masking(tokenized_sentence, rachas)\r\n",
        "    #print('RACHAS INPUT: {}'.format(rachas))\r\n",
        "    idxs_2_mask = [idx for idx in range(len(tokenized_sentence)) if idx not in idxs_2_mask]\r\n",
        "    rachas = racha_detection(idxs_2_mask)\r\n",
        "    enmascared_target = masking(tokenized_sentence, rachas)\r\n",
        "    #print('RACHAS TARGET: {}'.format(rachas))\r\n",
        "    \r\n",
        "    #print('POST-MASKED:')\r\n",
        "    #print('INPUT: {}'.format(tokenizer.convert_ids_to_tokens(enmascared_input)))\r\n",
        "    #print('TARGET: {}'.format(tokenizer.convert_ids_to_tokens(enmascared_target)))\r\n",
        "\r\n",
        "\r\n",
        "    #decoder_inputs = enmascared_target\r\n",
        "    encoder_inputs = tokenizer.tokenize('<pad>') + enmascared_input\r\n",
        "    decoder_inputs = tokenizer.tokenize('<pad>') + enmascared_target\r\n",
        "    decoder_labels = enmascared_target + tokenizer.tokenize('</s>')\r\n",
        "\r\n",
        "    print(\"INPUT: {}\".format(encoder_inputs))\r\n",
        "    print(\"INPUT_DE: {}\".format(decoder_inputs))\r\n",
        "    print(\"TARGET: {}\".format(decoder_labels))\r\n",
        "\r\n",
        "    \r\n",
        "\r\n",
        "    return enmascared_input, decoder_inputs, enmascared_target"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbXPBjfCLcW9"
      },
      "source": [
        "### Alternative Masking ###\r\n",
        "\r\n",
        "def racha_detection(lista):\r\n",
        "    # It returns a list of lists where each sub-list contains the consecutive tokens in the list\r\n",
        "    rachas = []\r\n",
        "    racha = []\r\n",
        "    for i, element in enumerate(lista):\r\n",
        "        if (i<len(lista)-1) and (lista[i+1] == element+1):\r\n",
        "            racha.append(element)\r\n",
        "        else:\r\n",
        "            if len(racha)>0:\r\n",
        "                rachas.append(racha + [element])          \r\n",
        "            else:# (i!=len(lista)-1):\r\n",
        "                rachas.append([element])\r\n",
        "            racha = []\r\n",
        "    return rachas\r\n",
        "\r\n",
        "def masking(tokenized_sentence, rachas):\r\n",
        "    # Function to mask a tokenized_sentence (token ids) following the rachas described in rachas\r\n",
        "    # Only one sentinel_token per racha\r\n",
        "    sent_token_id = 0\r\n",
        "    enmascared = tokenized_sentence.copy()\r\n",
        "    for racha in rachas:\r\n",
        "        sent_token = f'<extra_id_{sent_token_id}>'\r\n",
        "        sent_id = tokenizer.tokenize(sent_token)[0]\r\n",
        "        for i, idx in enumerate(racha):\r\n",
        "            if i==0:\r\n",
        "                enmascared[idx] = sent_id\r\n",
        "            else:\r\n",
        "                enmascared[idx] = -100\r\n",
        "        sent_token_id += 1\r\n",
        "        \r\n",
        "    enmascared = [t for t in enmascared if t!=-100] \r\n",
        "\r\n",
        "    return enmascared\r\n",
        "\r\n",
        "def add_noise(sentence, tokenizer=tokenizer, percent=0.15):\r\n",
        "    # Function that takes a sentence, tokenizer and a noise percentage and returns\r\n",
        "    # the masked input_ids and masked target_ids accordling with the T5 paper and HuggingFace docs\r\n",
        "    # To see the process working uncomment all the prints ;)\r\n",
        "    sentence = sentence['text']\r\n",
        "\r\n",
        "\r\n",
        "    tokenized_sentence = tokenizer.tokenize(sentence)\r\n",
        "    #print('PRE-MASKED:')\r\n",
        "    #print('INPUT: {}'.format(tokenizer.convert_ids_to_tokens(tokenized_sentence)))\r\n",
        "   \r\n",
        "    idxs_2_mask = sorted(random.sample(range(len(tokenized_sentence)), \r\n",
        "                                       int(len(tokenized_sentence)*percent)))\r\n",
        "    rachas = racha_detection(idxs_2_mask)\r\n",
        "    enmascared_input = masking(tokenized_sentence, rachas)\r\n",
        "    #print('RACHAS INPUT: {}'.format(rachas))\r\n",
        "    idxs_2_mask = [idx for idx in range(len(tokenized_sentence)) if idx not in idxs_2_mask]\r\n",
        "    rachas = racha_detection(idxs_2_mask)\r\n",
        "    enmascared_target = masking(tokenized_sentence, rachas)\r\n",
        "    #print('RACHAS TARGET: {}'.format(rachas))\r\n",
        "    \r\n",
        "    #print('POST-MASKED:')\r\n",
        "    #print('INPUT: {}'.format(tokenizer.convert_ids_to_tokens(enmascared_input)))\r\n",
        "    #print('TARGET: {}'.format(tokenizer.convert_ids_to_tokens(enmascared_target)))\r\n",
        "\r\n",
        "\r\n",
        "    decoder_inputs = enmascared_target[:-1]\r\n",
        "    decoder_inputs = tokenizer.tokenize('<pad>')[:-1] + decoder_inputs\r\n",
        "    #print('TARGET: {}'.format(tokenizer.convert_ids_to_tokens(decoder_input_ids)))\r\n",
        "\r\n",
        "\r\n",
        "    # Turn into tensors\r\n",
        "    encoder_inputs = tokenizer(enmascared_input, truncation=True, is_split_into_words=True,\r\n",
        "                          return_tensors='tf', padding=\"max_length\", max_length=encoder_max_len)\r\n",
        "        \r\n",
        "    decoder_labels = tokenizer(enmascared_target, truncation=True, is_split_into_words=True,\r\n",
        "                               return_tensors='tf', padding=\"max_length\", max_length=decoder_max_len)\r\n",
        "\r\n",
        "    decoder_inputs = tokenizer(decoder_inputs, truncation=True, add_special_tokens=False, is_split_into_words=True,\r\n",
        "                               return_tensors='tf', padding=\"max_length\", max_length=decoder_max_len)\r\n",
        "    \r\n",
        "    \r\n",
        "    #print('INPUT_E: {}'.format(tokenizer.convert_ids_to_tokens(encoder_inputs['input_ids'][0])))\r\n",
        "    #print('INPUT_D: {}'.format(tokenizer.convert_ids_to_tokens(decoder_inputs['input_ids'][0])))\r\n",
        "    #print('TARGET: {}'.format(tokenizer.convert_ids_to_tokens(decoder_labels['input_ids'][0])))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    outputs = {'input_ids': encoder_inputs['input_ids'][0], 'attention_mask': encoder_inputs['attention_mask'][0], \r\n",
        "               'decoder_input_ids': decoder_inputs['input_ids'][0], 'decoder_attention_mask': decoder_inputs['attention_mask'][0],\r\n",
        "               'decoder_labels': decoder_labels['input_ids'][0]}\r\n",
        "\r\n",
        "    return outputs\r\n",
        "\r\n",
        "    #return enmascared_input, enmascared_target"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}