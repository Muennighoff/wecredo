{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wecredo_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "493-x_0pforT",
        "3Zv4DpQtcikU",
        "vEO6-D2Pc2M7",
        "aC6c0nZobngy",
        "sNFDzmw3WaYn"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d349cafdc9564a61bd62d57226d517d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2147c6fa136e4431a6837260ce589c85",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c02cd65134b14152a43a080543c6fdb1",
              "IPY_MODEL_98773889934647208d99984a520bec0f"
            ]
          }
        },
        "2147c6fa136e4431a6837260ce589c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c02cd65134b14152a43a080543c6fdb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f768bfd4d5dd451ea41e2eba846d9880",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1895,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1895,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a578ed747ff04c93959ef07690547165"
          }
        },
        "98773889934647208d99984a520bec0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c36f913c6af441d897e7af69d90b761",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.06k/? [00:02&lt;00:00, 2.26kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32854d79d91b4766a2f534e166c885f0"
          }
        },
        "f768bfd4d5dd451ea41e2eba846d9880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a578ed747ff04c93959ef07690547165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c36f913c6af441d897e7af69d90b761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32854d79d91b4766a2f534e166c885f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4732cd877e3646e5994595b93d75b169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4e74d478da334a79be802333ad6c993d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dac39ed74f02478db9741f8919cfba40",
              "IPY_MODEL_b16cb67eb3604d30ae62ad1877b470b4"
            ]
          }
        },
        "4e74d478da334a79be802333ad6c993d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dac39ed74f02478db9741f8919cfba40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_362100c89ac74e9589e01f13ff956680",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 955,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 955,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_628f5eeedd924fa4a76775dc1f8fa3a7"
          }
        },
        "b16cb67eb3604d30ae62ad1877b470b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19826dc2b1504ac0b8c2c9992c6c21e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.19k/? [00:00&lt;00:00, 7.07kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3c4111fb9354d5da3a96b88ae9f5b1a"
          }
        },
        "362100c89ac74e9589e01f13ff956680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "628f5eeedd924fa4a76775dc1f8fa3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19826dc2b1504ac0b8c2c9992c6c21e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3c4111fb9354d5da3a96b88ae9f5b1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee4e97f33a1340f797ad7b111ab508eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fda41f9326f4ac5bf08bac70010ba7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e245c2b2ee8f4622bdfcaa61d9667ad7",
              "IPY_MODEL_d6944a8284e84ffe8d8cfefbae01dd9b"
            ]
          }
        },
        "4fda41f9326f4ac5bf08bac70010ba7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e245c2b2ee8f4622bdfcaa61d9667ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_17dcff13ebb8475a8f3b33077d7f97b6",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 8116577,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8116577,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74493f40aaa94ccd92f4a0a99952eca2"
          }
        },
        "d6944a8284e84ffe8d8cfefbae01dd9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b956bb5c0584520aa6b389b89b7ea5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 30.3M/? [00:01&lt;00:00, 28.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e731257bab654e29980e2b874c0b90bb"
          }
        },
        "17dcff13ebb8475a8f3b33077d7f97b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74493f40aaa94ccd92f4a0a99952eca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b956bb5c0584520aa6b389b89b7ea5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e731257bab654e29980e2b874c0b90bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afca0cc0f1894171a01bfce7ff390e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_00c08088c48e40cfa3ac21bc78c06afc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6834d27858624693bac9b893cca40972",
              "IPY_MODEL_eef453e549164eeba42399cbef955be1"
            ]
          }
        },
        "00c08088c48e40cfa3ac21bc78c06afc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6834d27858624693bac9b893cca40972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cd91d9f83fd74d10aff4209e336e873d",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1054280,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1054280,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6a7532ed5634b80963dfc2be8a2db8b"
          }
        },
        "eef453e549164eeba42399cbef955be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31cf780ab92f466bbc29f6218891a286",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.85M/? [00:00&lt;00:00, 20.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95ed31fb7ec94cfcaabbf8edfad458ca"
          }
        },
        "cd91d9f83fd74d10aff4209e336e873d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6a7532ed5634b80963dfc2be8a2db8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31cf780ab92f466bbc29f6218891a286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95ed31fb7ec94cfcaabbf8edfad458ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2662d66fb7094f57bec7f1d88f8104c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e2a718305e3247e180fc71ec1dbf805e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_28d3fa1eb76c48bd99838c3703c399c6",
              "IPY_MODEL_651fa87f73ce48e5a358955e7decc6f5"
            ]
          }
        },
        "e2a718305e3247e180fc71ec1dbf805e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28d3fa1eb76c48bd99838c3703c399c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bb61eb2f8eee4d2bbd901b4543249530",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7d14f36e33349278ad23b606855f286"
          }
        },
        "651fa87f73ce48e5a358955e7decc6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_48a61b5d27f4458b81c3fe2031a36c82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87599/0 [00:04&lt;00:00, 19969.00 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59f825c807ad4c959df8fdf6f4326a31"
          }
        },
        "bb61eb2f8eee4d2bbd901b4543249530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7d14f36e33349278ad23b606855f286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48a61b5d27f4458b81c3fe2031a36c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59f825c807ad4c959df8fdf6f4326a31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f7c36528a0747d9ac56bec88d277c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fbbfb6de81b44efaac08f8ba8094f694",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_df49d99f98354ffcafa93de08683b84d",
              "IPY_MODEL_d134d3dfedaf43359ff8bb0d80d88325"
            ]
          }
        },
        "fbbfb6de81b44efaac08f8ba8094f694": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df49d99f98354ffcafa93de08683b84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc9296d5aacc47e0b458070eff5f4eea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ea09dd56e744b63b34e3f70a378eb07"
          }
        },
        "d134d3dfedaf43359ff8bb0d80d88325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_34847a2abf0e4120b842dc15dd9902b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10570/0 [00:00&lt;00:00, 12522.25 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85960756492f427d96a23c74fcf50521"
          }
        },
        "fc9296d5aacc47e0b458070eff5f4eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ea09dd56e744b63b34e3f70a378eb07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34847a2abf0e4120b842dc15dd9902b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85960756492f427d96a23c74fcf50521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2d7849c4d754d68a4f17d4cedc332ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3d78d5b5ef3e4a6d94738bee94265380",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c9f95f1d335c4fea8fe2416c779554d6",
              "IPY_MODEL_55c86d2c8fc44851b07e3f802826c280"
            ]
          }
        },
        "3d78d5b5ef3e4a6d94738bee94265380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9f95f1d335c4fea8fe2416c779554d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c27bc661bd69401e9a5a643b4169af0b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12ebeec87b2d41c0abcf4ef0f91dcbd0"
          }
        },
        "55c86d2c8fc44851b07e3f802826c280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f4ddfce6216459584b558acbb88303d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:01&lt;00:00, 1.02kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a8da64c4f5a4292bde70424ccc55e7e"
          }
        },
        "c27bc661bd69401e9a5a643b4169af0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12ebeec87b2d41c0abcf4ef0f91dcbd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f4ddfce6216459584b558acbb88303d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a8da64c4f5a4292bde70424ccc55e7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05552c5606fa4844b453214286c18697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f4b22a9b3feb48d89685a3ce0fd055a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e8528a23cafe4aefba66b79964b78c5c",
              "IPY_MODEL_194cb8a0b2724788a6bdb2efead26fc6"
            ]
          }
        },
        "f4b22a9b3feb48d89685a3ce0fd055a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8528a23cafe4aefba66b79964b78c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ef0dc1f68f74affa53d8e96d0a2b512",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 791656,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 791656,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef6ac2bfa9334d18b9b026de14f1eaf2"
          }
        },
        "194cb8a0b2724788a6bdb2efead26fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d5bdff9486241acb1e94421c78b8095",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 792k/792k [00:06&lt;00:00, 115kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfb584bc6df548e78649214e7f62cb7b"
          }
        },
        "6ef0dc1f68f74affa53d8e96d0a2b512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef6ac2bfa9334d18b9b026de14f1eaf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d5bdff9486241acb1e94421c78b8095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfb584bc6df548e78649214e7f62cb7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "035bba5759604cb88a6b828efdf160bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd1635dbcf9b40b98aab044449815221",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_05f7ee11fd164d50918b70638c51b043",
              "IPY_MODEL_c600fe708b92409aa53bc1e86cad3c76"
            ]
          }
        },
        "bd1635dbcf9b40b98aab044449815221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05f7ee11fd164d50918b70638c51b043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e5a8a126f9b344eda9fa1db2d588b5ca",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1389353,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1389353,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3066e0e7591e43e68a99ba86ab3f085e"
          }
        },
        "c600fe708b92409aa53bc1e86cad3c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad00110a11cb453096d105a17a47b394",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.39M/1.39M [00:04&lt;00:00, 297kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3aa3e13c7eb441c1922d7cb67f2374ba"
          }
        },
        "e5a8a126f9b344eda9fa1db2d588b5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3066e0e7591e43e68a99ba86ab3f085e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad00110a11cb453096d105a17a47b394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3aa3e13c7eb441c1922d7cb67f2374ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40fd2c0f1567494eb584a63e967625d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2806e87606424414ba1a0a07178bd8bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_456d12fd32864979bbfaf1e6535a3cfa",
              "IPY_MODEL_488fe59d1b4e4840ba751b6904b26431"
            ]
          }
        },
        "2806e87606424414ba1a0a07178bd8bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "456d12fd32864979bbfaf1e6535a3cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2941bff632bc48db9d76820d78f32521",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87599,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87599,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77927fda54e34bcaa84880025352e60d"
          }
        },
        "488fe59d1b4e4840ba751b6904b26431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4098f0bc6d78442492d31126557d8ce7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87599/87599 [02:37&lt;00:00, 557.36ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b31204e8315439fa48d346bf7adfe6a"
          }
        },
        "2941bff632bc48db9d76820d78f32521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77927fda54e34bcaa84880025352e60d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4098f0bc6d78442492d31126557d8ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b31204e8315439fa48d346bf7adfe6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b97144df16094af1b818efbb0d2a4ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_25607cdc4bb843fca966c1338c95d2b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c0374b8e5c1b46f8ba09b3ccdd5c80db",
              "IPY_MODEL_70f417f68fea4872b8cdb0931aba03f9"
            ]
          }
        },
        "25607cdc4bb843fca966c1338c95d2b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0374b8e5c1b46f8ba09b3ccdd5c80db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc2150bcff41412da0c7afd8dd258c00",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5789ca7bd1e45ef89f293f888559cf6"
          }
        },
        "70f417f68fea4872b8cdb0931aba03f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e1a7140fa6c44564b2fe11814a9f57d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10570/10570 [00:29&lt;00:00, 358.31ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e8054d1158f4cfea892364f08356f68"
          }
        },
        "fc2150bcff41412da0c7afd8dd258c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5789ca7bd1e45ef89f293f888559cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1a7140fa6c44564b2fe11814a9f57d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e8054d1158f4cfea892364f08356f68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed86387380db4aea8915ca54179a23ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1962fdbf0824421cb0f767f38f5d059a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c03ee417e1b542dd896c08d056545844",
              "IPY_MODEL_a2b49e8e6de346c295a78c8b3d362baf"
            ]
          }
        },
        "1962fdbf0824421cb0f767f38f5d059a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c03ee417e1b542dd896c08d056545844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_684ae3ea7476426db388e9f1cef76bad",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87599,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87599,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d317f72ae72249d28d57e2f6054e8293"
          }
        },
        "a2b49e8e6de346c295a78c8b3d362baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_084503371a69430b9783e0ff475077fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87599/87599 [02:40&lt;00:00, 545.00ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85951c8bc035400e85b0c37cf9e82fa0"
          }
        },
        "684ae3ea7476426db388e9f1cef76bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d317f72ae72249d28d57e2f6054e8293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "084503371a69430b9783e0ff475077fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85951c8bc035400e85b0c37cf9e82fa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "775c1de7785a45edb63b2921ffea885a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e9f4f47f883a4e8dba62d29e2c363af0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d63261256d8343efb645c2595a515750",
              "IPY_MODEL_57661f04b9184465aa7a0806e2690660"
            ]
          }
        },
        "e9f4f47f883a4e8dba62d29e2c363af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d63261256d8343efb645c2595a515750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d9aa36a456c244a8ab2827e2342aaa52",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fee77f4427bb4751ba953ce75f98d09b"
          }
        },
        "57661f04b9184465aa7a0806e2690660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7163cb66940043f89f77191f596e6ce1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10570/10570 [01:20&lt;00:00, 131.56ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d22d6344c5440ffb587f37de3c0bfc7"
          }
        },
        "d9aa36a456c244a8ab2827e2342aaa52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fee77f4427bb4751ba953ce75f98d09b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7163cb66940043f89f77191f596e6ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d22d6344c5440ffb587f37de3c0bfc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcf8c1cd5e444edca20ded67aa2188f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec116f6156c1451a83dc5a818bf76758",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c6a520240b084b5e96af201dd93cd963",
              "IPY_MODEL_6c079d76ea8b4c008661ce3d83685fc1"
            ]
          }
        },
        "ec116f6156c1451a83dc5a818bf76758": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6a520240b084b5e96af201dd93cd963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71c7998a8ead4eb897fcc11c01ff2e3b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c6b4d0278f39446790d8012dbf7fbd75"
          }
        },
        "6c079d76ea8b4c008661ce3d83685fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74e05134f523405698f488d1f10ddb75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7000/7000 [00:39&lt;00:00, 177.48ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d40b9a5c44847fdaf06f4e6c24a3e92"
          }
        },
        "71c7998a8ead4eb897fcc11c01ff2e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c6b4d0278f39446790d8012dbf7fbd75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74e05134f523405698f488d1f10ddb75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d40b9a5c44847fdaf06f4e6c24a3e92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38f62227a71343e5959d30a6eac62459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_72db4b475b4240358eefe3af273a1142",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f9f6efaa94ab4519b38c15f4eb9dd29e",
              "IPY_MODEL_a909d8cd2d654850b6c923ac09f89aa8"
            ]
          }
        },
        "72db4b475b4240358eefe3af273a1142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9f6efaa94ab4519b38c15f4eb9dd29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3b1f9e511c3a4bc08d24dc9b600df23a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f29dd0abf4e48a0b9432ec1c9d13a2a"
          }
        },
        "a909d8cd2d654850b6c923ac09f89aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b8c12108a4264d9fa652c9631c158190",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [00:29&lt;00:00, 33.83ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bee6fb1276a43c585775275796d2b34"
          }
        },
        "3b1f9e511c3a4bc08d24dc9b600df23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f29dd0abf4e48a0b9432ec1c9d13a2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8c12108a4264d9fa652c9631c158190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bee6fb1276a43c585775275796d2b34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZoTzIBUcfq5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "493-x_0pforT"
      },
      "source": [
        "### Structure\r\n",
        "\r\n",
        "Implements a model for large-scale CN NLP training.\r\n",
        "\r\n",
        "In the Main Model section the models architecture is built. Whenever changes in the architecture are made the Experiments are used to validate them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FISZI4tOXiWv",
        "outputId": "cf3ec258-19a3-4f5c-df6a-a6e038501793"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "tf_version = tf.__version__\r\n",
        "print(\"Tensorflow: \", tf_version)\r\n",
        "\r\n",
        "tf_version_split = tf_version.split('.')\r\n",
        "assert int(tf_version_split[0])==2 and int(tf_version_split[-2])>=4, f\"Tensorflow version should be '2.4+,x', given {tf_version}\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow:  2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zv4DpQtcikU"
      },
      "source": [
        "### Main Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOlnegDBbNqh"
      },
      "source": [
        "#### WIP - DATA PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgEmRgUSZBUR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDEqA2mHZ3UD"
      },
      "source": [
        "#### WIP - Model Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIAchjJUt26P",
        "outputId": "b90b9690-04d2-473a-a9c2-79d5bca14ad8"
      },
      "source": [
        "# TODO: Remove dependency on performer repo?\r\n",
        "!git clone https://github.com/xl402/performer.git\r\n",
        "\r\n",
        "import os\r\n",
        "import sys\r\n",
        "module_path = os.path.abspath(os.path.join('./performer'))\r\n",
        "if module_path not in sys.path:\r\n",
        "    sys.path.append(module_path)\r\n",
        "\r\n",
        "from performer.networks.linear_attention import Performer   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'performer'...\n",
            "remote: Enumerating objects: 182, done.\u001b[K\n",
            "remote: Counting objects: 100% (182/182), done.\u001b[K\n",
            "remote: Compressing objects: 100% (111/111), done.\u001b[K\n",
            "remote: Total 691 (delta 64), reused 148 (delta 37), pack-reused 509\u001b[K\n",
            "Receiving objects: 100% (691/691), 691.80 KiB | 453.00 KiB/s, done.\n",
            "Resolving deltas: 100% (340/340), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYM-w202XUGf"
      },
      "source": [
        "\"\"\" Default Model Config \"\"\"\r\n",
        "\r\n",
        "conf = {\r\n",
        "        \"vocab_size\": 32128,\r\n",
        "        \"num_layers\": 6,\r\n",
        "        \"attention\": \r\n",
        "        .... \r\n",
        "        d_model=512,\r\n",
        "        d_kv=64,\r\n",
        "        d_ff=2048,\r\n",
        "        num_layers=6,\r\n",
        "        num_decoder_layers=None,\r\n",
        "        num_heads=8,\r\n",
        "        relative_attention_num_buckets=32,\r\n",
        "        dropout_rate=0.1,\r\n",
        "        layer_norm_epsilon=1e-6,\r\n",
        "        initializer_factor=1.0,\r\n",
        "        feed_forward_proj=\"relu\",\r\n",
        "        is_encoder_decoder=True,\r\n",
        "        use_cache=True,\r\n",
        "        pad_token_id=0,\r\n",
        "        eos_token_id=1,\r\n",
        "        **kwargs\r\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucYTZFREPGUj"
      },
      "source": [
        "\"\"\" Helper Functions for Model Architecture \"\"\"\r\n",
        "\r\n",
        "def gelu_new(x):\r\n",
        "    \"\"\"\r\n",
        "    Gaussian Error Linear Unit. This is a smoother version of the GELU. Original paper: https://arxiv.org/abs/1606.0841\r\n",
        "    Args:\r\n",
        "        x: float Tensor to perform activation\r\n",
        "    Returns:\r\n",
        "        `x` with the GELU activation applied.\r\n",
        "    \"\"\"\r\n",
        "    x = tf.convert_to_tensor(x)\r\n",
        "    pi = tf.cast(math.pi, x.dtype)\r\n",
        "    coeff = tf.cast(0.044715, x.dtype)\r\n",
        "    cdf = 0.5 * (1.0 + tf.tanh(tf.sqrt(2.0 / pi) * (x + coeff * tf.pow(x, 3))))\r\n",
        "\r\n",
        "    return x * cdf\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUAma2nL8A1q"
      },
      "source": [
        "\"\"\" Wecredo Model Architecture for Large-Scale CN NLP Training \"\"\"\r\n",
        "\r\n",
        "####################################################\r\n",
        "# TF 2.0 Model  constructed using Keras imperative API by sub-classing\r\n",
        "# - tf.keras.layers.Layer for the layers\r\n",
        "# - tf.keras.Model for the final model\r\n",
        "####################################################\r\n",
        "\r\n",
        "class T5LayerNorm(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, epsilon=1e-6, **kwargs):\r\n",
        "        \"\"\"\r\n",
        "        Construct a layernorm module in the T5 style No bias and no subtraction of mean.\r\n",
        "        \"\"\"\r\n",
        "        super().__init__(**kwargs)\r\n",
        "        self.variance_epsilon = epsilon\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        \"\"\"Build shared word embedding layer \"\"\"\r\n",
        "        self.weight = self.add_weight(\"weight\", shape=(input_shape[-1],), initializer=\"ones\")\r\n",
        "        super().build(input_shape)\r\n",
        "\r\n",
        "    def call(self, hidden_states):\r\n",
        "        variance = tf.math.reduce_mean(tf.math.square(hidden_states), axis=-1, keepdims=True)\r\n",
        "        hidden_states = hidden_states * tf.math.rsqrt(variance + self.variance_epsilon)\r\n",
        "        return self.weight * hidden_states\r\n",
        "\r\n",
        "# TODO - Define default config? // Remove config calls?\r\n",
        "class T5DenseReluDense(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        \"\"\"\r\n",
        "        Constructs a Relu Feed-Forward Layer. This is the default FF in T5. \r\n",
        "        \"\"\"\r\n",
        "        super().__init__(**kwargs)\r\n",
        "        self.wi = tf.keras.layers.Dense(config.d_ff, use_bias=False, name=\"wi\")\r\n",
        "        self.wo = tf.keras.layers.Dense(config.d_model, use_bias=False, name=\"wo\")\r\n",
        "        self.dropout = tf.keras.layers.Dropout(config.dropout_rate)\r\n",
        "        self.act = tf.keras.activations.relu\r\n",
        "\r\n",
        "    def call(self, hidden_states, training=False):\r\n",
        "        hidden_states = self.wi(hidden_states)\r\n",
        "        hidden_states = self.act(hidden_states)\r\n",
        "        hidden_states = self.dropout(hidden_states, training=training)\r\n",
        "        hidden_states = self.wo(hidden_states)\r\n",
        "        return hidden_states\r\n",
        "\r\n",
        "        \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "3AE55OukZ0yy",
        "outputId": "23cd0adb-d8e3-4bc1-ad7d-3330225926d3"
      },
      "source": [
        "import mesh_tensorflow as mtf\r\n",
        "import tensorflow.compat.v1 as tf\r\n",
        "import math\r\n",
        "import mesh_tensorflow.transformer as mtf_transformer\r\n",
        "import random\r\n",
        "from models.utils import parse_inputs, entmax_cross_entropy_with_logits\r\n",
        "\r\n",
        "# --------------------------------------------------------------------------------\r\n",
        "# LAYERS:\r\n",
        "\r\n",
        "sentinel = object()\r\n",
        "\r\n",
        "\r\n",
        "def exists(x):\r\n",
        "    return x is not None\r\n",
        "\r\n",
        "\r\n",
        "def identity(x, *args, **kwargs):\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "def is_incremental_inference(context):\r\n",
        "    return exists(context) and context.mode == \"incremental\"\r\n",
        "\r\n",
        "\r\n",
        "def norm(x, axis, epsilon=1e-8):\r\n",
        "    x -= mtf.reduce_mean(x, reduced_dim=axis, name=\"norm_reduce_mean_u\")\r\n",
        "    s = mtf.reduce_mean(mtf.square(x), reduced_dim=axis, name=\"norm_reduce_mean_s\")\r\n",
        "    return x * mtf.rsqrt(s + epsilon)\r\n",
        "\r\n",
        "\r\n",
        "# ReZero implementation\r\n",
        "def rezero(x, scope, dtype):\r\n",
        "    with tf.variable_scope(scope):\r\n",
        "        g = mtf.get_variable(x.mesh, \"g\", [], initializer=tf.constant_initializer(0), dtype=dtype)\r\n",
        "        return x * g\r\n",
        "\r\n",
        "\r\n",
        "def scale_norm(x, scope, *, variable_dtype, axis=sentinel, epsilon=1e-5, params=None):\r\n",
        "    if axis is sentinel:\r\n",
        "        axis = x.shape[-1]\r\n",
        "\r\n",
        "    with tf.variable_scope(scope):\r\n",
        "        g = mtf.get_variable(x.mesh, \"g\", [], initializer=tf.constant_initializer(1),\r\n",
        "                             master_dtype=variable_dtype.master_dtype,\r\n",
        "                             slice_dtype=variable_dtype.slice_dtype,\r\n",
        "                             activation_dtype=variable_dtype.activation_dtype)\r\n",
        "\r\n",
        "        x = norm(x, axis, epsilon)\r\n",
        "        x = x * g\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "def layer_norm(x, scope, *, variable_dtype, axis=sentinel, epsilon=1e-5, params=None):\r\n",
        "    \"\"\"Normalize to mean = 0, std = 1, then do a diagonal affine transform.\"\"\"\r\n",
        "    if axis is sentinel:\r\n",
        "        axis = x.shape[-1]\r\n",
        "\r\n",
        "    with tf.variable_scope(scope):\r\n",
        "        n_state = x.shape[-1]\r\n",
        "\r\n",
        "        g = mtf.get_variable(x.mesh, \"g\", [n_state], initializer=tf.constant_initializer(1),\r\n",
        "                             master_dtype=variable_dtype.master_dtype,\r\n",
        "                             slice_dtype=variable_dtype.slice_dtype,\r\n",
        "                             activation_dtype=variable_dtype.activation_dtype)\r\n",
        "        b = mtf.get_variable(x.mesh, \"b\", [n_state], initializer=tf.constant_initializer(0),\r\n",
        "                             master_dtype=variable_dtype.master_dtype,\r\n",
        "                             slice_dtype=variable_dtype.slice_dtype,\r\n",
        "                             activation_dtype=variable_dtype.activation_dtype)\r\n",
        "\r\n",
        "        x = norm(x, axis, epsilon)\r\n",
        "        x = x * g + b\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "### INTEGRATE PERFORMER ATTENTION ###\r\n",
        "def linear_attention(q, k, v):\r\n",
        "    batch_dim, seq_dim, head_dim, dim_out = (v.shape[0], v.shape[1], v.shape[2], v.shape[3])\r\n",
        "    q = mtf.rename_dimension(q, \"features_per_head\", \"features_per_head_in\")\r\n",
        "    k = mtf.rename_dimension(k, \"features_per_head\", \"features_per_head_in\")\r\n",
        "\r\n",
        "    dim_in = k.shape[-1]\r\n",
        "\r\n",
        "    q = mtf.softmax(q, dim_in)\r\n",
        "    k = mtf.softmax(k, seq_dim)\r\n",
        "\r\n",
        "    context = mtf.einsum([k, v], output_shape=[batch_dim, head_dim, dim_in, dim_out])\r\n",
        "    attn = mtf.einsum([q, context], output_shape=[batch_dim, seq_dim, head_dim, dim_out])\r\n",
        "    return attn\r\n",
        "\r\n",
        "\r\n",
        "def causal_linear_attention(q, k, v, epsilon=1e-6):\r\n",
        "    batch_dim, seq_dim, head_dim, dim_out = (v.shape[0], v.shape[1], v.shape[2], v.shape[3])\r\n",
        "    q = mtf.rename_dimension(q, \"features_per_head\", \"features_per_head_in\")\r\n",
        "    k = mtf.rename_dimension(k, \"features_per_head\", \"features_per_head_in\")\r\n",
        "\r\n",
        "    dim_in = k.shape[-1]\r\n",
        "\r\n",
        "    q = mtf.softmax(q, dim_in)\r\n",
        "    k = mtf.exp(k)\r\n",
        "\r\n",
        "    cumulative_k = mtf.cumsum(k, seq_dim)\r\n",
        "    context = mtf.einsum([k, v], output_shape=[batch_dim, seq_dim, head_dim, dim_in, dim_out])\r\n",
        "    cumulative_context = mtf.cumsum(context, seq_dim)\r\n",
        "\r\n",
        "    cumulative_context /= (cumulative_k + epsilon)\r\n",
        "    attn = mtf.einsum([q, cumulative_context], output_shape=[batch_dim, seq_dim, head_dim, dim_out])\r\n",
        "    return attn\r\n",
        "\r\n",
        "\r\n",
        "def linear(x, scope, nf, *, w_init_stdev=0.02, variable_dtype, params=None, scale=False):\r\n",
        "    # nf = number of features\r\n",
        "    if params[\"scale_by_depth\"] and scale:\r\n",
        "        # Scale by sqrt(num_layers), only happens at the final projection before a res block output\r\n",
        "        w_init_stdev = w_init_stdev * (1. / math.sqrt(params[\"n_layer\"]))\r\n",
        "    if params[\"scale_by_in\"]:  # Scale by sqrt(num_input_features)\r\n",
        "        w_init_stdev = w_init_stdev * (1. / math.sqrt(x.shape[-1].size))  # Dimension is a namedtuple of (name, size)\r\n",
        "    # Not in the variable_scope because mtf already has a variable_scope in it\r\n",
        "    with tf.variable_scope(\"conv1d_main\"):\r\n",
        "        c = mtf.layers.dense(x, new_dims=[nf], reduced_dims=[x.shape[-1]], name=scope, use_bias=True,\r\n",
        "                             kernel_initializer=tf.random_normal_initializer(stddev=w_init_stdev),\r\n",
        "                             variable_dtype=variable_dtype,\r\n",
        "                             )\r\n",
        "        return c\r\n",
        "\r\n",
        "\r\n",
        "def memory_key_values(k, v, num_mem_kv, dim_batch, dim_heads, variable_dtype, mesh):\r\n",
        "    \"\"\"memory / key values from all attention paper\"\"\"\r\n",
        "\r\n",
        "    dim_mem_kv = mtf.Dimension(\"mem_kv_sequence\", num_mem_kv)\r\n",
        "    emb_dim = k.shape[-1]\r\n",
        "    mem_std = 1 / math.sqrt(emb_dim.size)\r\n",
        "\r\n",
        "    mem_k = mtf.get_variable(mesh, \"mem_k\", mtf.Shape([dim_mem_kv, dim_heads, emb_dim]),\r\n",
        "                             initializer=tf.random_normal_initializer(stddev=mem_std),\r\n",
        "                             master_dtype=variable_dtype.master_dtype,\r\n",
        "                             slice_dtype=variable_dtype.slice_dtype,\r\n",
        "                             activation_dtype=variable_dtype.activation_dtype,\r\n",
        "                             )\r\n",
        "    mem_v = mtf.get_variable(mesh, \"mem_v\", mtf.Shape([dim_mem_kv, dim_heads, emb_dim]),\r\n",
        "                             initializer=tf.random_normal_initializer(stddev=mem_std),\r\n",
        "                             master_dtype=variable_dtype.master_dtype,\r\n",
        "                             slice_dtype=variable_dtype.slice_dtype,\r\n",
        "                             activation_dtype=variable_dtype.activation_dtype)\r\n",
        "\r\n",
        "    mem_k, mem_v = map(lambda t: mtf.broadcast(t, [dim_batch, dim_mem_kv, dim_heads, emb_dim]),\r\n",
        "                       (mem_k, mem_v))\r\n",
        "    mem_k, mem_v = map(lambda t: mtf.rename_dimension(t, \"mem_kv_sequence\", \"sequence\"),\r\n",
        "                       (mem_k, mem_v))\r\n",
        "\r\n",
        "    k = mtf.concat([mem_k, k], \"sequence\")\r\n",
        "    v = mtf.concat([mem_v, v], \"sequence\")\r\n",
        "    return k, v\r\n",
        "\r\n",
        "\r\n",
        "def attn(x, scope, n_state, *, attention_type, params, bias, dim_seq, memory_length_dim, variable_dtype, context=None):\r\n",
        "    # x :: [batch, seq, n_embd]\r\n",
        "    x_shape, dim_batch, *_, dim_embd, mesh = x.shape, *x.shape, x.mesh\r\n",
        "\r\n",
        "    # n_state is the same as config[\"n_embd\"], which is also the same as dim_embd.\r\n",
        "    assert n_state.size % params[\"n_head\"] == 0\r\n",
        "\r\n",
        "    dim_heads = mtf.Dimension(\"heads\", params[\"n_head\"])\r\n",
        "\r\n",
        "    num_mem_kv = params.get(\"num_mem_kv\", 0)\r\n",
        "    use_num_mem_kv = num_mem_kv > 0\r\n",
        "\r\n",
        "    with tf.variable_scope(scope):\r\n",
        "        # Compute attention inputs\r\n",
        "        dim_kv = mtf.Dimension(\"features_per_head\", params[\"n_embd\"] // params[\"n_head\"])\r\n",
        "        mtfparams = mtf.transformer.attention.attention_params_simple(\r\n",
        "            x.mesh,\r\n",
        "            io_dim=dim_embd,\r\n",
        "            kv_dim=dim_kv,\r\n",
        "            heads_dim=dim_heads,\r\n",
        "            variable_dtype=variable_dtype\r\n",
        "        )\r\n",
        "        q = mtfparams.compute_q(x)\r\n",
        "        k = mtfparams.compute_k(x)\r\n",
        "        v = mtfparams.compute_v(x)\r\n",
        "\r\n",
        "        if is_incremental_inference(context):\r\n",
        "            one_hot = mtf.one_hot(context.position - 1, dim_seq, dtype=variable_dtype.master_dtype)\r\n",
        "            inv_one_hot = 1.0 - one_hot\r\n",
        "            old_k, old_v = context.get_states(2)\r\n",
        "            k = old_k * inv_one_hot + k * one_hot\r\n",
        "            v = old_v * inv_one_hot + v * one_hot\r\n",
        "\r\n",
        "        if exists(context):\r\n",
        "            context.record_new_states([k, v])\r\n",
        "\r\n",
        "        with tf.variable_scope(\"attention\"):\r\n",
        "            if attention_type == \"local\":\r\n",
        "                # `local_attention_1d` has built in autoregressive masking, so we don't need mask_attn_weights.\r\n",
        "                radius = params.get(\"local_attention_radius\", 256)\r\n",
        "\r\n",
        "                if is_incremental_inference(context):\r\n",
        "                    q *= one_hot\r\n",
        "\r\n",
        "                a = mtf_transformer.attention.local_attention_1d(\r\n",
        "                    q, k, v,\r\n",
        "                    length_dim=k.shape[1],\r\n",
        "                    key_dim=dim_kv,\r\n",
        "                    value_dim=dim_kv,\r\n",
        "                    radius=radius,\r\n",
        "                    length_dim_num_splits=1,\r\n",
        "                    fully_autoregressive=params[\"causal\"],\r\n",
        "                    attention_kwargs={},\r\n",
        "                )\r\n",
        "\r\n",
        "                if is_incremental_inference(context):\r\n",
        "                    a = mtf.gather(a, context.position - 1, dim_seq)\r\n",
        "\r\n",
        "            elif attention_type == \"global\":\r\n",
        "\r\n",
        "                # TODO: pass in fake context\r\n",
        "                # Broadcast mask bias across batch and heads\r\n",
        "                if exists(bias):\r\n",
        "                    if not is_incremental_inference(context):\r\n",
        "                        broadcasted_bias = mtf.broadcast(bias, [dim_batch, dim_heads, bias.shape[-2], bias.shape[-1]])\r\n",
        "                    else:\r\n",
        "                        # In the incremental case, a custom mask needs to be built that masks out all key/values that are greater than the current position\r\n",
        "                        bias = mtf.gather(bias, context.position - 1, dim_seq)\r\n",
        "                        broadcasted_bias = mtf.broadcast(bias, [dim_batch, dim_heads, bias.shape[-1]])\r\n",
        "\r\n",
        "                # memory key / values, from all-attention paper\r\n",
        "                if use_num_mem_kv:\r\n",
        "                    k, v = memory_key_values(k, v, num_mem_kv, dim_batch, dim_heads, variable_dtype, mesh)\r\n",
        "\r\n",
        "                k = mtf.replace_dimensions(k, k.shape[1], memory_length_dim)\r\n",
        "                v = mtf.replace_dimensions(v, v.shape[1], memory_length_dim)\r\n",
        "\r\n",
        "                attn_dropout_rate = params[\"attn_dropout\"] if params[\"mode\"] == \"train\" else 0\r\n",
        "\r\n",
        "                a = mtf_transformer.attention.attention(\r\n",
        "                    q, k, v,\r\n",
        "                    memory_length_dim=memory_length_dim,\r\n",
        "                    key_dim=dim_kv,\r\n",
        "                    value_dim=dim_kv,\r\n",
        "                    bias=broadcasted_bias,\r\n",
        "                    dropout_rate=attn_dropout_rate\r\n",
        "                )\r\n",
        "\r\n",
        "            elif attention_type == \"linear\":\r\n",
        "                linear_attn_fn = causal_linear_attention if params[\"causal\"] else linear_attention\r\n",
        "                a = linear_attn_fn(q, k, v)\r\n",
        "\r\n",
        "            else:\r\n",
        "                raise NotImplementedError(\"Unknown attention type {}!\".format(attention_type))\r\n",
        "\r\n",
        "        with tf.variable_scope(\"compute_output\"):\r\n",
        "            a = mtfparams.compute_output(a, x_shape)\r\n",
        "\r\n",
        "        with tf.variable_scope(\"compute_output_bias\"):\r\n",
        "            b = mtf.get_variable(x.mesh, \"o_b\", [dim_embd], initializer=tf.constant_initializer(0),\r\n",
        "                                 master_dtype=variable_dtype.master_dtype,\r\n",
        "                                 slice_dtype=variable_dtype.slice_dtype,\r\n",
        "                                 activation_dtype=variable_dtype.activation_dtype)\r\n",
        "            a += b\r\n",
        "\r\n",
        "        if params[\"mode\"] == \"train\" and params[\"res_dropout\"] > 0:\r\n",
        "            a = mtf.dropout(a, rate=params[\"res_dropout\"], name=\"res_dropout\")\r\n",
        "        return a\r\n",
        "\r\n",
        "\r\n",
        "def get_activation_fn(params):\r\n",
        "    activation_fn = params.get(\"activation_fn\", \"gelu\")\r\n",
        "    \r\n",
        "\r\n",
        "    def _arcsinh(x):\r\n",
        "        return mtf.log(x + mtf.sqrt(1 + x ** 2))\r\n",
        "    def _var(x, init):\r\n",
        "        return mtf.get_variable(x.mesh, f\"activation-{random.randint(0, 2**32):x}\", [], initializer=tf.constant_initializer(init), dtype=x.dtype)\r\n",
        "    def _pos_var(x, val):\r\n",
        "        return mtf.softplus(_var(x, 0)) + val\r\n",
        "    \r\n",
        "    if activation_fn == \"gelu\": # https://arxiv.org/abs/1606.08415\r\n",
        "        return mtf.gelu\r\n",
        "    elif activation_fn == \"relu\":\r\n",
        "        return mtf.relu\r\n",
        "    elif activation_fn == \"sigmoid\":\r\n",
        "        return mtf.sigmoid\r\n",
        "    elif activation_fn == \"tanh\":\r\n",
        "        return mtf.tanh\r\n",
        "    elif activation_fn == \"selu\": # https://arxiv.org/abs/1706.02515\r\n",
        "        return mtf.selu\r\n",
        "    elif activation_fn == \"elu\": # https://arxiv.org/abs/1511.07289\r\n",
        "        return mtf.elu\r\n",
        "    elif activation_fn == \"lrelu001\":\r\n",
        "        return lambda x: mtf.leaky_relu(x, alpha=0.01)\r\n",
        "    elif activation_fn == \"lrelu020\":\r\n",
        "        return lambda x: mtf.leaky_relu(x, alpha=0.20)\r\n",
        "\r\n",
        "    elif activation_fn == \"abs\": \r\n",
        "        return mtf.abs\r\n",
        "    elif activation_fn == \"id\":\r\n",
        "        return lambda x: x\r\n",
        "    elif activation_fn == \"sin\":\r\n",
        "        return mtf.sin\r\n",
        "    elif activation_fn == \"cos\":\r\n",
        "        return mtf.cos\r\n",
        "    elif activation_fn == \"sign\":\r\n",
        "        return mtf.sign\r\n",
        "    elif activation_fn == \"triangle_relax\":\r\n",
        "        return lambda x: mtf.sin(x)-mtf.sin(3*x)/9+mtf.sin(5*x)/25-mtf.sin(7*x)/49\r\n",
        "    elif activation_fn == \"square_relax\":\r\n",
        "        return lambda x: mtf.cos(x)-mtf.cos(3*x)/3+mtf.cos(5*x)/5-mtf.cos(7*x)/7\r\n",
        "    elif activation_fn == \"spike\":\r\n",
        "        return lambda x: 1/(1+x**2)\r\n",
        "    elif activation_fn == \"spike2\":\r\n",
        "        return lambda x: mtf.exp(-x**2)\r\n",
        "    \r\n",
        "    elif activation_fn == \"tanhshrink\":\r\n",
        "        return lambda x: x - tanh(x)\r\n",
        "    elif activation_fn == \"softsign\":\r\n",
        "        return lambda x: x / (mtf.abs(x) + 1)\r\n",
        "    elif activation_fn == \"softmax\":\r\n",
        "        return lambda x: mtf.softmax(x, x.shape[-1])\r\n",
        "    elif activation_fn == \"logsoftmax\":\r\n",
        "        return lambda x: mtf.log_softmax(x, x.shape[-1])\r\n",
        "    elif activation_fn == \"bipolarsigmoid\":\r\n",
        "        return lambda x: mtf.sigmoid(x) * 2 - 1\r\n",
        "    elif activation_fn == \"rrelu\":  # https://arxiv.org/abs/1505.00853\r\n",
        "        def _rrelu_fn(x):\r\n",
        "            negative_scale = random.random()\r\n",
        "            return (negative_scale * mtf.abs(x) + x) / (1 + negative_scale)\r\n",
        "        return _rrelu_fn\r\n",
        "    elif activation_fn == \"elish\":  # https://arxiv.org/abs/1808.00783v1\r\n",
        "        def _elish_fn(x):\r\n",
        "            cond = mtf.cast(mtf.greater(x, 0), x.dtype)\r\n",
        "            exp = mtf.exp(x)\r\n",
        "            return cond * x / (1 + exp) + (1 - cond) * (exp - 1) / (1 / exp + 1)\r\n",
        "        return _elish_fn\r\n",
        "    \r\n",
        "    elif activation_fn == \"silu\": # https://arxiv.org/abs/1710.05941\r\n",
        "        return mtf.swish\r\n",
        "    \r\n",
        "    elif activation_fn == \"arcsinh\":\r\n",
        "        return _arcsinh\r\n",
        "    \r\n",
        "    \r\n",
        "    # parametric\r\n",
        "    elif activation_fn == \"aria\":  # https://arxiv.org/abs/1805.08878\r\n",
        "        return lambda x: x * (_var(x, 0) + _var(x, 1) / (_pos_var(x, 0) + _var(x, 1) * mtf.exp(_var(x, -1) * x) ** (1 / _pos_var(x, 1))))\r\n",
        "    elif activation_fn == \"prelu\":  # https://arxiv.org/abs/1502.01852\r\n",
        "        return lambda x: mtf.leaky_relu(x, alpha=_var(x, 0.2))\r\n",
        "    elif activation_fn == \"parcsinh\":\r\n",
        "        return lambda x: _var(x, 1) * _arcsinh(x * _pos_var(x, 1))\r\n",
        "    elif activation_fn == \"psoftplus\":\r\n",
        "        return lambda x: _var(x, 1) * mtf.softplus(x * _var(x, 1)) + _var(x, 0)\r\n",
        "    elif activation_fn == \"proottanh\":\r\n",
        "        return lambda x: (x ** _pos_var(x, 2) + _pos_var(x, 1)) ** (1 / _pos_var(x, 3)) * mtf.tanh(x)\r\n",
        "     \r\n",
        "    # https://arxiv.org/abs/1710.05941, https://arxiv.org/abs/1901.02671\r\n",
        "    elif activation_fn == \"maxsig\": \r\n",
        "        return lambda x: mtf.maximum(x, mtf.sigmoid(x))\r\n",
        "    elif activation_fn == \"cosid\": \r\n",
        "        return lambda x: mtf.cos(x) - x\r\n",
        "    elif activation_fn == \"minsin\": \r\n",
        "        return lambda x: mtf.minimum(x, mtf.sin(x))\r\n",
        "    elif activation_fn == \"maxtanh\": \r\n",
        "        return lambda x: mtf.maximum(x, mtf.tanh(x))\r\n",
        "    \r\n",
        "    elif activation_fn == \"softplus\":\r\n",
        "        return mtf.softplus\r\n",
        "    elif activation_fn == \"mish\": # https://arxiv.org/abs/1908.08681\r\n",
        "        return lambda x: x * mtf.tanh(mtf.softplus(x))\r\n",
        "    elif activation_fn == \"tanhexp\": # https://arxiv.org/abs/2003.09855\r\n",
        "        return lambda x: x * mtf.tanh(mtf.exp(x))\r\n",
        "    elif activation_fn == \"lisht\": # https://arxiv.org/abs/1901.05894\r\n",
        "        return lambda x: x * mtf.tanh(x)\r\n",
        "    elif activation_fn == \"seagull\": # https://arxiv.org/abs/2011.11713\r\n",
        "        return lambda x: mtf.log(1 + x ** 2)\r\n",
        "    elif activation_fn == \"snake\": # https://arxiv.org/abs/2006.08195\r\n",
        "        return lambda x: x + mtf.sin(x) ** 2\r\n",
        "    \r\n",
        "    elif activation_fn == \"roottanh\":  # made up\r\n",
        "        return lambda x: (x ** 2 + 1) ** (1/3) * mtf.tanh(x)\r\n",
        "    elif activation_fn == \"softplusmone\":  # made up\r\n",
        "        return lambda x: mtf.softplus(x) - 1\r\n",
        "    \r\n",
        "    else:\r\n",
        "        raise ValueError('unknown activation function \"activation_fn\" in config')\r\n",
        "\r\n",
        "def mlp(x, scope, n_state, *, variable_dtype, params):\r\n",
        "    activation_fn = get_activation_fn(params)\r\n",
        "    with tf.variable_scope(scope):\r\n",
        "        nx = x.shape[-1]\r\n",
        "        h = activation_fn(linear(x, \"c_fc\", n_state, variable_dtype=variable_dtype, params=params))\r\n",
        "        h2 = linear(h, \"c_proj\", nx, variable_dtype=variable_dtype, params=params, scale=True)\r\n",
        "        if params[\"mode\"] == \"train\" and params[\"res_dropout\"] > 0:\r\n",
        "            h2 = mtf.dropout(h2, rate=params[\"res_dropout\"], name=\"mlp_dropout\")\r\n",
        "        return h2\r\n",
        "\r\n",
        "\r\n",
        "def mlp_glu(x, scope, n_state, *, variable_dtype, params):\r\n",
        "    activation_fn = get_activation_fn(params)\r\n",
        "    with tf.variable_scope(scope):\r\n",
        "        nx = x.shape[-1]\r\n",
        "        h = linear(x, \"c_fc\", n_state, params=params)\r\n",
        "\r\n",
        "        h, gate = mtf.split(h, h.shape[-1], 2)\r\n",
        "        h *= activation_fn(gate)\r\n",
        "\r\n",
        "        h2 = linear(h, \"c_proj\", nx, variable_dtype=variable_dtype, params=params, scale=True)\r\n",
        "        if params[\"mode\"] == \"train\" and params[\"res_dropout\"] > 0:\r\n",
        "            h2 = mtf.dropout(h2, rate=params[\"res_dropout\"], name=\"mlp_dropout\")\r\n",
        "        return h2\r\n",
        "\r\n",
        "\r\n",
        "def block(params, scope, layer_num, bias, sequence_dim, memory_length_dim, variable_dtype, context=None):\r\n",
        "    use_mlp_glu = params[\"mlp_glu\"] == True\r\n",
        "    use_scale_norm = params[\"scalenorm\"] == True\r\n",
        "    use_moe = exists(params[\"moe_layers\"]) and (layer_num in params[\"moe_layers\"])\r\n",
        "    use_rezero = params[\"rezero\"] == True\r\n",
        "    macaron_attention = params[\"macaron\"] == True\r\n",
        "\r\n",
        "    def fn(x):\r\n",
        "        with tf.variable_scope(scope):\r\n",
        "            nx = x.shape[-1]  # Grab last dimension from input\r\n",
        "\r\n",
        "            if use_rezero:\r\n",
        "                prenorm = identity\r\n",
        "            elif use_scale_norm:\r\n",
        "                prenorm = scale_norm\r\n",
        "            else:\r\n",
        "                prenorm = layer_norm\r\n",
        "\r\n",
        "            pre_residual_fn = rezero if use_rezero else identity\r\n",
        "\r\n",
        "            attention_type = params[\"attention_types\"][layer_num]\r\n",
        "            \r\n",
        "            if macaron_attention:\r\n",
        "                mult = 0.5\r\n",
        "                mlp_fn = mlp_glu if use_mlp_glu else mlp\r\n",
        "                intermediate_size = nx.size * 4 * (1 if not use_mlp_glu else 2)\r\n",
        "                # Define intermediate layer of mlp - to split\r\n",
        "                dim_intermediate_expanded = mtf.Dimension(\"intermediate_expanded\", intermediate_size)\r\n",
        "                m = mlp_fn(x, \"mlp_macaron\", dim_intermediate_expanded, variable_dtype=variable_dtype, params=params)\r\n",
        "                \r\n",
        "                x = x + (m * mult)\r\n",
        "            else:\r\n",
        "                mult = 1\r\n",
        "\r\n",
        "            if attention_type != \"none\":\r\n",
        "                res_x = prenorm(x, \"norm_1\", variable_dtype=variable_dtype, params=params)\r\n",
        "                a = attn(res_x, \"attn\", nx, attention_type=attention_type,\r\n",
        "                         params=params, bias=bias, dim_seq=sequence_dim, memory_length_dim=memory_length_dim,\r\n",
        "                         variable_dtype=variable_dtype, context=context)\r\n",
        "            else:\r\n",
        "                a = x\r\n",
        "\r\n",
        "            x = x + pre_residual_fn(a, \"norm_rezero_1\", dtype=variable_dtype)\r\n",
        "\r\n",
        "            res_x = prenorm(x, \"norm_2\", variable_dtype=variable_dtype, params=params)\r\n",
        "\r\n",
        "            if use_moe:\r\n",
        "                moe_params = mtf.transformer.moe.HParams()\r\n",
        "                mtf.transformer.moe.set_default_moe_hparams(moe_params)\r\n",
        "                moe_params.add_hparam(\"moe_min_expert_capacity\", 1)\r\n",
        "                moe_params.add_hparam(\"moe_use_experts_attention\", False)\r\n",
        "\r\n",
        "                # Override defaults\r\n",
        "                for k, v in params[\"moe_params\"].items():\r\n",
        "                    moe_params.add_hparam(k, v)\r\n",
        "\r\n",
        "                moe_train = params[\"mode\"] == \"train\"\r\n",
        "\r\n",
        "                m, aux_loss = mtf.transformer.moe.transformer_moe_layer_v1(res_x, x.shape[-1], moe_params,\r\n",
        "                                                                           train=moe_train,\r\n",
        "                                                                           mesh_shape=params[\"mesh_shape\"],\r\n",
        "                                                                           layout=params[\"layout\"],\r\n",
        "                                                                           activation=params.get(\"moe_activation\", \"relu\"),\r\n",
        "                                                                           variable_dtype=variable_dtype,\r\n",
        "                                                                           num_microbatches=params[\"num_microbatches\"])\r\n",
        "                m = mtf.dropout(m, rate=params[\"res_dropout\"], name=\"moe_dropout\")\r\n",
        "            else:\r\n",
        "\r\n",
        "                mlp_fn = mlp_glu if use_mlp_glu else mlp\r\n",
        "                intermediate_size = nx.size * 4 * (1 if not use_mlp_glu else 2)\r\n",
        "\r\n",
        "                # Define intermediate layer of mlp - to split\r\n",
        "                dim_intermediate_expanded = mtf.Dimension(\"intermediate_expanded\", intermediate_size)\r\n",
        "\r\n",
        "                m = mlp_fn(res_x, \"mlp\", dim_intermediate_expanded, variable_dtype=variable_dtype, params=params)\r\n",
        "                aux_loss = mtf.zeros(x.mesh, mtf.Shape([]), dtype=variable_dtype.slice_dtype)\r\n",
        "\r\n",
        "            x = x + pre_residual_fn((m*mult), \"norm_rezero_2\", variable_dtype)\r\n",
        "            return x, aux_loss\r\n",
        "\r\n",
        "    return fn\r\n",
        "\r\n",
        "\r\n",
        "def axial_positional_emb(embd_dim, mesh, params, variable_dtype):\r\n",
        "    # Use axial position encoding\r\n",
        "    axial_dim_1, axial_dim_2 = params[\"axial_pos_emb\"]\r\n",
        "\r\n",
        "    axial_dim = mtf.Dimension(\"axial_dim\", axial_dim_1 * axial_dim_2)\r\n",
        "    dim_axials = [mtf.Dimension(f\"axial_dim_{i}\", t) for i, t in enumerate((axial_dim_1, axial_dim_2))]\r\n",
        "\r\n",
        "    axial_wpe_1 = mtf.get_variable(mesh, \"axial_wpe_1\", mtf.Shape([dim_axials[0], embd_dim]),\r\n",
        "                                   initializer=tf.random_normal_initializer(stddev=0.01),\r\n",
        "                                   master_dtype=variable_dtype.master_dtype,\r\n",
        "                                   slice_dtype=variable_dtype.slice_dtype,\r\n",
        "                                   activation_dtype=variable_dtype.activation_dtype)\r\n",
        "\r\n",
        "    axial_wpe_2 = mtf.get_variable(mesh, \"axial_wpe_2\", mtf.Shape([dim_axials[1], embd_dim]),\r\n",
        "                                   initializer=tf.random_normal_initializer(stddev=0.01),\r\n",
        "                                   master_dtype=variable_dtype.master_dtype,\r\n",
        "                                   slice_dtype=variable_dtype.slice_dtype,\r\n",
        "                                   activation_dtype=variable_dtype.activation_dtype)\r\n",
        "\r\n",
        "    axial_wpe_1, axial_wpe_2 = map(lambda t: mtf.broadcast(t, [dim_axials[0], dim_axials[1], embd_dim]),\r\n",
        "                                   (axial_wpe_1, axial_wpe_2))\r\n",
        "    wpe = (axial_wpe_1 + axial_wpe_2) / 2\r\n",
        "\r\n",
        "    wpe = mtf.reshape(wpe, [axial_dim, embd_dim])\r\n",
        "\r\n",
        "    return wpe\r\n",
        "\r\n",
        "# --------------------------------------------------------------------------------\r\n",
        "# MODEL:\r\n",
        "\r\n",
        "def model(mtf_features, other_features, params, mesh, variable_dtype, context=None):\r\n",
        "    \"\"\"Wecredo_Model implemented in mesh tensorflow.\"\"\"\r\n",
        "\r\n",
        "    x, batch_dim, sequence_dim, embd_dim, vocab_dim, embed_sequence_dim = parse_inputs(mtf_features, other_features)\r\n",
        "\r\n",
        "    if is_incremental_inference(context):\r\n",
        "        # reshape inputs if in inference mode\r\n",
        "        x = mtf.gather(x, context.position - 1, sequence_dim)\r\n",
        "        x = mtf.reshape(x, [batch_dim])\r\n",
        "\r\n",
        "    use_axial_pos_emb = params[\"axial_pos_emb\"] is not None\r\n",
        "\r\n",
        "    if not use_axial_pos_emb:\r\n",
        "        # Use standard position encoding\r\n",
        "        wpe = mtf.get_variable(mesh, \"wpe\", mtf.Shape([embed_sequence_dim, embd_dim]),\r\n",
        "                               initializer=tf.random_normal_initializer(stddev=0.01),\r\n",
        "                               master_dtype=variable_dtype.master_dtype,\r\n",
        "                               slice_dtype=variable_dtype.slice_dtype,\r\n",
        "                               activation_dtype=variable_dtype.activation_dtype)\r\n",
        "    else:\r\n",
        "        wpe = axial_positional_emb(embd_dim, mesh, params, variable_dtype)\r\n",
        "\r\n",
        "    # Text encoding\r\n",
        "    wte = mtf.get_variable(mesh, \"wte\", mtf.Shape([vocab_dim, embd_dim]),\r\n",
        "                           initializer=tf.random_normal_initializer(stddev=0.02),\r\n",
        "                           master_dtype=variable_dtype.master_dtype,\r\n",
        "                           slice_dtype=variable_dtype.slice_dtype,\r\n",
        "                           activation_dtype=variable_dtype.activation_dtype)\r\n",
        "\r\n",
        "    with tf.variable_scope(\"token_embd\"):\r\n",
        "        # Text embedding\r\n",
        "        h = mtf.gather(wte, x, vocab_dim)\r\n",
        "        if params[\"embed_dropout\"] > 0 and params[\"mode\"] == \"train\":\r\n",
        "            h = mtf.dropout(h, rate=params[\"embed_dropout\"], name=\"wte_dropout\")\r\n",
        "\r\n",
        "    with tf.variable_scope(\"pos_embd\"):\r\n",
        "        # Positional embedding\r\n",
        "        position_indices = mtf.range(mesh, sequence_dim, tf.int64) if not is_incremental_inference(context) else (\r\n",
        "                context.position - 1)\r\n",
        "        pos_emb = mtf.gather(wpe, position_indices, wpe.shape[0])\r\n",
        "        if params[\"embed_dropout\"] > 0 and params[\"mode\"] == \"train\":\r\n",
        "            pos_emb = mtf.dropout(pos_emb, rate=params[\"embed_dropout\"], name=\"wte_dropout\")\r\n",
        "        h += pos_emb\r\n",
        "\r\n",
        "    aux_losses = 0  # instantiate auxiliary losses (for MOE models)\r\n",
        "\r\n",
        "    for layer in range(params[\"n_layer\"]):\r\n",
        "        # attn blocks\r\n",
        "        share_parameters = exists(params[\"share_parameters\"]) and params[\"share_parameters\"] == True\r\n",
        "        block_scope = f\"h{layer}\" if not share_parameters else \"\"\r\n",
        "\r\n",
        "        block_fn = block(params=params, scope=block_scope, layer_num=layer,\r\n",
        "                         bias=other_features[\"attn_bias\"],\r\n",
        "                         sequence_dim=sequence_dim,\r\n",
        "                         memory_length_dim=other_features[\"memory_length_dim\"],\r\n",
        "                         variable_dtype=variable_dtype,\r\n",
        "                         context=context)\r\n",
        "\r\n",
        "        # If true and in train mode, enable gradient checkpointing\r\n",
        "        recompute_grad = params[\"recompute_grad\"] and (params[\"mode\"] == \"train\") == True\r\n",
        "        h, loss = block_fn(h) if not recompute_grad else mtf.recompute_grad(block_fn, [h])\r\n",
        "        aux_losses += loss\r\n",
        "\r\n",
        "    no_weight_tie_emb = params[\"no_weight_tie\"] == True\r\n",
        "    if no_weight_tie_emb:\r\n",
        "        with tf.variable_scope(\"wte_final_linear\"):\r\n",
        "            logits = linear(h, \"linear_out\", vocab_dim, variable_dtype=variable_dtype, params=params)\r\n",
        "    else:\r\n",
        "        # Layer normalize & affine transform\r\n",
        "        h = layer_norm(h, \"ln_f\", variable_dtype=variable_dtype)\r\n",
        "        seq_dim = sequence_dim if not is_incremental_inference(context) else mtf.Dimension(\"sequence\", 1)\r\n",
        "        with tf.variable_scope(\"wte_final_einsum\"):\r\n",
        "            # Equivalent to tf.matmul\r\n",
        "            logits = mtf.einsum([h, wte], output_shape=[batch_dim, seq_dim, vocab_dim])\r\n",
        "\r\n",
        "    if params[\"mode\"] in [\"train\", \"eval\"]:\r\n",
        "        labels = mtf_features[\"labels\"]\r\n",
        "        z_loss = params.get(\"z_loss\", 1e-4) # an auxiliary loss used to stabilize mtf xentropy\r\n",
        "\r\n",
        "        # Go to full precision for the logits \r\n",
        "        logits = mtf.cast(logits, tf.float32)\r\n",
        "\r\n",
        "        use_entmax_loss = params.get(\"entmax_loss\", False)\r\n",
        "        loss_fn = mtf.layers.softmax_cross_entropy_with_logits if not use_entmax_loss else entmax_cross_entropy_with_logits\r\n",
        "\r\n",
        "        with tf.variable_scope(\"xentropy_final\"):\r\n",
        "            loss_batch = loss_fn(logits=logits, targets=labels,\r\n",
        "                                 vocab_dim=logits.shape[-1], z_loss=z_loss)\r\n",
        "\r\n",
        "        # For non-autoregressive models (masked language modeling training)\r\n",
        "        # Make sure labels with padding tokens are not counted in the loss\r\n",
        "        if not params[\"causal\"]:\r\n",
        "            padding_id = params.get(\"padding_id\", 0)\r\n",
        "            loss_batch = mtf.where(mtf.not_equal(labels, padding_id), loss_batch, mtf.zeros_like(loss_batch))\r\n",
        "\r\n",
        "        with tf.variable_scope(\"reduce_mean_final\"):\r\n",
        "            loss = mtf.reduce_mean(loss_batch)\r\n",
        "\r\n",
        "        loss += aux_losses  # Add on auxiliary losses (currently only used for MoE)\r\n",
        "        loss /= params[\"num_microbatches\"]\r\n",
        "        # Convert to train dtype\r\n",
        "        loss = mtf.cast(loss, variable_dtype.slice_dtype)\r\n",
        "    else:\r\n",
        "        loss = None\r\n",
        "        loss_batch = None\r\n",
        "\r\n",
        "    # Cast back to checkpoint dtype\r\n",
        "    logits = mtf.cast(logits, variable_dtype.master_dtype)\r\n",
        "    return logits, loss, loss_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6da1f4f0ae9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmesh_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmesh_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmtf_transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mesh_tensorflow'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDMXjYnwbUJo"
      },
      "source": [
        "#### WIP - CONFIGURING THE MODEL & TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KehXHGzvbZAz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrPZyZmB8wsk"
      },
      "source": [
        "---\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvxOXQLbpokZ"
      },
      "source": [
        "### Experiments \r\n",
        "\r\n",
        "Experiments to test the current implementation. Whenever changes are made to the main model architecture make sure it:\r\n",
        "- Works in eager execution\r\n",
        "- Works in static execution\r\n",
        "- Works on TPU (ideally distributed)\r\n",
        "- Produces acceptable results on some of the below tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsTVnTJeWR1l"
      },
      "source": [
        "#### Question Answering\r\n",
        "\r\n",
        "On SQuAD dataset; Also part of T5 tasks. <br>\r\n",
        "- Modelling - Eager: Ready\r\n",
        "- Modelling - Static: WIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCuaa2BJXat8",
        "outputId": "8a8a0003-e098-455d-b57a-3de5d556b1a9"
      },
      "source": [
        "### Installs ###\r\n",
        "\r\n",
        "!pip install -q datasets\r\n",
        "!pip install -q transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 163kB 5.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 17.7MB 359kB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 56.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 6.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 56.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 56.9MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGL_VHcFnmi7"
      },
      "source": [
        "### Imports ###\r\n",
        "\r\n",
        "import transformers\r\n",
        "import numpy as np\r\n",
        "from datasets import load_dataset\r\n",
        "\r\n",
        "# If import error below, restart session; reinstall transformers\r\n",
        "from transformers import AutoTokenizer, TFT5ForConditionalGeneration"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551,
          "referenced_widgets": [
            "d349cafdc9564a61bd62d57226d517d8",
            "2147c6fa136e4431a6837260ce589c85",
            "c02cd65134b14152a43a080543c6fdb1",
            "98773889934647208d99984a520bec0f",
            "f768bfd4d5dd451ea41e2eba846d9880",
            "a578ed747ff04c93959ef07690547165",
            "3c36f913c6af441d897e7af69d90b761",
            "32854d79d91b4766a2f534e166c885f0",
            "4732cd877e3646e5994595b93d75b169",
            "4e74d478da334a79be802333ad6c993d",
            "dac39ed74f02478db9741f8919cfba40",
            "b16cb67eb3604d30ae62ad1877b470b4",
            "362100c89ac74e9589e01f13ff956680",
            "628f5eeedd924fa4a76775dc1f8fa3a7",
            "19826dc2b1504ac0b8c2c9992c6c21e2",
            "a3c4111fb9354d5da3a96b88ae9f5b1a",
            "ee4e97f33a1340f797ad7b111ab508eb",
            "4fda41f9326f4ac5bf08bac70010ba7d",
            "e245c2b2ee8f4622bdfcaa61d9667ad7",
            "d6944a8284e84ffe8d8cfefbae01dd9b",
            "17dcff13ebb8475a8f3b33077d7f97b6",
            "74493f40aaa94ccd92f4a0a99952eca2",
            "4b956bb5c0584520aa6b389b89b7ea5a",
            "e731257bab654e29980e2b874c0b90bb",
            "afca0cc0f1894171a01bfce7ff390e7e",
            "00c08088c48e40cfa3ac21bc78c06afc",
            "6834d27858624693bac9b893cca40972",
            "eef453e549164eeba42399cbef955be1",
            "cd91d9f83fd74d10aff4209e336e873d",
            "b6a7532ed5634b80963dfc2be8a2db8b",
            "31cf780ab92f466bbc29f6218891a286",
            "95ed31fb7ec94cfcaabbf8edfad458ca",
            "2662d66fb7094f57bec7f1d88f8104c5",
            "e2a718305e3247e180fc71ec1dbf805e",
            "28d3fa1eb76c48bd99838c3703c399c6",
            "651fa87f73ce48e5a358955e7decc6f5",
            "bb61eb2f8eee4d2bbd901b4543249530",
            "b7d14f36e33349278ad23b606855f286",
            "48a61b5d27f4458b81c3fe2031a36c82",
            "59f825c807ad4c959df8fdf6f4326a31",
            "1f7c36528a0747d9ac56bec88d277c48",
            "fbbfb6de81b44efaac08f8ba8094f694",
            "df49d99f98354ffcafa93de08683b84d",
            "d134d3dfedaf43359ff8bb0d80d88325",
            "fc9296d5aacc47e0b458070eff5f4eea",
            "4ea09dd56e744b63b34e3f70a378eb07",
            "34847a2abf0e4120b842dc15dd9902b7",
            "85960756492f427d96a23c74fcf50521",
            "f2d7849c4d754d68a4f17d4cedc332ce",
            "3d78d5b5ef3e4a6d94738bee94265380",
            "c9f95f1d335c4fea8fe2416c779554d6",
            "55c86d2c8fc44851b07e3f802826c280",
            "c27bc661bd69401e9a5a643b4169af0b",
            "12ebeec87b2d41c0abcf4ef0f91dcbd0",
            "9f4ddfce6216459584b558acbb88303d",
            "3a8da64c4f5a4292bde70424ccc55e7e",
            "05552c5606fa4844b453214286c18697",
            "f4b22a9b3feb48d89685a3ce0fd055a8",
            "e8528a23cafe4aefba66b79964b78c5c",
            "194cb8a0b2724788a6bdb2efead26fc6",
            "6ef0dc1f68f74affa53d8e96d0a2b512",
            "ef6ac2bfa9334d18b9b026de14f1eaf2",
            "7d5bdff9486241acb1e94421c78b8095",
            "bfb584bc6df548e78649214e7f62cb7b",
            "035bba5759604cb88a6b828efdf160bf",
            "bd1635dbcf9b40b98aab044449815221",
            "05f7ee11fd164d50918b70638c51b043",
            "c600fe708b92409aa53bc1e86cad3c76",
            "e5a8a126f9b344eda9fa1db2d588b5ca",
            "3066e0e7591e43e68a99ba86ab3f085e",
            "ad00110a11cb453096d105a17a47b394",
            "3aa3e13c7eb441c1922d7cb67f2374ba",
            "40fd2c0f1567494eb584a63e967625d6",
            "2806e87606424414ba1a0a07178bd8bc",
            "456d12fd32864979bbfaf1e6535a3cfa",
            "488fe59d1b4e4840ba751b6904b26431",
            "2941bff632bc48db9d76820d78f32521",
            "77927fda54e34bcaa84880025352e60d",
            "4098f0bc6d78442492d31126557d8ce7",
            "8b31204e8315439fa48d346bf7adfe6a",
            "b97144df16094af1b818efbb0d2a4ff8",
            "25607cdc4bb843fca966c1338c95d2b3",
            "c0374b8e5c1b46f8ba09b3ccdd5c80db",
            "70f417f68fea4872b8cdb0931aba03f9",
            "fc2150bcff41412da0c7afd8dd258c00",
            "b5789ca7bd1e45ef89f293f888559cf6",
            "e1a7140fa6c44564b2fe11814a9f57d7",
            "5e8054d1158f4cfea892364f08356f68"
          ]
        },
        "id": "vDYZPe85aBTm",
        "outputId": "3326ddb8-97af-4316-9647-0202540660ad"
      },
      "source": [
        "### Data ###\r\n",
        "\r\n",
        "# Dict of form: dict_keys(['answers', 'context', 'id', 'question', 'title'])\r\n",
        "train_ds = load_dataset('squad', split='train')\r\n",
        "valid_ds = load_dataset('squad', split='validation')\r\n",
        "\r\n",
        "print(\"Example: \", next(iter(train_ds)))\r\n",
        "\r\n",
        "# Tokenize data to prepare for feeding in model \r\n",
        "# Using huggingface tokenizer for now - We can easily swap this for a CN one lateron\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\r\n",
        "\r\n",
        "encoder_max_len = 250 # 512\r\n",
        "decoder_max_len = 54 # 97\r\n",
        "batch_size = 4\r\n",
        "buffer_size = 1000\r\n",
        "\r\n",
        "ntrain = len(train_ds)\r\n",
        "nvalid = len(valid_ds)\r\n",
        "steps = int(np.ceil(ntrain/batch_size))\r\n",
        "valid_steps = int(np.ceil(nvalid/batch_size))\r\n",
        "\r\n",
        "def tokenize(example):\r\n",
        "    \"\"\"\r\n",
        "    Prepares input example for model\r\n",
        "    eos_token=\"</s>\",\r\n",
        "    unk_token=\"<unk>\",\r\n",
        "    pad_token=\"<pad>\"\r\n",
        "\r\n",
        "    TODOs:\r\n",
        "    - Remove max_len? \r\n",
        "    - In final stage adopt preprocessing from https://github.com/google-research/text-to-text-transfer-transformer/blob/867715664c8393cf12093ea9633f868c0df35548/t5/data/preprocessors.py\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    context = example['context']\r\n",
        "    question = example['question']\r\n",
        "    answer = example['answers']['text'][0] # Sometimes multiple; In T5 only take first\r\n",
        "\r\n",
        "\r\n",
        "    inputs = f\"question: {str(question)} context: {str(context)}\"\r\n",
        "    targets = f\"{str(answer)}\"\r\n",
        "\r\n",
        "    # TODO: Do we need those two diff. input types?\r\n",
        "    encoder_inputs = tokenizer(inputs, truncation=True, \r\n",
        "                              return_tensors='tf', padding=\"max_length\", max_length=encoder_max_len)\r\n",
        "    \r\n",
        "    decoder_inputs = tokenizer(targets, truncation=True, \r\n",
        "                               return_tensors='tf', padding=\"max_length\", max_length=decoder_max_len)\r\n",
        "    \r\n",
        "    outputs = {'input_ids': encoder_inputs['input_ids'][0], 'attention_mask': encoder_inputs['attention_mask'][0], \r\n",
        "               'labels': decoder_inputs['input_ids'][0], 'decoder_attention_mask': decoder_inputs['attention_mask'][0]}\r\n",
        "    return outputs\r\n",
        "\r\n",
        "def to_tf_dataset(dataset): \r\n",
        "  \"\"\"\r\n",
        "  Turns dataset into a TF compatible dataset; TODO: Combine with tokenize?  / Load TF dataset directly by loading Squad from tfds\r\n",
        "  \"\"\" \r\n",
        "  columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\r\n",
        "  dataset.set_format(type='tensorflow', columns=columns)\r\n",
        "  return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \r\n",
        "                'labels':tf.int32, 'decoder_attention_mask':tf.int32,  }\r\n",
        "  return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \r\n",
        "                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None])}\r\n",
        "  ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\r\n",
        "  return ds\r\n",
        "\r\n",
        "\r\n",
        "train_ds = train_ds.map(tokenize)\r\n",
        "valid_ds = valid_ds.map(tokenize)\r\n",
        "\r\n",
        "train_ds = to_tf_dataset(train_ds)\r\n",
        "valid_ds = to_tf_dataset(valid_ds)\r\n",
        "\r\n",
        "train_ds = train_ds.shuffle(buffer_size).batch(batch_size)\r\n",
        "valid_ds = valid_ds.shuffle(buffer_size).batch(batch_size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d349cafdc9564a61bd62d57226d517d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1895.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4732cd877e3646e5994595b93d75b169",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=955.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.75 MiB, post-processed: Unknown size, total: 119.27 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4c81550d83a2ac7c7ce23783bd8ff36642800e6633c1f18417fb58c3ff50cdd7...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee4e97f33a1340f797ad7b111ab508eb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=8116577.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afca0cc0f1894171a01bfce7ff390e7e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1054280.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2662d66fb7094f57bec7f1d88f8104c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f7c36528a0747d9ac56bec88d277c48",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4c81550d83a2ac7c7ce23783bd8ff36642800e6633c1f18417fb58c3ff50cdd7. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4c81550d83a2ac7c7ce23783bd8ff36642800e6633c1f18417fb58c3ff50cdd7)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Example:  {'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']}, 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'id': '5733be284776f41900661182', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'title': 'University_of_Notre_Dame'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2d7849c4d754d68a4f17d4cedc332ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "05552c5606fa4844b453214286c18697",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "035bba5759604cb88a6b828efdf160bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1389353.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40fd2c0f1567494eb584a63e967625d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87599.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b97144df16094af1b818efbb0d2a4ff8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10570.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1YTEl1-MXDW"
      },
      "source": [
        "##### Static - Loss Internal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "ed86387380db4aea8915ca54179a23ab",
            "1962fdbf0824421cb0f767f38f5d059a",
            "c03ee417e1b542dd896c08d056545844",
            "a2b49e8e6de346c295a78c8b3d362baf",
            "684ae3ea7476426db388e9f1cef76bad",
            "d317f72ae72249d28d57e2f6054e8293",
            "084503371a69430b9783e0ff475077fe",
            "85951c8bc035400e85b0c37cf9e82fa0",
            "775c1de7785a45edb63b2921ffea885a",
            "e9f4f47f883a4e8dba62d29e2c363af0",
            "d63261256d8343efb645c2595a515750",
            "57661f04b9184465aa7a0806e2690660",
            "d9aa36a456c244a8ab2827e2342aaa52",
            "fee77f4427bb4751ba953ce75f98d09b",
            "7163cb66940043f89f77191f596e6ce1",
            "7d22d6344c5440ffb587f37de3c0bfc7"
          ]
        },
        "id": "Kt_DXcl_0VMW",
        "outputId": "74af39e6-49e1-4f8d-82b3-50991be0eef4"
      },
      "source": [
        "### Data V2 - Loss Internal ###\r\n",
        "\r\n",
        "# Dict of form: dict_keys(['answers', 'context', 'id', 'question', 'title'])\r\n",
        "train_ds = load_dataset('squad', split='train')\r\n",
        "valid_ds = load_dataset('squad', split='validation')\r\n",
        "\r\n",
        "print(\"Example: \", next(iter(train_ds)))\r\n",
        "\r\n",
        "# Tokenize data to prepare for feeding in model \r\n",
        "# Using huggingface tokenizer for now - We can easily swap this for a CN one lateron\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\r\n",
        "\r\n",
        "encoder_max_len = 250 # 512\r\n",
        "decoder_max_len = 54 # 97\r\n",
        "batch_size = 4\r\n",
        "buffer_size = 1000\r\n",
        "\r\n",
        "ntrain = len(train_ds)\r\n",
        "nvalid = len(valid_ds)\r\n",
        "steps = int(np.ceil(ntrain/batch_size))\r\n",
        "valid_steps = int(np.ceil(nvalid/batch_size))\r\n",
        "\r\n",
        "def tokenize(example):\r\n",
        "    \"\"\"\r\n",
        "    Prepares input example for model\r\n",
        "    eos_token=\"</s>\",\r\n",
        "    unk_token=\"<unk>\",\r\n",
        "    pad_token=\"<pad>\"\r\n",
        "\r\n",
        "    TODOs:\r\n",
        "    - Remove max_len? \r\n",
        "    - In final stage adopt preprocessing from https://github.com/google-research/text-to-text-transfer-transformer/blob/867715664c8393cf12093ea9633f868c0df35548/t5/data/preprocessors.py\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    context = example['context']\r\n",
        "    question = example['question']\r\n",
        "    answer = example['answers']['text'][0] # Sometimes multiple; In T5 only take first\r\n",
        "\r\n",
        "\r\n",
        "    inputs = f\"question: {str(question)} context: {str(context)}\"\r\n",
        "    targets = f\"{str(answer)}\"\r\n",
        "\r\n",
        "    # Encoder Inputs: question: ... context: ... </s>\r\n",
        "    encoder_inputs = tokenizer(inputs, truncation=True, \r\n",
        "                              return_tensors='tf', padding=\"max_length\", max_length=encoder_max_len)\r\n",
        "    \r\n",
        "\r\n",
        "    # Teacher forcing - i.e. labels are dec. inputs shifted\r\n",
        "\r\n",
        "    # Decoder Labels: answer </s>\r\n",
        "    decoder_labels = tokenizer(targets, truncation=True,\r\n",
        "                               return_tensors='tf', padding=\"max_length\", max_length=decoder_max_len)\r\n",
        "\r\n",
        "    # Decoder Inputs: <pad> answer\r\n",
        "    targets = f\"<pad> {str(answer)}\"\r\n",
        "    decoder_inputs = tokenizer(targets, truncation=True, add_special_tokens=False,\r\n",
        "                               return_tensors='tf', padding=\"max_length\", max_length=decoder_max_len)\r\n",
        "    \r\n",
        "\r\n",
        "    outputs = {'input_ids': encoder_inputs['input_ids'][0], 'attention_mask': encoder_inputs['attention_mask'][0], \r\n",
        "               'decoder_input_ids': decoder_inputs['input_ids'][0], 'decoder_attention_mask': decoder_inputs['attention_mask'][0],\r\n",
        "               'decoder_labels': decoder_labels['input_ids'][0]}\r\n",
        "\r\n",
        "    return outputs\r\n",
        "\r\n",
        "def to_tf_dataset(dataset): \r\n",
        "  \"\"\"\r\n",
        "  Turns dataset into a TF compatible dataset; TODO: Combine with tokenize?  / Load TF dataset directly by loading Squad from tfds\r\n",
        "  \"\"\" \r\n",
        "  columns = ['input_ids', 'attention_mask', 'decoder_input_ids', 'decoder_attention_mask', 'decoder_labels']\r\n",
        "  dataset.set_format(type='tensorflow', columns=columns)\r\n",
        "\r\n",
        "  return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \r\n",
        "                'decoder_input_ids':tf.int32, 'decoder_attention_mask':tf.int32, \r\n",
        "                'decoder_labels':tf.int32}\r\n",
        "  return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \r\n",
        "                  'decoder_input_ids': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None]),\r\n",
        "                  'decoder_labels': tf.TensorShape([None])}\r\n",
        "\r\n",
        "  ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\r\n",
        "  return ds\r\n",
        "\r\n",
        "\r\n",
        "train_ds = train_ds.map(tokenize)\r\n",
        "valid_ds = valid_ds.map(tokenize)\r\n",
        "\r\n",
        "train_ds = to_tf_dataset(train_ds)\r\n",
        "valid_ds = to_tf_dataset(valid_ds)\r\n",
        "\r\n",
        "train_ds = train_ds.shuffle(buffer_size).batch(batch_size)\r\n",
        "valid_ds = valid_ds.shuffle(buffer_size).batch(batch_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4c81550d83a2ac7c7ce23783bd8ff36642800e6633c1f18417fb58c3ff50cdd7)\n",
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4c81550d83a2ac7c7ce23783bd8ff36642800e6633c1f18417fb58c3ff50cdd7)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Example:  {'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']}, 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'id': '5733be284776f41900661182', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'title': 'University_of_Notre_Dame'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed86387380db4aea8915ca54179a23ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87599.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "775c1de7785a45edb63b2921ffea885a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10570.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjIb4zDKhM0J"
      },
      "source": [
        "### Modelling - Static ###\r\n",
        "\r\n",
        "class Wrapper(tf.keras.Model):\r\n",
        "    def __init__(self, model, *args, **kwargs):\r\n",
        "        super().__init__(*args, **kwargs)\r\n",
        "        self.model = model\r\n",
        "        # Track loss (Loss itself its CategoricalCrossEnt.)\r\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name='loss') \r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def train_step(self, data):\r\n",
        "        # Data is a dictionary\r\n",
        "        #y = data.pop(\"decoder_labels\", None)\r\n",
        "        y = data[\"decoder_labels\"]\r\n",
        "        x = data\r\n",
        "\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            # Forward pass\r\n",
        "            y_pred = self.model(x, training=True)\r\n",
        "            # Compute the loss value.\r\n",
        "            y_pred = y_pred.logits\r\n",
        "            loss = self.compute_loss(y, y_pred)\r\n",
        "            # Reduce loss to single digit\r\n",
        "            loss = tf.reduce_mean(loss)\r\n",
        "\r\n",
        "        # Compute gradients\r\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\r\n",
        "        # Update weights\r\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n",
        "        # Update loss tracker\r\n",
        "        self.loss_tracker.update_state(loss)  \r\n",
        "        # Update metrics\r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "    def test_step(self, data):\r\n",
        "        # Data is a dictionary\r\n",
        "        y = data[\"decoder_labels\"]\r\n",
        "        x = data\r\n",
        "\r\n",
        "        # Compute predictions\r\n",
        "        y_pred = self.model(x, training=False)\r\n",
        "        y_pred = y_pred.logits\r\n",
        "        loss = self.compute_loss(y, y_pred)\r\n",
        "\r\n",
        "        # Updates the metrics tracking the loss\r\n",
        "        self.loss_tracker.update_state(loss)  \r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "\r\n",
        "    def train_eager(self, train_ds, valid_ds, epochs, steps=-1):\r\n",
        "\r\n",
        "        for epoch in range(epochs):\r\n",
        "          for (batch, (train, val)) in enumerate(zip(train_ds, valid_ds)):\r\n",
        "\r\n",
        "            self.train_step(train)\r\n",
        "\r\n",
        "            if batch % 5 == 0:\r\n",
        "              self.test_step(val)\r\n",
        "              print('Batch {}, Last Train Loss {}, Last Val Loss {}'.format(batch, self.loss_tracker[-1], loss_history_val[-1]))\r\n",
        "\r\n",
        "            if batch == steps:\r\n",
        "              break \r\n",
        "\r\n",
        "          print ('Epoch {} finished'.format(epoch))\r\n",
        "\r\n",
        "\r\n",
        "    def compute_loss(self, labels, logits):\r\n",
        "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "            from_logits=True, reduction=tf.keras.losses.Reduction.NONE\r\n",
        "        )\r\n",
        "        # make sure only labels that are not equal to -100 do affect loss\r\n",
        "        active_loss = tf.not_equal(tf.reshape(labels, (-1,)), -100)\r\n",
        "        reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[2])), active_loss)\r\n",
        "        labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\r\n",
        "\r\n",
        "        return loss_fn(labels, reduced_logits)\r\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PZXjE8pRRp5"
      },
      "source": [
        "def shape_list(tensor: tf.Tensor):\r\n",
        "    \"\"\"\r\n",
        "    Deal with dynamic shape in tensorflow cleanly.\r\n",
        "    Args:\r\n",
        "        tensor (:obj:`tf.Tensor`): The tensor we want the shape of.\r\n",
        "    Returns:\r\n",
        "        :obj:`List[int]`: The shape of the tensor as a list.\r\n",
        "    \"\"\"\r\n",
        "    dynamic = tf.shape(tensor)\r\n",
        "\r\n",
        "    if tensor.shape == tf.TensorShape(None):\r\n",
        "        return dynamic\r\n",
        "\r\n",
        "    static = tensor.shape.as_list()\r\n",
        "\r\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "XPIthJsIa3OW",
        "outputId": "1662ed51-d83c-4bc4-c9b5-3e54a20775cc"
      },
      "source": [
        "model.loss_tracker"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-1c0c3ec3863c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_output_at\u001b[0;34m(self, node_index)\u001b[0m\n\u001b[1;32m   2115\u001b[0m     \"\"\"\n\u001b[1;32m   2116\u001b[0m     return self._get_node_attribute_at_index(node_index, 'output_tensors',\n\u001b[0;32m-> 2117\u001b[0;31m                                              'output')\n\u001b[0m\u001b[1;32m   2118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m   2668\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m       raise RuntimeError('The layer has never been called '\n\u001b[0;32m-> 2670\u001b[0;31m                          'and thus has no defined ' + attr_name + '.')\n\u001b[0m\u001b[1;32m   2671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2672\u001b[0m       raise ValueError('Asked to get ' + attr_name + ' at node ' +\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The layer has never been called and thus has no defined output."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "TXgBU2zGadqz",
        "outputId": "c84f4548-5cdd-4256-c7cf-2733a318c938"
      },
      "source": [
        "model.train_eager(train_ds, valid_ds, 1, 100)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-444e2228dc23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-04f73d716e6d>\u001b[0m in \u001b[0;36mtrain_eager\u001b[0;34m(self, train_ds, valid_ds, epochs, steps)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Batch {}, Last Train Loss {}, Last Val Loss {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'loss_history_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "5fK9WDHSTSnm",
        "outputId": "5e03ae5c-40b7-4dee-a476-e6f26fbe709a"
      },
      "source": [
        "### Modelling - Static ###\r\n",
        "\r\n",
        "# \"Friendlier\" metric as only looks whether ground truth is in models top 5 preds\r\n",
        "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')]\r\n",
        "\r\n",
        "learning_rate = 1e-5 \r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\r\n",
        "\r\n",
        "base_model = TFT5ForConditionalGeneration.from_pretrained(\"t5-base\")\r\n",
        "model = Wrapper(base_model)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, metrics=metrics)\r\n",
        "\r\n",
        "model.fit(train_ds.take(1000), steps_per_epoch=500, epochs=2, validation_data=valid_ds.take(1000))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - ETA: 0s - accuracy: 0.6566 - loss: 1.6168"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r500/500 [==============================] - 263s 469ms/step - accuracy: 0.6570 - loss: 1.6168 - val_accuracy: 0.9971 - val_loss: 0.0548\n",
            "Epoch 2/2\n",
            " 40/500 [=>............................] - ETA: 1:52 - accuracy: 0.9949 - loss: 0.0730"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-06c6374ad28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fglAbyWlMdrF"
      },
      "source": [
        "##### Static Loss External"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pamc7LTbJX2j"
      },
      "source": [
        "### Modelling V2 (Loss external) ###\r\n",
        "\r\n",
        "class Wrapper(tf.keras.Model):\r\n",
        "    def __init__(self, model, *args, **kwargs):\r\n",
        "        super().__init__(*args, **kwargs)\r\n",
        "        self.model = model\r\n",
        "\r\n",
        "    def train_step(self, data):\r\n",
        "        # Data is a dictionary with label\r\n",
        "\r\n",
        "        y = data[\"labels\"]\r\n",
        "        x = data\r\n",
        "\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            outputs = self.model(x, training=True)  # Forward pass\r\n",
        "            # Compute the loss value.\r\n",
        "            # The loss function is configured in `compile()`.\r\n",
        "\r\n",
        "            loss = outputs[0]  \r\n",
        "            y_pred = outputs[1]\r\n",
        "\r\n",
        "        #loss = tf.reduce_mean(loss)\r\n",
        "        # Compute gradients\r\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\r\n",
        "        # Update weights\r\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n",
        "        # Update metrics\r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "    def test_step(self, data):\r\n",
        "        y = data[\"labels\"]\r\n",
        "        x = data\r\n",
        "        outputs = self.model(x, training=True)\r\n",
        "        loss = outputs[0]  \r\n",
        "        #loss = tf.reduce_mean(loss)\r\n",
        "        y_pred = outputs[1]\r\n",
        "        #self.loss_tracker.update_state(loss)\r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "    def train_eager(self, train_ds, valid_ds, epochs, steps=-1):\r\n",
        "\r\n",
        "        for epoch in range(epochs):\r\n",
        "          for (batch, (train, val)) in enumerate(zip(train_ds, valid_ds)):\r\n",
        "\r\n",
        "            self.train_step(train)\r\n",
        "\r\n",
        "            if batch % 5 == 0:\r\n",
        "              self.test_step(val)\r\n",
        "              print('Batch {}, Last Train Loss {}, Last Val Loss {}'.format(batch, loss_history_train[-1], loss_history_val[-1]))\r\n",
        "\r\n",
        "            if batch == steps:\r\n",
        "              break \r\n",
        "\r\n",
        "          print ('Epoch {} finished'.format(epoch))\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pX9lQomOMEw",
        "outputId": "48bf0e2f-b02a-452e-be9d-8b68dbf0a67a"
      },
      "source": [
        "### Modelling - Static ###\r\n",
        "\r\n",
        "# \"Friendlier\" metric as only looks whether ground truth is in models top 5 preds\r\n",
        "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')]\r\n",
        "\r\n",
        "learning_rate = 1e-5#0.001 \r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\r\n",
        "\r\n",
        "#model = Wrapper.from_pretrained(\"t5-base\")\r\n",
        "\r\n",
        "base_model = TFT5ForConditionalGeneration.from_pretrained(\"t5-base\")\r\n",
        "model = Wrapper(base_model)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, metrics=metrics)\r\n",
        "\r\n",
        "# TODO: Move to eager execution; TODO: Train on TPU\r\n",
        "# TODO - Breaks at 2nd epoch?\r\n",
        "model.fit(train_ds.take(1000), steps_per_epoch=500, epochs=2, validation_data=valid_ds.take(1000))\r\n",
        "#model.fit(train_ds, epochs=5, steps_per_epoch=steps, validation_data=valid_ds, validation_steps=valid_steps)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - ETA: 0s - accuracy: 0.6466"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r500/500 [==============================] - 266s 481ms/step - accuracy: 0.6470 - val_accuracy: 0.9933\n",
            "Epoch 2/2\n",
            "500/500 [==============================] - 233s 467ms/step - accuracy: 0.9961 - val_accuracy: 0.9960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1c7d939240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTLdAtNpMRxs"
      },
      "source": [
        "##### Static - Original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obcuf30FYjC2"
      },
      "source": [
        "### Modelling - Static ###\r\n",
        "\r\n",
        "# Wrapping the original model with two simple functions: Train & Test\r\n",
        "# Wrapping a Huggingface model for now but lateron the Wecredo model architecture\r\n",
        "\r\n",
        "class Wrapper(TFT5ForConditionalGeneration):\r\n",
        "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\r\n",
        "        super().__init__(*args, **kwargs)\r\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name='loss') \r\n",
        "    \r\n",
        "    # > Graph execution w/ tf.function\r\n",
        "    @tf.function\r\n",
        "    def train_step(self, data):\r\n",
        "        x = data\r\n",
        "        y = x[\"labels\"]\r\n",
        "        y = tf.reshape(y, [-1, 1])\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "\r\n",
        "            # > Feeds it just into TFT5ForConditionalGeneration; training=True turns on dropout\r\n",
        "            outputs = self(x, training=True)\r\n",
        "\r\n",
        "            # TODO: Manually compute loss; not have transformer autocompute it\r\n",
        "            loss = outputs[0]  \r\n",
        "            logits = outputs[1]\r\n",
        "\r\n",
        "            # Reduce loss to single digit\r\n",
        "            loss = tf.reduce_mean(loss)\r\n",
        "            grads = tape.gradient(loss, self.trainable_variables)\r\n",
        "            \r\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\r\n",
        "        lr = self.optimizer._decayed_lr(tf.float32)\r\n",
        "        \r\n",
        "        self.loss_tracker.update_state(loss)        \r\n",
        "        self.compiled_metrics.update_state(y, logits)\r\n",
        "        metrics = {m.name: m.result() for m in self.metrics}\r\n",
        "        metrics.update({'lr': lr})\r\n",
        "        \r\n",
        "        return metrics\r\n",
        "\r\n",
        "    def test_step(self, data):\r\n",
        "        x = data\r\n",
        "        y = x[\"labels\"]\r\n",
        "        y = tf.reshape(y, [-1, 1])\r\n",
        "        output = self(x, training=False)\r\n",
        "        loss = output[0]\r\n",
        "        loss = tf.reduce_mean(loss)\r\n",
        "        logits = output[1]\r\n",
        "        \r\n",
        "        self.loss_tracker.update_state(loss)\r\n",
        "        self.compiled_metrics.update_state(y, logits)\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "j2At3O2QjzyH",
        "outputId": "16bc9228-2e3a-48f6-bf70-92dbcc3bb7ff"
      },
      "source": [
        "### Modelling - Static ###\r\n",
        "\r\n",
        "# \"Friendlier\" metric as only looks whether ground truth is in models top 5 preds\r\n",
        "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')]\r\n",
        "\r\n",
        "learning_rate = 0.001 \r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\r\n",
        "\r\n",
        "model = Wrapper.from_pretrained(\"t5-base\")\r\n",
        "model.compile(optimizer=optimizer, metrics=metrics)\r\n",
        "\r\n",
        "# TODO: Move to eager execution; TODO: Train on TPU\r\n",
        "# TODO - Breaks at 2nd epoch?\r\n",
        "model.fit(train_ds, epochs=5, steps_per_epoch=steps, validation_data=valid_ds, validation_steps=valid_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing Wrapper.\n",
            "\n",
            "All the layers of Wrapper were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Wrapper for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc9be7795f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7fc9dc127d90> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc9be7795f8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7fc9dc127d90> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fc9d9ab78c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function wrap at 0x7fc9d9ab78c8> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  918/21900 [>.............................] - ETA: 1:25:48 - accuracy: 0.9796 - loss: 0.1103 - lr: 0.0010"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7716ffc12c8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV5P2021MEyk"
      },
      "source": [
        "##### Eager-Only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k8qwAKNQLLlf",
        "outputId": "328bce71-bd80-41c0-a5d1-4e44586e5a6a"
      },
      "source": [
        "### Modelling - Eager ###\r\n",
        "\r\n",
        "learning_rate = 1e-5\r\n",
        "model = TFT5ForConditionalGeneration.from_pretrained(\"t5-base\")\r\n",
        "\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\r\n",
        "\r\n",
        "loss_history_train = []\r\n",
        "loss_history_val = []\r\n",
        "\r\n",
        "def train_step(data):\r\n",
        "    x = data\r\n",
        "\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "\r\n",
        "        # > Feeds it just into TFT5ForConditionalGeneration; training=True turns on dropout\r\n",
        "        outputs = model(x, training=True)\r\n",
        "\r\n",
        "        loss = outputs[0]  \r\n",
        "        logits = outputs[1]\r\n",
        "\r\n",
        "        # Reduce loss to single digit\r\n",
        "        loss = tf.reduce_mean(loss)\r\n",
        "\r\n",
        "    loss_history_train.append(loss.numpy().mean())\r\n",
        "    # Calculate grads & update\r\n",
        "    grads = tape.gradient(loss, model.trainable_variables)    \r\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n",
        "    \r\n",
        "def test_step(data):\r\n",
        "    x = data\r\n",
        "    output = model(x, training=False)\r\n",
        "    loss = output[0]\r\n",
        "    loss = tf.reduce_mean(loss)\r\n",
        "    loss_history_val.append(loss.numpy().mean())\r\n",
        "\r\n",
        "\r\n",
        "def train(epochs, steps=-1):\r\n",
        "  for epoch in range(epochs):\r\n",
        "    for (batch, (train, val)) in enumerate(zip(train_ds, valid_ds)):\r\n",
        "      train_step(train)\r\n",
        "      test_step(val)\r\n",
        "      if batch % 5 == 0:\r\n",
        "        print('Batch {}, Last Train Loss {}, Last Val Loss {}'.format(batch, loss_history_train[-1], loss_history_val[-1]))\r\n",
        "\r\n",
        "      if batch == steps:\r\n",
        "        break \r\n",
        "\r\n",
        "    print ('Epoch {} finished'.format(epoch))\r\n",
        "\r\n",
        "\r\n",
        "train(epochs=2, steps=500)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 0, Last Train Loss 18.817346572875977, Last Val Loss 21.907432556152344\n",
            "Batch 5, Last Train Loss 17.075010299682617, Last Val Loss 21.295143127441406\n",
            "Batch 10, Last Train Loss 14.165051460266113, Last Val Loss 16.9741268157959\n",
            "Batch 15, Last Train Loss 15.446833610534668, Last Val Loss 16.751110076904297\n",
            "Batch 20, Last Train Loss 12.061304092407227, Last Val Loss 10.404147148132324\n",
            "Batch 25, Last Train Loss 10.07026195526123, Last Val Loss 10.916749000549316\n",
            "Batch 30, Last Train Loss 8.332906723022461, Last Val Loss 10.377346992492676\n",
            "Batch 35, Last Train Loss 7.587803363800049, Last Val Loss 9.178731918334961\n",
            "Batch 40, Last Train Loss 6.862760066986084, Last Val Loss 8.216968536376953\n",
            "Batch 45, Last Train Loss 5.672942161560059, Last Val Loss 4.254398822784424\n",
            "Batch 50, Last Train Loss 4.520209789276123, Last Val Loss 3.229088306427002\n",
            "Batch 55, Last Train Loss 5.447192192077637, Last Val Loss 3.174879789352417\n",
            "Batch 60, Last Train Loss 2.297957181930542, Last Val Loss 2.0461535453796387\n",
            "Batch 65, Last Train Loss 2.0007855892181396, Last Val Loss 3.0077178478240967\n",
            "Batch 70, Last Train Loss 1.948745846748352, Last Val Loss 0.7123419642448425\n",
            "Batch 75, Last Train Loss 1.5391064882278442, Last Val Loss 0.5790628790855408\n",
            "Batch 80, Last Train Loss 2.0151591300964355, Last Val Loss 0.5030857920646667\n",
            "Batch 85, Last Train Loss 1.168382167816162, Last Val Loss 0.25181275606155396\n",
            "Batch 90, Last Train Loss 1.19036066532135, Last Val Loss 2.3099021911621094\n",
            "Batch 95, Last Train Loss 1.2378931045532227, Last Val Loss 0.3728069067001343\n",
            "Batch 100, Last Train Loss 1.112203598022461, Last Val Loss 0.1282966136932373\n",
            "Batch 105, Last Train Loss 1.0058414936065674, Last Val Loss 0.22088831663131714\n",
            "Batch 110, Last Train Loss 1.4448089599609375, Last Val Loss 0.11467943340539932\n",
            "Batch 115, Last Train Loss 1.1892887353897095, Last Val Loss 0.09677915275096893\n",
            "Batch 120, Last Train Loss 1.1061140298843384, Last Val Loss 0.153128519654274\n",
            "Batch 125, Last Train Loss 1.04524827003479, Last Val Loss 0.2352762371301651\n",
            "Batch 130, Last Train Loss 0.9301944971084595, Last Val Loss 0.1290193349123001\n",
            "Batch 135, Last Train Loss 0.848412275314331, Last Val Loss 0.11214706301689148\n",
            "Batch 140, Last Train Loss 0.9825266599655151, Last Val Loss 0.10718505829572678\n",
            "Batch 145, Last Train Loss 0.95146244764328, Last Val Loss 0.05735328420996666\n",
            "Batch 150, Last Train Loss 0.5918256640434265, Last Val Loss 0.05122450366616249\n",
            "Batch 155, Last Train Loss 1.0954684019088745, Last Val Loss 0.060405433177948\n",
            "Batch 160, Last Train Loss 0.7236894965171814, Last Val Loss 0.0597965382039547\n",
            "Batch 165, Last Train Loss 0.6451513171195984, Last Val Loss 0.04966222122311592\n",
            "Batch 170, Last Train Loss 0.8160414695739746, Last Val Loss 0.3007831871509552\n",
            "Batch 175, Last Train Loss 0.7137618660926819, Last Val Loss 0.12020408362150192\n",
            "Batch 180, Last Train Loss 0.6685460805892944, Last Val Loss 0.05706791952252388\n",
            "Batch 185, Last Train Loss 0.5823396444320679, Last Val Loss 0.09113625437021255\n",
            "Batch 190, Last Train Loss 0.5137336850166321, Last Val Loss 0.0174302589148283\n",
            "Batch 195, Last Train Loss 0.4512365162372589, Last Val Loss 0.03347404673695564\n",
            "Batch 200, Last Train Loss 0.513843834400177, Last Val Loss 0.016715271398425102\n",
            "Batch 205, Last Train Loss 0.6412419676780701, Last Val Loss 0.043107353150844574\n",
            "Batch 210, Last Train Loss 0.4108106791973114, Last Val Loss 0.019727708771824837\n",
            "Batch 215, Last Train Loss 0.6150586605072021, Last Val Loss 0.050766266882419586\n",
            "Batch 220, Last Train Loss 0.489286869764328, Last Val Loss 0.026323601603507996\n",
            "Batch 225, Last Train Loss 0.38979119062423706, Last Val Loss 0.034041184931993484\n",
            "Batch 230, Last Train Loss 0.45334362983703613, Last Val Loss 0.007901475764811039\n",
            "Batch 235, Last Train Loss 0.4429248571395874, Last Val Loss 0.003363081719726324\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e82dfb9159f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-e82dfb9159f8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, steps)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-e82dfb9159f8>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# > Feeds it just into TFT5ForConditionalGeneration; training=True turns on dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# TODO: Manually compute loss; not have transformer autocompute it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/t5/modeling_tf_t5.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, head_mask, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m             )\n\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/t5/modeling_tf_t5.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"use_cache\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_attentions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             )\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/t5/modeling_tf_t5.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, head_mask, past_key_value, use_cache, output_attentions, training)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# Apply Feed Forward layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/t5/modeling_tf_t5.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, hidden_states, training)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mdense_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseReluDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/t5/modeling_tf_t5.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, hidden_states, training)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m         dtype=self._compute_dtype_object)\n\u001b[0m\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   4613\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tensordot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4614\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4615\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4616\u001b[0m     \u001b[0ma_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4617\u001b[0m     \u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims_static\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensordot_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_var_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1391\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_other\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvalue\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_existing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    670\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[0;34m()\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0;32m--> 663\u001b[0;31m           self._handle, self._dtype)\n\u001b[0m\u001b[1;32m    664\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m--> 471\u001b[0;31m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0m\u001b[1;32m    472\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "OfwlDzvxeqV_",
        "outputId": "7a67fe91-713b-4446-9a9b-1dd916f9589f"
      },
      "source": [
        "### Evaluation ###\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(loss_history_train)\r\n",
        "plt.plot(loss_history_val)\r\n",
        "plt.title('Model Loss')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.xlabel('# Batch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4Wa46Qarmwa",
        "outputId": "1f37f209-5b72-46b4-e96a-5f55b20535cc"
      },
      "source": [
        "### Evaluation ###\r\n",
        "\r\n",
        "context = \"Beijing (/ˌbeɪˈdʒɪŋ/ BAY-JING[10][11] Mandarin pronunciation: [pèi.tɕíŋ] (About this soundlisten)), alternatively romanized as Peking[12] (/ˌpiˈkɪŋ/ PEE-KING),[13] is the capital of the People's Republic of China. It is the world's most populous national capital city, with over 21 million residents within an administrative area of 16,410.5 km2 (6336 sq. mi.).[4] It is located in Northern China, is governed as a municipality under the direct administration of the State Council with 16 urban, suburban, and rural districts.[14] Beijing is mostly surrounded by Hebei Province with the exception of neighboring Tianjin to the southeast; together, the three divisions form the Jingjinji megalopolis and the national capital region of China\"\r\n",
        "\r\n",
        "question = \"What is the capital of China?\"\r\n",
        "\r\n",
        "inputs = f\"question: {question} context: {context}\"\r\n",
        "\r\n",
        "encoded_query = tokenizer(inputs, return_tensors='tf', pad_to_max_length=True, truncation=True, max_length=encoder_max_len)\r\n",
        "\r\n",
        "input_ids = encoded_query[\"input_ids\"]\r\n",
        "attention_mask = encoded_query[\"attention_mask\"]\r\n",
        "\r\n",
        "generated_answer = model.generate(input_ids, attention_mask=attention_mask, \r\n",
        "                                 max_length=decoder_max_len, top_p=0.95, top_k=50, repetition_penalty=2)\r\n",
        "decoded_answer = tokenizer.decode(generated_answer.numpy()[0])\r\n",
        "\r\n",
        "print(\"Answer: \", decoded_answer)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Answer:  <pad> True</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEO6-D2Pc2M7"
      },
      "source": [
        "#### Summarization\r\n",
        "\r\n",
        "On CNN/Dailymail dataset; Also part of T5 tasks.\r\n",
        "\r\n",
        "- Modelling - Eager: Ready\r\n",
        "- Modelling - Static: WIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yal3sEdVoxXW"
      },
      "source": [
        "### Installs ###\r\n",
        "\r\n",
        "!pip install -q datasets\r\n",
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVJQmWLuozji"
      },
      "source": [
        "### Imports ###\r\n",
        "\r\n",
        "import transformers\r\n",
        "import numpy as np\r\n",
        "from datasets import load_dataset\r\n",
        "\r\n",
        "# If import error below, restart session; reinstall transformers\r\n",
        "from transformers import AutoTokenizer, TFT5ForConditionalGeneration"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D00dCo5HweOX",
        "outputId": "125f6630-5736-41c1-bfd2-e011d17410b1"
      },
      "source": [
        "### Data ###\r\n",
        "\r\n",
        "# 287,113 train samples; 13,368 val samples\r\n",
        "train_ds = load_dataset(\"cnn_dailymail\", \"2.0.0\", split='train')\r\n",
        "valid_ds = load_dataset(\"cnn_dailymail\", \"2.0.0\", split='validation')\r\n",
        "\r\n",
        "# Subsample to 10K for faster training & quick testing\r\n",
        "train_ds = train_ds.select(range(10000))\r\n",
        "valid_ds = valid_ds.select(range(10000))\r\n",
        "\r\n",
        "print(\"Example: \", next(iter(train_ds)))\r\n",
        "\r\n",
        "# Tokenize data to prepare for feeding in model \r\n",
        "# Using huggingface tokenizer for now - We can easily swap this for a CN one lateron\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\r\n",
        "\r\n",
        "# Max_lens from: https://github.com/google-research/text-to-text-transfer-transformer/blob/04776f4efae818030bce71c111d7042c11e8703b/t5/models/gin/sequence_lengths/cnn_dailymail_v002.gin\r\n",
        "# Mean is 781 for article; 56 for highlights\r\n",
        "encoder_max_len = 512\r\n",
        "decoder_max_len = 128 # 512\r\n",
        "batch_size = 2\r\n",
        "buffer_size = 1000\r\n",
        "\r\n",
        "ntrain = len(train_ds)\r\n",
        "nvalid = len(valid_ds)\r\n",
        "steps = int(np.ceil(ntrain/batch_size))\r\n",
        "valid_steps = int(np.ceil(nvalid/batch_size))\r\n",
        "\r\n",
        "def tokenize(example):\r\n",
        "    \"\"\"\r\n",
        "    Prepares input example for model\r\n",
        "    eos_token=\"</s>\",\r\n",
        "    unk_token=\"<unk>\",\r\n",
        "    pad_token=\"<pad>\"\r\n",
        "\r\n",
        "    TODOs:\r\n",
        "    - Remove max_len? \r\n",
        "    - In final stage adopt preprocessing from https://github.com/google-research/text-to-text-transfer-transformer/blob/867715664c8393cf12093ea9633f868c0df35548/t5/data/preprocessors.py\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    article = example[\"article\"]\r\n",
        "    summary = example[\"highlights\"]\r\n",
        "\r\n",
        "    inputs = f\"summarize: {str(article)}\"\r\n",
        "    targets = f\"{str(summary)}\"\r\n",
        "\r\n",
        "    # TODO: Do we need those two diff. input types?\r\n",
        "    encoder_inputs = tokenizer(inputs, truncation=True, \r\n",
        "                              return_tensors='tf', padding=\"max_length\", max_length=encoder_max_len)\r\n",
        "    \r\n",
        "    decoder_inputs = tokenizer(targets, truncation=True, \r\n",
        "                               return_tensors='tf', padding=\"max_length\", max_length=decoder_max_len)\r\n",
        "    \r\n",
        "    outputs = {'input_ids': encoder_inputs['input_ids'][0], 'attention_mask': encoder_inputs['attention_mask'][0], \r\n",
        "               'labels': decoder_inputs['input_ids'][0], 'decoder_attention_mask': decoder_inputs['attention_mask'][0]}\r\n",
        "    return outputs\r\n",
        "\r\n",
        "def to_tf_dataset(dataset): \r\n",
        "  \"\"\"\r\n",
        "  Turns dataset into a TF compatible dataset via tf's from_generator\r\n",
        "  \"\"\" \r\n",
        "  columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\r\n",
        "  dataset.set_format(type='tensorflow', columns=columns)\r\n",
        "  return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \r\n",
        "                'labels':tf.int32, 'decoder_attention_mask':tf.int32,  }\r\n",
        "  return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \r\n",
        "                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None])}\r\n",
        "  ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\r\n",
        "  return ds\r\n",
        "\r\n",
        "\r\n",
        "train_ds = train_ds.map(tokenize)\r\n",
        "valid_ds = valid_ds.map(tokenize)\r\n",
        "\r\n",
        "train_ds = to_tf_dataset(train_ds)\r\n",
        "valid_ds = to_tf_dataset(valid_ds)\r\n",
        "\r\n",
        "train_ds = train_ds.shuffle(buffer_size).batch(batch_size)\r\n",
        "valid_ds = valid_ds.shuffle(buffer_size).batch(batch_size)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/2.0.0/2.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602)\n",
            "Reusing dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/2.0.0/2.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Example:  {'article': 'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It\\'s a step that is set to turn an international crisis into a fierce domestic political battle. There are key questions looming over the debate: What did U.N. weapons inspectors find in Syria? What happens if Congress votes no? And how will the Syrian government react? In a televised address from the White House Rose Garden earlier Saturday, the president said he would take his case to Congress, not because he has to -- but because he wants to. \"While I believe I have the authority to carry out this military action without specific congressional authorization, I know that the country will be stronger if we take this course, and our actions will be even more effective,\" he said. \"We should have this debate, because the issues are too big for business as usual.\" Obama said top congressional leaders had agreed to schedule a debate when the body returns to Washington on September 9. The Senate Foreign Relations Committee will hold a hearing over the matter on Tuesday, Sen. Robert Menendez said. Transcript: Read Obama\\'s full remarks . Syrian crisis: Latest developments . U.N. inspectors leave Syria . Obama\\'s remarks came shortly after U.N. inspectors left Syria, carrying evidence that will determine whether chemical weapons were used in an attack early last week in a Damascus suburb. \"The aim of the game here, the mandate, is very clear -- and that is to ascertain whether chemical weapons were used -- and not by whom,\" U.N. spokesman Martin Nesirky told reporters on Saturday. But who used the weapons in the reported toxic gas attack in a Damascus suburb on August 21 has been a key point of global debate over the Syrian crisis. Top U.S. officials have said there\\'s no doubt that the Syrian government was behind it, while Syrian officials have denied responsibility and blamed jihadists fighting with the rebels. British and U.S. intelligence reports say the attack involved chemical weapons, but U.N. officials have stressed the importance of waiting for an official report from inspectors. The inspectors will share their findings with U.N. Secretary-General Ban Ki-moon Ban, who has said he wants to wait until the U.N. team\\'s final report is completed before presenting it to the U.N. Security Council. The Organization for the Prohibition of Chemical Weapons, which nine of the inspectors belong to, said Saturday that it could take up to three weeks to analyze the evidence they collected. \"It needs time to be able to analyze the information and the samples,\" Nesirky said. He noted that Ban has repeatedly said there is no alternative to a political solution to the crisis in Syria, and that \"a military solution is not an option.\" Bergen:  Syria is a problem from hell for the U.S. Obama: \\'This menace must be confronted\\' Obama\\'s senior advisers have debated the next steps to take, and the president\\'s comments Saturday came amid mounting political pressure over the situation in Syria. Some U.S. lawmakers have called for immediate action while others warn of stepping into what could become a quagmire. Some global leaders have expressed support, but the British Parliament\\'s vote against military action earlier this week was a blow to Obama\\'s hopes of getting strong backing from key NATO allies. On Saturday, Obama proposed what he said would be a limited military action against Syrian President Bashar al-Assad. Any military attack would not be open-ended or include U.S. ground forces, he said. Syria\\'s alleged use of chemical weapons earlier this month \"is an assault on human dignity,\" the president said. A failure to respond with force, Obama argued,  \"could lead to escalating use of chemical weapons or their proliferation to terrorist groups who would do our people harm. In a world with many dangers, this menace must be confronted.\" Syria missile strike: What would happen next? Map: U.S. and allied assets around Syria . Obama decision came Friday night . On Friday night, the president made a last-minute decision to consult lawmakers. What will happen if they vote no? It\\'s unclear. A senior administration official told CNN that Obama has the authority to act without Congress -- even if Congress rejects his request for authorization to use force. Obama on Saturday continued to shore up support for a strike on the al-Assad government. He spoke by phone with French President Francois Hollande before his Rose Garden speech. \"The two leaders agreed that the international community must deliver a resolute message to the Assad regime -- and others who would consider using chemical weapons -- that these crimes are unacceptable and those who violate this international norm will be held accountable by the world,\" the White House said. Meanwhile, as uncertainty loomed over how Congress would weigh in, U.S. military officials said they remained at the ready. 5 key assertions: U.S. intelligence report on Syria . Syria: Who wants what after chemical weapons horror . Reactions mixed to Obama\\'s speech . A spokesman for the Syrian National Coalition said that the opposition group was disappointed by Obama\\'s announcement. \"Our fear now is that the lack of action could embolden the regime and they repeat his attacks in a more serious way,\" said spokesman Louay Safi. \"So we are quite concerned.\" Some members of Congress applauded Obama\\'s decision. House Speaker John Boehner, Majority Leader Eric Cantor, Majority Whip Kevin McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement Saturday praising the president. \"Under the Constitution, the responsibility to declare war lies with Congress,\" the Republican lawmakers said. \"We are glad the president is seeking authorization for any military action in Syria in response to serious, substantive questions being raised.\" More than 160 legislators, including 63 of Obama\\'s fellow Democrats, had signed letters calling for either a vote or at least a \"full debate\" before any U.S. action. British Prime Minister David Cameron, whose own attempt to get lawmakers in his country to support military action in Syria failed earlier this week, responded to Obama\\'s speech in a Twitter post Saturday. \"I understand and support Barack Obama\\'s position on Syria,\" Cameron said. An influential lawmaker in Russia -- which has stood by Syria and criticized the United States -- had his own theory. \"The main reason Obama is turning to the Congress:  the military operation did not get enough support either in the world, among allies of the US or in the United States itself,\" Alexei Pushkov, chairman of the international-affairs committee of the Russian State Duma, said in a Twitter post. In the United States, scattered groups of anti-war protesters around the country took to the streets Saturday. \"Like many other Americans...we\\'re just tired of the United States getting involved and invading and bombing other countries,\" said Robin Rosecrans, who was among hundreds at a Los Angeles demonstration. What do Syria\\'s neighbors think? Why Russia, China, Iran stand by Assad . Syria\\'s government unfazed . After Obama\\'s speech, a military and political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia opposes military action against Syria, is \"crying for help\" for someone to come to his rescue and is facing two defeats -- on the political and military levels. Syria\\'s prime minister appeared unfazed by the saber-rattling. \"The Syrian Army\\'s status is on maximum readiness and fingers are on the trigger to confront all challenges,\" Wael Nader al-Halqi said during a meeting with a delegation of Syrian expatriates from Italy, according to a banner on Syria State TV that was broadcast prior to Obama\\'s address. An anchor on Syrian state television said Obama \"appeared to be preparing for an aggression on Syria based on repeated lies.\" A top Syrian diplomat told the state television network that Obama was facing pressure to take military action from Israel, Turkey, some Arabs and right-wing extremists in the United States. \"I think he has done well by doing what Cameron did in terms of taking the issue to Parliament,\" said Bashar Jaafari, Syria\\'s ambassador to the United Nations. Both Obama and Cameron, he said, \"climbed to the top of the tree and don\\'t know how to get down.\" The Syrian government has denied that it used chemical weapons in the August 21 attack, saying that jihadists fighting with the rebels used them in an effort to turn global sentiments against it. British intelligence had put the number of people killed in the attack at more than 350. On Saturday, Obama said \"all told, well over 1,000 people were murdered.\" U.S. Secretary of State John Kerry on Friday cited a death toll of 1,429, more than 400 of them children. No explanation was offered for the discrepancy. Iran: U.S. military action in Syria would spark \\'disaster\\' Opinion: Why strikes in Syria are a bad idea .', 'highlights': 'Syrian official: Obama climbed to the top of the tree, \"doesn\\'t know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .', 'id': '0001d1afc246a7964130f43ae940af6bc6c57f01'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/2.0.0/2.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602/cache-4827f4f6826c3a1b.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/cnn_dailymail/2.0.0/2.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602/cache-87c4dd8c7238b381.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SMiSLwvyxeZY",
        "outputId": "e9598246-b32c-4e85-fa8e-51ec1d9e1bab"
      },
      "source": [
        "### Modelling - Eager ###\r\n",
        "\r\n",
        "learning_rate = 1e-5\r\n",
        "model = TFT5ForConditionalGeneration.from_pretrained(\"t5-base\")\r\n",
        "\r\n",
        "loss_object = tf.keras.metrics.Mean(name='loss') \r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\r\n",
        "\r\n",
        "loss_history_train = []\r\n",
        "loss_history_val = []\r\n",
        "\r\n",
        "def train_step(data):\r\n",
        "    x = data\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "\r\n",
        "        # > Feeds it just into TFT5ForConditionalGeneration; training=True turns on dropout\r\n",
        "        outputs = model(x, training=True)\r\n",
        "        # TODO: Manually compute loss; not have transformer autocompute it\r\n",
        "        loss = outputs[0]\r\n",
        "        # Reduce loss to single digit\r\n",
        "        loss = tf.reduce_mean(loss)\r\n",
        "\r\n",
        "    loss_history_train.append(loss.numpy().mean())\r\n",
        "    # Calculate grads & update\r\n",
        "    grads = tape.gradient(loss, model.trainable_variables)    \r\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n",
        "    \r\n",
        "\r\n",
        "def test_step(data):\r\n",
        "    x = data\r\n",
        "    output = model(x, training=False)\r\n",
        "    loss = output[0]\r\n",
        "    loss = tf.reduce_mean(loss)\r\n",
        "    loss_history_val.append(loss.numpy().mean())\r\n",
        "\r\n",
        "\r\n",
        "def train(epochs, steps=-1):\r\n",
        "  for epoch in range(epochs):\r\n",
        "    for (batch, (train, val)) in enumerate(zip(train_ds, valid_ds)):\r\n",
        "      train_step(train)\r\n",
        "      test_step(val)\r\n",
        "      if batch % 5 == 0:\r\n",
        "        print('Batch {}, Last Train Loss {}, Last Val Loss {}'.format(batch, loss_history_train[-1], loss_history_val[-1]))\r\n",
        "\r\n",
        "      if batch == steps:\r\n",
        "        break \r\n",
        "\r\n",
        "    print ('Epoch {} finished'.format(epoch))\r\n",
        "\r\n",
        "\r\n",
        "train(epochs=1, steps=500)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 0, Last Train Loss 9.202120780944824, Last Val Loss 9.99158000946045\n",
            "Batch 5, Last Train Loss 8.323246002197266, Last Val Loss 8.111117362976074\n",
            "Batch 10, Last Train Loss 7.096862316131592, Last Val Loss 9.064104080200195\n",
            "Batch 15, Last Train Loss 5.784824848175049, Last Val Loss 8.216259002685547\n",
            "Batch 20, Last Train Loss 4.890959739685059, Last Val Loss 5.232797145843506\n",
            "Batch 25, Last Train Loss 3.9022815227508545, Last Val Loss 3.2586159706115723\n",
            "Batch 30, Last Train Loss 3.077070474624634, Last Val Loss 3.4051480293273926\n",
            "Batch 35, Last Train Loss 3.6157517433166504, Last Val Loss 3.261713981628418\n",
            "Batch 40, Last Train Loss 3.3529109954833984, Last Val Loss 2.322368860244751\n",
            "Batch 45, Last Train Loss 3.1860604286193848, Last Val Loss 3.5429272651672363\n",
            "Batch 50, Last Train Loss 2.8773632049560547, Last Val Loss 2.822544813156128\n",
            "Batch 55, Last Train Loss 2.354495048522949, Last Val Loss 1.2274950742721558\n",
            "Batch 60, Last Train Loss 2.0779480934143066, Last Val Loss 2.2288827896118164\n",
            "Batch 65, Last Train Loss 1.910990595817566, Last Val Loss 1.1979844570159912\n",
            "Batch 70, Last Train Loss 1.9763665199279785, Last Val Loss 1.7591667175292969\n",
            "Batch 75, Last Train Loss 1.9742485284805298, Last Val Loss 1.1718238592147827\n",
            "Batch 80, Last Train Loss 1.8118302822113037, Last Val Loss 1.0453163385391235\n",
            "Batch 85, Last Train Loss 1.8732385635375977, Last Val Loss 1.1173431873321533\n",
            "Batch 90, Last Train Loss 1.503553867340088, Last Val Loss 0.8533610105514526\n",
            "Batch 95, Last Train Loss 2.1760663986206055, Last Val Loss 1.3547724485397339\n",
            "Batch 100, Last Train Loss 1.3578981161117554, Last Val Loss 1.331978440284729\n",
            "Batch 105, Last Train Loss 1.187109351158142, Last Val Loss 1.1057305335998535\n",
            "Batch 110, Last Train Loss 2.1326420307159424, Last Val Loss 0.8207297921180725\n",
            "Batch 115, Last Train Loss 1.529942274093628, Last Val Loss 0.7897603511810303\n",
            "Batch 120, Last Train Loss 1.6007858514785767, Last Val Loss 1.255683183670044\n",
            "Batch 125, Last Train Loss 1.7448310852050781, Last Val Loss 0.9006292223930359\n",
            "Batch 130, Last Train Loss 1.0875861644744873, Last Val Loss 1.1813104152679443\n",
            "Batch 135, Last Train Loss 1.505243182182312, Last Val Loss 0.8752762675285339\n",
            "Batch 140, Last Train Loss 1.6518806219100952, Last Val Loss 0.6528425216674805\n",
            "Batch 145, Last Train Loss 1.396776795387268, Last Val Loss 1.323564887046814\n",
            "Batch 150, Last Train Loss 1.7373127937316895, Last Val Loss 1.283003807067871\n",
            "Batch 155, Last Train Loss 1.4195659160614014, Last Val Loss 0.8189259171485901\n",
            "Batch 160, Last Train Loss 1.67403244972229, Last Val Loss 0.9909512996673584\n",
            "Batch 165, Last Train Loss 1.3445065021514893, Last Val Loss 0.8893075585365295\n",
            "Batch 170, Last Train Loss 1.3972821235656738, Last Val Loss 0.6004682183265686\n",
            "Batch 175, Last Train Loss 1.5329421758651733, Last Val Loss 0.8269614577293396\n",
            "Batch 180, Last Train Loss 1.3499350547790527, Last Val Loss 1.0311073064804077\n",
            "Batch 185, Last Train Loss 1.4773797988891602, Last Val Loss 1.0983593463897705\n",
            "Batch 190, Last Train Loss 1.6371580362319946, Last Val Loss 2.980419158935547\n",
            "Batch 195, Last Train Loss 1.4082610607147217, Last Val Loss 0.7281914949417114\n",
            "Batch 200, Last Train Loss 1.386313796043396, Last Val Loss 0.6683247089385986\n",
            "Batch 205, Last Train Loss 0.968248724937439, Last Val Loss 1.4740604162216187\n",
            "Batch 210, Last Train Loss 1.0430481433868408, Last Val Loss 1.0788495540618896\n",
            "Batch 215, Last Train Loss 1.3114389181137085, Last Val Loss 0.6249789595603943\n",
            "Batch 220, Last Train Loss 1.3265787363052368, Last Val Loss 0.9389104843139648\n",
            "Batch 225, Last Train Loss 1.202297329902649, Last Val Loss 0.7907056212425232\n",
            "Batch 230, Last Train Loss 1.2857335805892944, Last Val Loss 0.9076670408248901\n",
            "Batch 235, Last Train Loss 1.0389995574951172, Last Val Loss 0.8789063692092896\n",
            "Batch 240, Last Train Loss 1.4231672286987305, Last Val Loss 0.5551300048828125\n",
            "Batch 245, Last Train Loss 1.0441021919250488, Last Val Loss 0.9917683005332947\n",
            "Batch 250, Last Train Loss 1.2177412509918213, Last Val Loss 0.6048216223716736\n",
            "Batch 255, Last Train Loss 1.5550553798675537, Last Val Loss 0.6875823736190796\n",
            "Batch 260, Last Train Loss 1.1080796718597412, Last Val Loss 1.4754102230072021\n",
            "Batch 265, Last Train Loss 1.1903375387191772, Last Val Loss 1.0320340394973755\n",
            "Batch 270, Last Train Loss 0.9330727458000183, Last Val Loss 1.0368345975875854\n",
            "Batch 275, Last Train Loss 1.124383568763733, Last Val Loss 1.0794835090637207\n",
            "Batch 280, Last Train Loss 1.0486596822738647, Last Val Loss 1.190577745437622\n",
            "Batch 285, Last Train Loss 1.187928557395935, Last Val Loss 0.8945070505142212\n",
            "Batch 290, Last Train Loss 0.9078794121742249, Last Val Loss 3.0383520126342773\n",
            "Batch 295, Last Train Loss 1.3499641418457031, Last Val Loss 1.1257946491241455\n",
            "Batch 300, Last Train Loss 0.9618512392044067, Last Val Loss 1.734112024307251\n",
            "Batch 305, Last Train Loss 0.9244586825370789, Last Val Loss 0.5855097770690918\n",
            "Batch 310, Last Train Loss 1.1596261262893677, Last Val Loss 1.0671933889389038\n",
            "Batch 315, Last Train Loss 1.2614713907241821, Last Val Loss 0.5611000657081604\n",
            "Batch 320, Last Train Loss 1.0222220420837402, Last Val Loss 0.8641722202301025\n",
            "Batch 325, Last Train Loss 0.8256201148033142, Last Val Loss 0.9887619018554688\n",
            "Batch 330, Last Train Loss 1.4097731113433838, Last Val Loss 0.5514378547668457\n",
            "Batch 335, Last Train Loss 1.2118802070617676, Last Val Loss 1.0968364477157593\n",
            "Batch 340, Last Train Loss 1.3082466125488281, Last Val Loss 0.5999709963798523\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b456c6841460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-b456c6841460>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, steps)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Batch {}, Last Train Loss {}, Last Val Loss {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_history_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b456c6841460>\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/t5/modeling_tf_t5.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, head_mask, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, labels, logits)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# make sure only labels that are not equal to -100 do not affect loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mactive_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mreduced_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mboolean_mask_v2\u001b[0;34m(tensor, mask, axis, name)\u001b[0m\n\u001b[1;32m   1829\u001b[0m   \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1830\u001b[0m   \"\"\"\n\u001b[0;32m-> 1831\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mboolean_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mboolean_mask\u001b[0;34m(tensor, mask, name, axis)\u001b[0m\n\u001b[1;32m   1751\u001b[0m       \u001b[0mshape_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mndims_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0mleading_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mndims_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m     tensor = reshape(\n\u001b[1;32m   1755\u001b[0m         \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(input, axis, keep_dims, name)\u001b[0m\n\u001b[1;32m   6623\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6624\u001b[0m       return prod_eager_fallback(\n\u001b[0;32m-> 6625\u001b[0;31m           input, axis, keep_dims=keep_dims, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   6626\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6627\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mprod_eager_fallback\u001b[0;34m(input, axis, keep_dims, name, ctx)\u001b[0m\n\u001b[1;32m   6655\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"keep_dims\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tidx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6656\u001b[0m   _result = _execute.execute(b\"Prod\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 6657\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   6658\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6659\u001b[0m     _execute.record_gradient(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "lyHiZNFHB_k0",
        "outputId": "fa8de59d-cef1-469a-d747-c9484ed8daba"
      },
      "source": [
        "### Evaluation ###\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(loss_history_train)\r\n",
        "plt.plot(loss_history_val)\r\n",
        "plt.title('Model Loss')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.xlabel('# Batch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTwYVuPPDKbz",
        "outputId": "16eee46d-f685-4690-dcc3-091b386e3efe"
      },
      "source": [
        "### Evaluation ###\r\n",
        "\r\n",
        "# Taken from https://en.wikipedia.org/wiki/Beijing\r\n",
        "article = \"Beijing (/ˌbeɪˈdʒɪŋ/ BAY-JING[10][11] Mandarin pronunciation: [pèi.tɕíŋ] (About this soundlisten)), alternatively romanized as Peking[12] (/ˌpiˈkɪŋ/ PEE-KING),[13] is the capital of the People's Republic of China. It is the world's most populous national capital city, with over 21 million residents within an administrative area of 16,410.5 km2 (6336 sq. mi.).[4] It is located in Northern China, is governed as a municipality under the direct administration of the State Council with 16 urban, suburban, and rural districts.[14] Beijing is mostly surrounded by Hebei Province with the exception of neighboring Tianjin to the southeast; together, the three divisions form the Jingjinji megalopolis and the national capital region of China.[15] \\\r\n",
        "Beijing is a global city, and one of the world's leading centers for culture, diplomacy and politics, business and economics, education, language, and science and technology. A megacity, Beijing is the second-largest Chinese city by urban population after Shanghai and is the nation's cultural, educational, and political center.[16] It is home to the headquarters of most of China's largest state-owned companies and houses the largest number of Fortune Global 500 companies in the world, as well as the world's four biggest financial institutions.[17][18] Beijing is the billionaire capital of the world with the highest number of billionaires living in the city.[19][20] It is also a major hub for the national highway, expressway, railway, and high-speed rail networks. The Beijing Capital International Airport has been the second busiest in the world by passenger traffic since 2010,[21] and, as of 2016, the city's subway network is the busiest and longest in the world. The Beijing Daxing International Airport, a second international airport in Beijing, is the largest single-structure airport terminal in the world.[22][23] \\\r\n",
        "Combining both modern and traditional style architectures, Beijing is one of the oldest cities in the world, with a rich history dating back three millennia. As the last of the Four Great Ancient Capitals of China, Beijing has been the political center of the country for most of the past eight centuries,[24] and was the largest city in the world by population for much of the second millennium AD.[25] With mountains surrounding the inland city on three sides, in addition to the old inner and outer city walls, Beijing was strategically poised and developed to be the residence of the emperor and thus was the perfect location for the imperial capital. The city is renowned for its opulent palaces, temples, parks, gardens, tombs, walls and gates.[26] It has seven UNESCO World Heritage Sites—the Forbidden City, Temple of Heaven, Summer Palace, Ming Tombs, Zhoukoudian, and parts of the Great Wall and the Grand Canal—all of which are popular tourist locations.[27] Siheyuans, the city's traditional housing style, and hutongs, the narrow alleys between siheyuans, are major tourist attractions and are common in urban Beijing. \\\r\n",
        "Many of Beijing's 91 universities[28] consistently rank among the best in the Asia Pacific and the world.[29][30] Beijing is home to the two best universities (Tsinghua and Peking) in the Asia Pacific and emerging countries.[31][32] Beijing CBD is a center for Beijing's economic expansion, with the ongoing or recently completed construction of multiple skyscrapers. Beijing's Zhongguancun area is a world leading center of scientific and technological innovation as well as entrepreneurship. Beijing has been ranked the No.1 city in the world for scientific research as tracked by the Nature Index since 2016.[33][34] The city has hosted numerous international and national sporting events, the most notable being the 2008 Summer Olympics and 2008 Summer Paralympics Games. Beijing will become the first city ever to host both the Summer and Winter Olympics,[35] and also the first city ever to host both the Summer and Winter Paralympics.[36] Beijing hosts 172 foreign embassies as well as the headquarters of the Asian Infrastructure Investment Bank (AIIB), the Shanghai Cooperation Organisation (SCO) and the Silk Road Fund. \"\r\n",
        "\r\n",
        "inputs = f\"summarize: {str(article)}\"\r\n",
        "\r\n",
        "encoded_query = tokenizer(inputs, return_tensors='tf', pad_to_max_length=True, truncation=True, max_length=encoder_max_len)\r\n",
        "\r\n",
        "input_ids = encoded_query[\"input_ids\"]\r\n",
        "attention_mask = encoded_query[\"attention_mask\"]\r\n",
        "\r\n",
        "generated_answer = model.generate(input_ids, attention_mask=attention_mask, \r\n",
        "                                 max_length=decoder_max_len, top_p=0.95, top_k=50, repetition_penalty=2)\r\n",
        "decoded_answer = tokenizer.decode(generated_answer.numpy()[0])\r\n",
        "\r\n",
        "print(\"Answer: \", decoded_answer)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Answer:  <pad> Beijing is the world's most populous national capital city. Beijing is home to many of china’ largest state-owned companies and financial institutions a megacity based in Beijing eqiuan jinping. Beijing has been the last of the Four Great Ancient Capital cities of China ; it is now the world' premier cultural center & cultural center...</s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC6c0nZobngy"
      },
      "source": [
        "#### Translation\r\n",
        "\r\n",
        "On WMT English-Chinese dataset from 2020; T5 used WMT datasets for English-French & English-Romanian translation <br>\r\n",
        "\r\n",
        "Does not produce reasonable results on huggingface models as of now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BHP6fXUbLmT",
        "outputId": "a84280cc-2457-4391-8436-67b231835b80"
      },
      "source": [
        "### Installs ###\r\n",
        "\r\n",
        "# Needed for mT5\r\n",
        "!pip install -q transformers[sentencepiece]\r\n",
        "\r\n",
        "!pip install -q datasets\r\n",
        "!pip install -q transformers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.1MB 4.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eNTDddkhBul"
      },
      "source": [
        "### Imports ###\r\n",
        "\r\n",
        "import transformers\r\n",
        "import numpy as np\r\n",
        "from datasets import load_dataset\r\n",
        "\r\n",
        "# If import error below, restart session; reinstall transformers\r\n",
        "from transformers import AutoTokenizer, TFXLMRobertaForMaskedLM"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "bcf8c1cd5e444edca20ded67aa2188f0",
            "ec116f6156c1451a83dc5a818bf76758",
            "c6a520240b084b5e96af201dd93cd963",
            "6c079d76ea8b4c008661ce3d83685fc1",
            "71c7998a8ead4eb897fcc11c01ff2e3b",
            "c6b4d0278f39446790d8012dbf7fbd75",
            "74e05134f523405698f488d1f10ddb75",
            "0d40b9a5c44847fdaf06f4e6c24a3e92",
            "38f62227a71343e5959d30a6eac62459",
            "72db4b475b4240358eefe3af273a1142",
            "f9f6efaa94ab4519b38c15f4eb9dd29e",
            "a909d8cd2d654850b6c923ac09f89aa8",
            "3b1f9e511c3a4bc08d24dc9b600df23a",
            "6f29dd0abf4e48a0b9432ec1c9d13a2a",
            "b8c12108a4264d9fa652c9631c158190",
            "2bee6fb1276a43c585775275796d2b34"
          ]
        },
        "id": "BFsLYUVLc7E6",
        "outputId": "5478324a-3c22-43c1-d771-60259b878761"
      },
      "source": [
        "### Data ###\r\n",
        "\r\n",
        "# Dict of form: dict_keys(['answers', 'context', 'id', 'question', 'title'])\r\n",
        "train_ds = load_dataset(\"wmt20_mlqe_task2\", \"en-zh\", split='train')\r\n",
        "valid_ds = load_dataset(\"wmt20_mlqe_task2\", \"en-zh\", split='validation')\r\n",
        "\r\n",
        "print(\"Example: \", next(iter(train_ds))[\"translation\"])\r\n",
        "\r\n",
        "# Pretrained TFXLM - mT5 shows even worse results as no supervised pre-training\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\r\n",
        "\r\n",
        "encoder_max_len = 20\r\n",
        "decoder_max_len = 20\r\n",
        "batch_size = 4\r\n",
        "buffer_size = 1000\r\n",
        "\r\n",
        "ntrain = len(train_ds)\r\n",
        "nvalid = len(valid_ds)\r\n",
        "steps = int(np.ceil(ntrain/batch_size))\r\n",
        "valid_steps = int(np.ceil(nvalid/batch_size))\r\n",
        "\r\n",
        "def tokenize(example, en_zh=False):\r\n",
        "    \"\"\"\r\n",
        "    Prepares input example for model\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    en = example['translation']['en']\r\n",
        "    zh = example['translation']['zh']\r\n",
        "\r\n",
        "    if en_zh:\r\n",
        "        inputs = f\"translate: {str(en)}\"\r\n",
        "        targets = f\"{str(zh)}\"\r\n",
        "    else:\r\n",
        "        inputs = f\"translate: {str(zh)}\"\r\n",
        "        targets = f\"{str(en)}\"\r\n",
        "\r\n",
        "    # TODO: Do we need those two diff. input types?\r\n",
        "    encoder_inputs = tokenizer(inputs, truncation=True, \r\n",
        "                              return_tensors='tf', padding=\"max_length\", max_length=encoder_max_len)\r\n",
        "    \r\n",
        "    decoder_inputs = tokenizer(targets, truncation=True, \r\n",
        "                               return_tensors='tf', padding=\"max_length\", max_length=decoder_max_len)\r\n",
        "    \r\n",
        "    outputs = {'input_ids': encoder_inputs['input_ids'][0], 'attention_mask': encoder_inputs['attention_mask'][0], \r\n",
        "               'labels': decoder_inputs['input_ids'][0], 'decoder_attention_mask': decoder_inputs['attention_mask'][0]}\r\n",
        "    return outputs\r\n",
        "\r\n",
        "def to_tf_dataset(dataset): \r\n",
        "  \"\"\"\r\n",
        "  Turns dataset into a TF compatible dataset; TODO: Combine with tokenize?  / Load TF dataset directly by loading Squad from tfds\r\n",
        "  \"\"\" \r\n",
        "  columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\r\n",
        "  dataset.set_format(type='tensorflow', columns=columns)\r\n",
        "  return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \r\n",
        "                'labels':tf.int32, 'decoder_attention_mask':tf.int32,  }\r\n",
        "  return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \r\n",
        "                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None])}\r\n",
        "  ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\r\n",
        "  return ds\r\n",
        "\r\n",
        "\r\n",
        "train_ds = train_ds.map(tokenize)\r\n",
        "valid_ds = valid_ds.map(tokenize)\r\n",
        "\r\n",
        "train_ds = to_tf_dataset(train_ds)\r\n",
        "valid_ds = to_tf_dataset(valid_ds)\r\n",
        "\r\n",
        "train_ds = train_ds.shuffle(buffer_size).batch(batch_size)\r\n",
        "valid_ds = valid_ds.shuffle(buffer_size).batch(batch_size)\r\n",
        "\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset wmt20_mlqe_task2 (/root/.cache/huggingface/datasets/wmt20_mlqe_task2/en-zh/1.1.0/9981db758dc33c011f45b9d30ad11c6bc427c341c72fd6dc9e5a994f6da3b046)\n",
            "Reusing dataset wmt20_mlqe_task2 (/root/.cache/huggingface/datasets/wmt20_mlqe_task2/en-zh/1.1.0/9981db758dc33c011f45b9d30ad11c6bc427c341c72fd6dc9e5a994f6da3b046)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Example:  {'en': 'the last conquistador then rides on with his sword drawn .', 'zh': '最后 的 征服者 骑着 他 的 剑 继续前进 .'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcf8c1cd5e444edca20ded67aa2188f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38f62227a71343e5959d30a6eac62459",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9OT1OwQhStW",
        "outputId": "7043f0e1-4620-4008-d720-1ae433b031e0"
      },
      "source": [
        "### Eager Modelling ###\r\n",
        "\r\n",
        "model = TFXLMRobertaForMaskedLM.from_pretrained(\"jplu/tf-xlm-roberta-base\")\r\n",
        "\r\n",
        "learning_rate = 1e-5\r\n",
        "\r\n",
        "loss_object = tf.keras.metrics.Mean(name='loss') \r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\r\n",
        "\r\n",
        "loss_history_train = []\r\n",
        "loss_history_val = []\r\n",
        "\r\n",
        "def train_step(data):\r\n",
        "    x = data\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        # > Feeds it just into TFT5ForConditionalGeneration; training=True turns on dropout\r\n",
        "        outputs = model(x, training=True)\r\n",
        "        # TODO: Manually compute loss; not have transformer autocompute it\r\n",
        "        loss = outputs[0]  \r\n",
        "        # Reduce loss to single digit\r\n",
        "        loss = tf.reduce_mean(loss)\r\n",
        "\r\n",
        "    loss_history_train.append(loss.numpy().mean())\r\n",
        "    # Calculate grads & update\r\n",
        "    grads = tape.gradient(loss, model.trainable_variables)    \r\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n",
        "    \r\n",
        "def test_step(data):\r\n",
        "    x = data\r\n",
        "    output = model(x, training=False)\r\n",
        "    loss = output[0]\r\n",
        "    loss = tf.reduce_mean(loss)\r\n",
        "    loss_history_val.append(loss.numpy().mean())\r\n",
        "\r\n",
        "def train(epochs, steps=-1):\r\n",
        "  for epoch in range(epochs):\r\n",
        "    for (batch, (train, val)) in enumerate(zip(train_ds, valid_ds)):\r\n",
        "      train_step(train)\r\n",
        "      test_step(val)\r\n",
        "      if batch % 5 == 0:\r\n",
        "        print('Batch {}, Last Train Loss {}, Last Val Loss {}'.format(batch, loss_history_train[-1], loss_history_val[-1]))\r\n",
        "\r\n",
        "      if batch == steps:\r\n",
        "        break \r\n",
        "\r\n",
        "    print ('Epoch {} finished'.format(epoch))\r\n",
        "\r\n",
        "train(epochs=2, steps=500)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFXLMRobertaForMaskedLM.\n",
            "\n",
            "All the layers of TFXLMRobertaForMaskedLM were initialized from the model checkpoint at jplu/tf-xlm-roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForMaskedLM for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Batch 0, Last Train Loss 24.055482864379883, Last Val Loss 20.661113739013672\n",
            "Batch 5, Last Train Loss 9.834460258483887, Last Val Loss 9.746481895446777\n",
            "Batch 10, Last Train Loss 7.3413987159729, Last Val Loss 7.716361999511719\n",
            "Batch 15, Last Train Loss 8.128362655639648, Last Val Loss 7.010308265686035\n",
            "Batch 20, Last Train Loss 8.930416107177734, Last Val Loss 7.637303352355957\n",
            "Batch 25, Last Train Loss 7.020506381988525, Last Val Loss 7.0156683921813965\n",
            "Batch 30, Last Train Loss 8.167766571044922, Last Val Loss 7.932093620300293\n",
            "Batch 35, Last Train Loss 6.909090995788574, Last Val Loss 8.016721725463867\n",
            "Batch 40, Last Train Loss 7.923210144042969, Last Val Loss 7.031032562255859\n",
            "Batch 45, Last Train Loss 8.134921073913574, Last Val Loss 6.515093803405762\n",
            "Batch 50, Last Train Loss 6.85300350189209, Last Val Loss 6.941930294036865\n",
            "Batch 55, Last Train Loss 8.123805046081543, Last Val Loss 6.784092903137207\n",
            "Batch 60, Last Train Loss 7.664870262145996, Last Val Loss 6.69750452041626\n",
            "Batch 65, Last Train Loss 5.941651344299316, Last Val Loss 6.599776268005371\n",
            "Batch 70, Last Train Loss 8.067425727844238, Last Val Loss 8.849550247192383\n",
            "Batch 75, Last Train Loss 6.510737419128418, Last Val Loss 6.9327545166015625\n",
            "Batch 80, Last Train Loss 6.434304714202881, Last Val Loss 6.947214603424072\n",
            "Batch 85, Last Train Loss 7.243135929107666, Last Val Loss 7.470428466796875\n",
            "Batch 90, Last Train Loss 7.681960105895996, Last Val Loss 6.277872562408447\n",
            "Batch 95, Last Train Loss 6.6328020095825195, Last Val Loss 7.640500545501709\n",
            "Batch 100, Last Train Loss 6.527219295501709, Last Val Loss 9.309410095214844\n",
            "Batch 105, Last Train Loss 6.729360103607178, Last Val Loss 7.369116306304932\n",
            "Batch 110, Last Train Loss 8.372856140136719, Last Val Loss 6.457521915435791\n",
            "Batch 115, Last Train Loss 7.628893852233887, Last Val Loss 7.534781455993652\n",
            "Batch 120, Last Train Loss 6.734086036682129, Last Val Loss 6.3225250244140625\n",
            "Batch 125, Last Train Loss 7.541905403137207, Last Val Loss 8.211000442504883\n",
            "Batch 130, Last Train Loss 7.196406364440918, Last Val Loss 6.818301200866699\n",
            "Batch 135, Last Train Loss 8.412328720092773, Last Val Loss 7.782083034515381\n",
            "Batch 140, Last Train Loss 6.2198357582092285, Last Val Loss 7.006402015686035\n",
            "Batch 145, Last Train Loss 6.44455623626709, Last Val Loss 6.189380645751953\n",
            "Batch 150, Last Train Loss 6.1773552894592285, Last Val Loss 6.815335273742676\n",
            "Batch 155, Last Train Loss 7.046614646911621, Last Val Loss 7.250124454498291\n",
            "Batch 160, Last Train Loss 5.999414920806885, Last Val Loss 6.172795295715332\n",
            "Batch 165, Last Train Loss 6.451006889343262, Last Val Loss 5.828237533569336\n",
            "Batch 170, Last Train Loss 6.969752311706543, Last Val Loss 6.071042537689209\n",
            "Batch 175, Last Train Loss 6.732448577880859, Last Val Loss 6.198202610015869\n",
            "Batch 180, Last Train Loss 6.85656213760376, Last Val Loss 6.241733551025391\n",
            "Batch 185, Last Train Loss 8.010336875915527, Last Val Loss 6.696540832519531\n",
            "Batch 190, Last Train Loss 6.358259677886963, Last Val Loss 6.177757263183594\n",
            "Batch 195, Last Train Loss 6.2682013511657715, Last Val Loss 5.801807403564453\n",
            "Batch 200, Last Train Loss 6.254044532775879, Last Val Loss 7.188641548156738\n",
            "Batch 205, Last Train Loss 6.831803798675537, Last Val Loss 7.576312065124512\n",
            "Batch 210, Last Train Loss 7.376315116882324, Last Val Loss 7.642670631408691\n",
            "Batch 215, Last Train Loss 6.70364236831665, Last Val Loss 5.830371856689453\n",
            "Batch 220, Last Train Loss 6.517353057861328, Last Val Loss 7.040572166442871\n",
            "Batch 225, Last Train Loss 6.417993068695068, Last Val Loss 6.147659778594971\n",
            "Batch 230, Last Train Loss 6.526442050933838, Last Val Loss 6.723492622375488\n",
            "Batch 235, Last Train Loss 6.307215690612793, Last Val Loss 6.873915672302246\n",
            "Batch 240, Last Train Loss 6.00405740737915, Last Val Loss 8.392696380615234\n",
            "Batch 245, Last Train Loss 7.4401445388793945, Last Val Loss 7.160349369049072\n",
            "Epoch 0 finished\n",
            "Batch 0, Last Train Loss 6.539641380310059, Last Val Loss 7.552402496337891\n",
            "Batch 5, Last Train Loss 6.277495384216309, Last Val Loss 6.508299827575684\n",
            "Batch 10, Last Train Loss 6.324077129364014, Last Val Loss 7.290907382965088\n",
            "Batch 15, Last Train Loss 5.880025386810303, Last Val Loss 6.519957065582275\n",
            "Batch 20, Last Train Loss 6.755338191986084, Last Val Loss 5.958640098571777\n",
            "Batch 25, Last Train Loss 6.529753684997559, Last Val Loss 6.3553361892700195\n",
            "Batch 30, Last Train Loss 6.701959133148193, Last Val Loss 6.354918479919434\n",
            "Batch 35, Last Train Loss 6.731657981872559, Last Val Loss 6.473829746246338\n",
            "Batch 40, Last Train Loss 6.271251678466797, Last Val Loss 6.524815559387207\n",
            "Batch 45, Last Train Loss 7.332529544830322, Last Val Loss 6.753221035003662\n",
            "Batch 50, Last Train Loss 7.042824745178223, Last Val Loss 6.133872032165527\n",
            "Batch 55, Last Train Loss 6.1276044845581055, Last Val Loss 7.257730007171631\n",
            "Batch 60, Last Train Loss 6.775810241699219, Last Val Loss 6.393582344055176\n",
            "Batch 65, Last Train Loss 7.121835231781006, Last Val Loss 6.156214237213135\n",
            "Batch 70, Last Train Loss 5.286073207855225, Last Val Loss 6.458357810974121\n",
            "Batch 75, Last Train Loss 6.152222633361816, Last Val Loss 6.063483715057373\n",
            "Batch 80, Last Train Loss 6.384759902954102, Last Val Loss 6.798463344573975\n",
            "Batch 85, Last Train Loss 7.0086846351623535, Last Val Loss 6.083643913269043\n",
            "Batch 90, Last Train Loss 7.065948486328125, Last Val Loss 5.819845676422119\n",
            "Batch 95, Last Train Loss 7.018231391906738, Last Val Loss 7.474778652191162\n",
            "Batch 100, Last Train Loss 5.779598236083984, Last Val Loss 7.406594753265381\n",
            "Batch 105, Last Train Loss 6.1262407302856445, Last Val Loss 8.606878280639648\n",
            "Batch 110, Last Train Loss 6.570298671722412, Last Val Loss 6.605428218841553\n",
            "Batch 115, Last Train Loss 6.3848676681518555, Last Val Loss 6.21234130859375\n",
            "Batch 120, Last Train Loss 6.772850036621094, Last Val Loss 6.129076957702637\n",
            "Batch 125, Last Train Loss 5.918158531188965, Last Val Loss 6.104498863220215\n",
            "Batch 130, Last Train Loss 5.949993133544922, Last Val Loss 5.819584846496582\n",
            "Batch 135, Last Train Loss 7.148855686187744, Last Val Loss 7.063958168029785\n",
            "Batch 140, Last Train Loss 5.626442909240723, Last Val Loss 5.896178245544434\n",
            "Batch 145, Last Train Loss 5.599120616912842, Last Val Loss 7.448530673980713\n",
            "Batch 150, Last Train Loss 7.924685478210449, Last Val Loss 7.4093122482299805\n",
            "Batch 155, Last Train Loss 5.704987525939941, Last Val Loss 6.411594390869141\n",
            "Batch 160, Last Train Loss 6.821242332458496, Last Val Loss 6.39070987701416\n",
            "Batch 165, Last Train Loss 6.554444313049316, Last Val Loss 7.286166191101074\n",
            "Batch 170, Last Train Loss 6.244264125823975, Last Val Loss 5.972216606140137\n",
            "Batch 175, Last Train Loss 6.041932582855225, Last Val Loss 7.001224517822266\n",
            "Batch 180, Last Train Loss 6.3699774742126465, Last Val Loss 5.963217735290527\n",
            "Batch 185, Last Train Loss 6.273704528808594, Last Val Loss 6.36197566986084\n",
            "Batch 190, Last Train Loss 6.1795501708984375, Last Val Loss 7.192929267883301\n",
            "Batch 195, Last Train Loss 6.319687843322754, Last Val Loss 7.449571132659912\n",
            "Batch 200, Last Train Loss 6.222994804382324, Last Val Loss 6.328802585601807\n",
            "Batch 205, Last Train Loss 6.243083953857422, Last Val Loss 6.078269958496094\n",
            "Batch 210, Last Train Loss 6.683969020843506, Last Val Loss 6.169483661651611\n",
            "Batch 215, Last Train Loss 5.793272495269775, Last Val Loss 5.713885307312012\n",
            "Batch 220, Last Train Loss 6.3468499183654785, Last Val Loss 6.5222368240356445\n",
            "Batch 225, Last Train Loss 6.699427127838135, Last Val Loss 6.689505100250244\n",
            "Batch 230, Last Train Loss 6.131404399871826, Last Val Loss 6.179358005523682\n",
            "Batch 235, Last Train Loss 6.6667799949646, Last Val Loss 5.914539337158203\n",
            "Batch 240, Last Train Loss 6.114438533782959, Last Val Loss 5.184967041015625\n",
            "Batch 245, Last Train Loss 6.303281784057617, Last Val Loss 6.862519264221191\n",
            "Epoch 1 finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "7SsFb0mBo4mV",
        "outputId": "acba9704-009c-4149-bb60-0f4802efbefd"
      },
      "source": [
        "### Evaluation ###\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(loss_history_train)\r\n",
        "plt.plot(loss_history_val)\r\n",
        "plt.title('Model Loss')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.xlabel('# Batch')\r\n",
        "plt.legend(['train', 'val'], loc='upper left')\r\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iC_M9eBhz7y",
        "outputId": "03fdd815-44bc-4fe5-e9f5-1055da8c1f2e"
      },
      "source": [
        "### Evaluation ###\r\n",
        "\r\n",
        "en = \"the conquistador then rides on with his sword drawn.\"\r\n",
        "zh = \"最后 的 征服者 骑着 他 的 剑 继续前进 .\"\r\n",
        "\r\n",
        "inputs = f\"translate: {str(zh)}\"\r\n",
        "\r\n",
        "\r\n",
        "encoded_query = tokenizer(inputs, return_tensors='tf', padding=\"max_length\", truncation=True, max_length=encoder_max_len)\r\n",
        "\r\n",
        "input_ids = encoded_query[\"input_ids\"]\r\n",
        "attention_mask = encoded_query[\"attention_mask\"]\r\n",
        "\r\n",
        "generated_answer = model.generate(input_ids, attention_mask=attention_mask,\r\n",
        "                                 max_length=decoder_max_len+1, top_p=0.95, top_k=50, repetition_penalty=2)\r\n",
        "\r\n",
        "decoded_answer = tokenizer.decode(generated_answer.numpy()[0])\r\n",
        "\r\n",
        "print(\"Answer: \", decoded_answer)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer:  <s> translate: 最后 的 征服者 骑着 他 的 </s>,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNFDzmw3WaYn"
      },
      "source": [
        "#### Distributed Training Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjzWDhQr8-lM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "928eRHoFXUSM"
      },
      "source": [
        "### TODOs\r\n",
        "\r\n",
        "- Visualize Losses with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE-Uu5WHXc_a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}