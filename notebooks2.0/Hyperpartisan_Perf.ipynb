{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HyperpartisanPerformer_Short.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xgmb4TgpBlVR",
        "_tyjPdyORIbR",
        "k2M1klptIve-",
        "cZzLI2YtIxrU"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b6a94caf4a94e8b9e58c5e9cec05a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5dc05341bb64d7286e82af6dc24cf6c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b0d85e68e17f48f694dfd5440b1d49ef",
              "IPY_MODEL_be7e9d3e1df2437ea18fdcdcfd0f490d"
            ]
          }
        },
        "c5dc05341bb64d7286e82af6dc24cf6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0d85e68e17f48f694dfd5440b1d49ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ffa40f995387425e8ab389599e5a97c4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebbe77e4c314435e8642a092e6962d10"
          }
        },
        "be7e9d3e1df2437ea18fdcdcfd0f490d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36b1063415a447f7acc60e7b9a996962",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 500/500 [00:55&lt;00:00,  9.07ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c3f3dc0026646a0bdebe41918a86bbc"
          }
        },
        "ffa40f995387425e8ab389599e5a97c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebbe77e4c314435e8642a092e6962d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36b1063415a447f7acc60e7b9a996962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c3f3dc0026646a0bdebe41918a86bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67099d0d3f1741288b2516220a930d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b5369103c834905a0e866ae7624a2e7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0baf8099548645978d641cc48fb3bfce",
              "IPY_MODEL_6d1affc780de4364ab43dc05f0338024"
            ]
          }
        },
        "2b5369103c834905a0e866ae7624a2e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0baf8099548645978d641cc48fb3bfce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e113e1f7cd0f4f1eb87b050ae4443527",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_498f35710b4e4816892e593342c75631"
          }
        },
        "6d1affc780de4364ab43dc05f0338024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81c081473c0a4c4ca052cdffcfb63456",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [00:50&lt;00:00,  1.99ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_481c2bf4723144139063fd6dcb03d245"
          }
        },
        "e113e1f7cd0f4f1eb87b050ae4443527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "498f35710b4e4816892e593342c75631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81c081473c0a4c4ca052cdffcfb63456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "481c2bf4723144139063fd6dcb03d245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U_kmaCcyoY_",
        "outputId": "19e4418e-88df-467b-e115-a338e1750acb"
      },
      "source": [
        "!git clone https://github.com/Muennighoff/transformers.git\r\n",
        "\r\n",
        "!cd trans*; pip install -q -e '.[dev]'\r\n",
        "%cd transformers/src\r\n",
        "\r\n",
        "!pip install -q datasets\r\n",
        "!pip install -q bleach"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "/content/transformers/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgmb4TgpBlVR"
      },
      "source": [
        "##### Activate TPU (only for TF)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAxqPNYVBnS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20048dcb-84c8-406a-ff4f-b595b6e68dd0"
      },
      "source": [
        "# If this cell takes very long to run; factory reset and run this cell the very first\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "try:\r\n",
        "    # Locate TPU\r\n",
        "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\r\n",
        "    # Establish communication / Locates TPU on the network\r\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER)\r\n",
        "    # Connect\r\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\r\n",
        "    # Start TPU\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\r\n",
        "    # Set strategy\r\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n",
        "\r\n",
        "    print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\r\n",
        "\r\n",
        "except ValueError:\r\n",
        "    print(\"No TPU found\")\r\n",
        "\r\n",
        "# Check devices\r\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.52.149.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.52.149.10:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.52.149.10:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.52.149.10:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of accelerators:  8\n",
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tyjPdyORIbR"
      },
      "source": [
        "##### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPT_u5RGyqm2"
      },
      "source": [
        "from datasets import load_dataset\r\n",
        "from transformers import BertTokenizerFast\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import bleach\r\n",
        "import re\r\n",
        "\r\n",
        "import torch"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_-Q6gq-y9bO",
        "outputId": "0fb56986-1e6c-4d2d-a2c7-dfc5b91ab401"
      },
      "source": [
        "dataset = load_dataset('hyperpartisan_news_detection', 'byarticle')\r\n",
        "dataset"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:datasets.builder:Reusing dataset hyperpartisan_news_detection (/root/.cache/huggingface/datasets/hyperpartisan_news_detection/byarticle/1.0.0/60aa536d5067f21aacb9ab08b94548649fd241c1e3cf6bb643d0a4a1b20bcf25)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'title', 'hyperpartisan', 'url', 'published_at'],\n",
              "        num_rows: 645\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSfK2ZGq0sYN"
      },
      "source": [
        "def clean_text(text, label):\r\n",
        "    \"\"\" Clean the input text and remove special characters \"\"\"\r\n",
        "    text = bleach.clean(text,strip=True)\r\n",
        "    text = text.replace('<p>', '')\r\n",
        "    text = text.replace('</p>', '')\r\n",
        "    text = text.replace('\\n', '')\r\n",
        "    text = text.replace('&amp;#160;', '')\r\n",
        "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\r\n",
        "    if str(label) == 'True':\r\n",
        "        new_label = 1\r\n",
        "    else:\r\n",
        "        new_label = 0\r\n",
        "    return text, new_label\r\n",
        "\r\n",
        "\r\n",
        "def convert_to_features(example):\r\n",
        "    # Tokenize contexts and questions (as pairs of inputs)\r\n",
        "    text_, target_ = clean_text(example['text'], example['hyperpartisan'])\r\n",
        "    encodings = tokenizer.encode_plus(text_, pad_to_max_length=True, max_length=2048,\r\n",
        "                                      add_special_tokens=True,\r\n",
        "                                      return_token_type_ids=False,\r\n",
        "                                      return_attention_mask=True,\r\n",
        "                                      padding='max_length', truncation=True,\r\n",
        "                                      )\r\n",
        "    targets = torch.tensor(target_,dtype=torch.long)\r\n",
        "    \r\n",
        "    encodings.update({'labels': targets,\r\n",
        "                      'attention_mask': encodings['attention_mask']})\r\n",
        "    return encodings"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "8b6a94caf4a94e8b9e58c5e9cec05a9b",
            "c5dc05341bb64d7286e82af6dc24cf6c",
            "b0d85e68e17f48f694dfd5440b1d49ef",
            "be7e9d3e1df2437ea18fdcdcfd0f490d",
            "ffa40f995387425e8ab389599e5a97c4",
            "ebbe77e4c314435e8642a092e6962d10",
            "36b1063415a447f7acc60e7b9a996962",
            "4c3f3dc0026646a0bdebe41918a86bbc",
            "67099d0d3f1741288b2516220a930d35",
            "2b5369103c834905a0e866ae7624a2e7",
            "0baf8099548645978d641cc48fb3bfce",
            "6d1affc780de4364ab43dc05f0338024",
            "e113e1f7cd0f4f1eb87b050ae4443527",
            "498f35710b4e4816892e593342c75631",
            "81c081473c0a4c4ca052cdffcfb63456",
            "481c2bf4723144139063fd6dcb03d245"
          ]
        },
        "id": "tr5JAB8V1fTM",
        "outputId": "578173ff-bdca-435e-e61d-26261ffbca77"
      },
      "source": [
        "## Take subset of data\r\n",
        "#train_size = 20000\r\n",
        "#val_size = 5000\r\n",
        "\r\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\r\n",
        "\r\n",
        "#train_indices = np.random.randint(0, len(dataset['train']), train_size)\r\n",
        "#val_indices = np.random.randint(0, len(dataset['validation']), val_size)\r\n",
        "#train_dataset = dataset['train'].select(train_indices)\r\n",
        "#val_dataset = dataset['validation'].select(val_indices)\r\n",
        "\r\n",
        "\r\n",
        "train_dataset =  dataset['train'].select(range(0, 500)).map(convert_to_features, load_from_cache_file=False)\r\n",
        "val_dataset =  dataset['train'].select(range(500, 600)).map(convert_to_features, load_from_cache_file=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b6a94caf4a94e8b9e58c5e9cec05a9b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67099d0d3f1741288b2516220a930d35",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15rX550o7lMr",
        "outputId": "f88cb577-9527-4e02-e7da-93937c75e949"
      },
      "source": [
        "# Not perfect cleaning but better than nothing for now\r\n",
        "for i in dataset[\"train\"].select(range(1)):\r\n",
        "  print(i)\r\n",
        "  print(i.keys())\r\n",
        "  \r\n",
        "for i in dataset[\"train\"].select(range(1)):\r\n",
        "  print(clean_text(i[\"text\"], i[\"hyperpartisan\"]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'hyperpartisan': True, 'published_at': '2017-09-10', 'text': '<p>Money ( <a href=\"https://farm8.static.flickr.com/7020/6551534889_9c8ae52997.jpg\" type=\"external\">Image</a> by <a href=\"https://www.flickr.com/people/68751915@N05/\" type=\"external\">401(K) 2013</a>) <a href=\"https://creativecommons.org/licenses/by-sa/2.0/\" type=\"external\">Permission</a> <a type=\"internal\">Details</a> <a type=\"internal\">DMCA</a></p> No Pill Can Stop Tinnitus, But This 1 Weird Trick Can \\n<p>The walls are closing in on Congress.</p> \\n<p>Terrifying walls of water from Hurricanes Harvey and Irma, which, when the damage is totaled, could rise to a half trillion dollars. The Walls of War: The multi-trillion dollar ongoing cost of Afghanistan, Iraq and other interventions. The crumbling walls of the U.S. infrastructure, which need at least $3 trillion to be repaired or replaced. A wall of 11 million undocumented immigrants, whose deportation could easily cost $200 billion. The planned wall at the Mexican border, which some estimates place at $67 billion. Then there is the Wall of All, the $20 trillion national debt. The walls of debt are closing in.</p> \\n<p>At moments of crisis in our nation, in addition to invoking the assistance of Higher powers, we can call upon the Constitution for guidance.</p> \\n<p>Article I, Section 8, of the U.S. Constitution contains a long-forgotten provision, \"the coinage clause,\" which empowered Congress \"to coin (create) Money.\" The ability to create money to meet the needs of the nation is a sovereign power, which enables a nation to have control of its own destiny.</p> \\n<p>The same article indicates the Founders anticipated having to borrow money on the full faith and credit of the United States. Enter the Funding Act of 1790, which assumed and paid off the debt of the colonies and retired the financial obligations of the newly created states now united. This was a powerful, object lesson in debt retirement, relevant today.</p> \\n<p>It is abundantly clear from a plain reading of the coinage clause that the Founders never intended that the only way the government was to be funded was to borrow money.</p> \\n<p>The needs of the nation were to come from a system of not borrowing wherein money was a neutral value of exchange connecting resources, people and needs, without debt attached.</p> \\n<p>In 1913, the passage of the Federal Reserve Act ceded the constitutional power to create money (and control of our national destiny), to the Federal Reserve, a quasi-private central bank. At this fateful point, the only way money could be brought into being was to borrow it, whereby money became equated with debt. The money system transited from public control to private control, and there it has remained.</p> \\n<p>Instead of following the path set forth by the Founders to create money directly, our government became obliged to borrow from private banks, which assumed the sovereign power to create money from nothing and then loan it to the government, turning on its head the intention of the Founders.</p> \\n<p>As a member of Congress, I came to the conclusion that while the debate over taxation was interesting, it was wholly insufficient. One must first study how money is created, before one can sensibly have a discussion of how it is to be taxed.</p> \\n<p>With the help of staff, I spent a full five years working with legislative counsel to come up with a way to realign with the founding principles, to reclaim and to re-establish for our nation the sovereign power to create money.</p> \\n<p>The vehicle was H.R. 2990, the National Emergency Employment Defense (NEED Act), which articulates why the current debate over the debt ceiling should lead directly to a debate about monetary policy, and the origins of the debt-based economic system.</p> How To Easily Kill All Indoor Odor, Mold, And Bacteria &#8212; Without Lifting A Finger No More Tinnitus (Ear Ringing) If You Do This Immediately \\n<p>In our work on the NEED Act, we propound that the present monetary system has led to a concentration of wealth, expansion of national debt, excessive reliance on taxation, devaluation of the currency, increases in the cost of public infrastructure, unemployment and underemployment and the erosion of the ability of Congress to meet the needs of the American people.</p> \\n<p>This system has been a source of financial instability where the banks\\' ability to create money out of nothing has become a financial liability for the American taxpayers. When banks engaged in speculative lending, turning the financial system into a casino, they were bailed out while millions of Americans lost their homes. No surprise that today we are told there is not enough money for creating jobs, rebuilding America, health care, education and retirement security. But there is always money to bail out the banks.</p> \\n<p>Let us take the opportunity afforded in the debate over the debt ceiling to regain control of our sovereignty and our national destiny. We can have a future of abundance instead of poverty, but we must first take down the wall which separates us from our true sovereignty, the power to coin and create money.</p> \\n<p>Let us return to first principles, and reclaim the constitutional power to coin and create United States money and spend it into circulation to meet the needs of the nation and reduce taxes.</p> \\n<p>Two hundred and thirty years ago this month, delegates from 13 states gathered in a constitutional convention, which set the stage for ratification. Let us summon that same revolutionary spirit and its wisdom to guide us in the days ahead.</p> Seniors Can\\'t Get Enough of This Sweet Treat That Has Shown to Turn Back the Clock on Alzheimer\\'s From flickr.com: Money {MID-161793} \\n<p>Money ( <a href=\"https://farm8.static.flickr.com/7020/6551534889_9c8ae52997.jpg\" type=\"external\">Image</a> by <a href=\"https://www.flickr.com/people/68751915@N05/\" type=\"external\">401(K) 2013</a>) <a href=\"https://creativecommons.org/licenses/by-sa/2.0/\" type=\"external\">Permission</a> <a type=\"internal\">Details</a> <a type=\"internal\">DMCA</a></p> \\n<p>The walls are closing in on Congress.</p> \\n<p>Terrifying walls of water from Hurricanes Harvey and Irma, which, when the damage is totaled, could rise to a half trillion dollars. The Walls of War: The multi-trillion dollar ongoing cost of Afghanistan, Iraq and other interventions. The crumbling walls of the U.S. infrastructure, which need at least $3 trillion to be repaired or replaced. A wall of 11 million undocumented immigrants, whose deportation could easily cost $200 billion. The planned wall at the Mexican border, which some estimates place at $67 billion. Then there is the Wall of All, the $20 trillion national debt. The walls of debt are closing in.</p> \\n<p>At moments of crisis in our nation, in addition to invoking the assistance of Higher powers, we can call upon the Constitution for guidance.</p> \\n<p>Article I, Section 8, of the U.S. Constitution contains a long-forgotten provision, \"the coinage clause,\" which empowered Congress \"to coin (create) Money.\" The ability to create money to meet the needs of the nation is a sovereign power, which enables a nation to have control of its own destiny.</p> \\n<p>The same article indicates the Founders anticipated having to borrow money on the full faith and credit of the United States. Enter the Funding Act of 1790, which assumed and paid off the debt of the colonies and retired the financial obligations of the newly created states now united. This was a powerful, object lesson in debt retirement, relevant today.</p> \\n<p>It is abundantly clear from a plain reading of the coinage clause that the Founders never intended that the only way the government was to be funded was to borrow money.</p> \\n<p>The needs of the nation were to come from a system of not borrowing wherein money was a neutral value of exchange connecting resources, people and needs, without debt attached.</p> \\n<p>In 1913, the passage of the Federal Reserve Act ceded the constitutional power to create money (and control of our national destiny), to the Federal Reserve, a quasi-private central bank. At this fateful point, the only way money could be brought into being was to borrow it, whereby money became equated with debt. The money system transited from public control to private control, and there it has remained.</p> \\n<p>Instead of following the path set forth by the Founders to create money directly, our government became obliged to borrow from private banks, which assumed the sovereign power to create money from nothing and then loan it to the government, turning on its head the intention of the Founders.</p> \\n<p>As a member of Congress, I came to the conclusion that while the debate over taxation was interesting, it was wholly insufficient. One must first study how money is created, before one can sensibly have a discussion of how it is to be taxed.</p> \\n<p>With the help of staff, I spent a full five years working with legislative counsel to come up with a way to realign with the founding principles, to reclaim and to re-establish for our nation the sovereign power to create money.</p> \\n<p>The vehicle was H.R. 2990, the National Emergency Employment Defense (NEED Act), which articulates why the current debate over the debt ceiling should lead directly to a debate about monetary policy, and the origins of the debt-based economic system.</p> How To Easily Kill All Indoor Odor, Mold, And Bacteria &#8212; Without Lifting A Finger Trump to End the Dollar as We Know It by November 8, 2018?', 'title': 'Kucinich: Reclaiming the money power', 'url': 'https://www.opednews.com/articles/Kucinich-Reclaiming-the-m-by-Dennis-Kucinich-Banks_Debt_Funding_Money-170910-112.html'}\n",
            "dict_keys(['hyperpartisan', 'published_at', 'text', 'title', 'url'])\n",
            "('Money ( <a href=\"https://farm8.static.flickr.com/7020/6551534889_9c8ae52997.jpg\">Image</a> by <a href=\"https://www.flickr.com/people/68751915@N05/\">401(K) 2013</a>) <a href=\"https://creativecommons.org/licenses/by-sa/2.0/\">Permission</a> <a>Details</a> <a>DMCA</a> No Pill Can Stop Tinnitus, But This 1 Weird Trick Can The walls are closing in on Congress. Terrifying walls of water from Hurricanes Harvey and Irma, which, when the damage is totaled, could rise to a half trillion dollars. The Walls of War: The multi-trillion dollar ongoing cost of Afghanistan, Iraq and other interventions. The crumbling walls of the U.S. infrastructure, which need at least $3 trillion to be repaired or replaced. A wall of 11 million undocumented immigrants, whose deportation could easily cost $200 billion. The planned wall at the Mexican border, which some estimates place at $67 billion. Then there is the Wall of All, the $20 trillion national debt. The walls of debt are closing in. At moments of crisis in our nation, in addition to invoking the assistance of Higher powers, we can call upon the Constitution for guidance. Article I, Section 8, of the U.S. Constitution contains a long-forgotten provision, \"the coinage clause,\" which empowered Congress \"to coin (create) Money.\" The ability to create money to meet the needs of the nation is a sovereign power, which enables a nation to have control of its own destiny. The same article indicates the Founders anticipated having to borrow money on the full faith and credit of the United States. Enter the Funding Act of 1790, which assumed and paid off the debt of the colonies and retired the financial obligations of the newly created states now united. This was a powerful, object lesson in debt retirement, relevant today. It is abundantly clear from a plain reading of the coinage clause that the Founders never intended that the only way the government was to be funded was to borrow money. The needs of the nation were to come from a system of not borrowing wherein money was a neutral value of exchange connecting resources, people and needs, without debt attached. In 1913, the passage of the Federal Reserve Act ceded the constitutional power to create money (and control of our national destiny), to the Federal Reserve, a quasi-private central bank. At this fateful point, the only way money could be brought into being was to borrow it, whereby money became equated with debt. The money system transited from public control to private control, and there it has remained. Instead of following the path set forth by the Founders to create money directly, our government became obliged to borrow from private banks, which assumed the sovereign power to create money from nothing and then loan it to the government, turning on its head the intention of the Founders. As a member of Congress, I came to the conclusion that while the debate over taxation was interesting, it was wholly insufficient. One must first study how money is created, before one can sensibly have a discussion of how it is to be taxed. With the help of staff, I spent a full five years working with legislative counsel to come up with a way to realign with the founding principles, to reclaim and to re-establish for our nation the sovereign power to create money. The vehicle was H.R. 2990, the National Emergency Employment Defense (NEED Act), which articulates why the current debate over the debt ceiling should lead directly to a debate about monetary policy, and the origins of the debt-based economic system. How To Easily Kill All Indoor Odor, Mold, And Bacteria &#8212; Without Lifting A Finger No More Tinnitus (Ear Ringing) If You Do This Immediately In our work on the NEED Act, we propound that the present monetary system has led to a concentration of wealth, expansion of national debt, excessive reliance on taxation, devaluation of the currency, increases in the cost of public infrastructure, unemployment and underemployment and the erosion of the ability of Congress to meet the needs of the American people. This system has been a source of financial instability where the banks\\' ability to create money out of nothing has become a financial liability for the American taxpayers. When banks engaged in speculative lending, turning the financial system into a casino, they were bailed out while millions of Americans lost their homes. No surprise that today we are told there is not enough money for creating jobs, rebuilding America, health care, education and retirement security. But there is always money to bail out the banks. Let us take the opportunity afforded in the debate over the debt ceiling to regain control of our sovereignty and our national destiny. We can have a future of abundance instead of poverty, but we must first take down the wall which separates us from our true sovereignty, the power to coin and create money. Let us return to first principles, and reclaim the constitutional power to coin and create United States money and spend it into circulation to meet the needs of the nation and reduce taxes. Two hundred and thirty years ago this month, delegates from 13 states gathered in a constitutional convention, which set the stage for ratification. Let us summon that same revolutionary spirit and its wisdom to guide us in the days ahead. Seniors Can\\'t Get Enough of This Sweet Treat That Has Shown to Turn Back the Clock on Alzheimer\\'s From flickr.com: Money {MID-161793} Money ( <a href=\"https://farm8.static.flickr.com/7020/6551534889_9c8ae52997.jpg\">Image</a> by <a href=\"https://www.flickr.com/people/68751915@N05/\">401(K) 2013</a>) <a href=\"https://creativecommons.org/licenses/by-sa/2.0/\">Permission</a> <a>Details</a> <a>DMCA</a> The walls are closing in on Congress. Terrifying walls of water from Hurricanes Harvey and Irma, which, when the damage is totaled, could rise to a half trillion dollars. The Walls of War: The multi-trillion dollar ongoing cost of Afghanistan, Iraq and other interventions. The crumbling walls of the U.S. infrastructure, which need at least $3 trillion to be repaired or replaced. A wall of 11 million undocumented immigrants, whose deportation could easily cost $200 billion. The planned wall at the Mexican border, which some estimates place at $67 billion. Then there is the Wall of All, the $20 trillion national debt. The walls of debt are closing in. At moments of crisis in our nation, in addition to invoking the assistance of Higher powers, we can call upon the Constitution for guidance. Article I, Section 8, of the U.S. Constitution contains a long-forgotten provision, \"the coinage clause,\" which empowered Congress \"to coin (create) Money.\" The ability to create money to meet the needs of the nation is a sovereign power, which enables a nation to have control of its own destiny. The same article indicates the Founders anticipated having to borrow money on the full faith and credit of the United States. Enter the Funding Act of 1790, which assumed and paid off the debt of the colonies and retired the financial obligations of the newly created states now united. This was a powerful, object lesson in debt retirement, relevant today. It is abundantly clear from a plain reading of the coinage clause that the Founders never intended that the only way the government was to be funded was to borrow money. The needs of the nation were to come from a system of not borrowing wherein money was a neutral value of exchange connecting resources, people and needs, without debt attached. In 1913, the passage of the Federal Reserve Act ceded the constitutional power to create money (and control of our national destiny), to the Federal Reserve, a quasi-private central bank. At this fateful point, the only way money could be brought into being was to borrow it, whereby money became equated with debt. The money system transited from public control to private control, and there it has remained. Instead of following the path set forth by the Founders to create money directly, our government became obliged to borrow from private banks, which assumed the sovereign power to create money from nothing and then loan it to the government, turning on its head the intention of the Founders. As a member of Congress, I came to the conclusion that while the debate over taxation was interesting, it was wholly insufficient. One must first study how money is created, before one can sensibly have a discussion of how it is to be taxed. With the help of staff, I spent a full five years working with legislative counsel to come up with a way to realign with the founding principles, to reclaim and to re-establish for our nation the sovereign power to create money. The vehicle was H.R. 2990, the National Emergency Employment Defense (NEED Act), which articulates why the current debate over the debt ceiling should lead directly to a debate about monetary policy, and the origins of the debt-based economic system. How To Easily Kill All Indoor Odor, Mold, And Bacteria &#8212; Without Lifting A Finger Trump to End the Dollar as We Know It by November 8, 2018?', 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zBYS3lE7u6W",
        "outputId": "2a92db0f-d07b-4c2b-b634-2cd8092aad13"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['attention_mask', 'hyperpartisan', 'input_ids', 'labels', 'published_at', 'text', 'title', 'url'],\n",
              "    num_rows: 500\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2M1klptIve-"
      },
      "source": [
        "##### PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3gGdmroJVlP"
      },
      "source": [
        "columns = ['input_ids', 'attention_mask', 'labels']\r\n",
        "train_dataset.set_format(type='torch', columns=columns)\r\n",
        "val_dataset.set_format(type='torch', columns=columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JANsIVpf8urt"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n",
        "from transformers import BertForSequenceClassification, BertPerformerForSequenceClassification, BertPerformerConfig, BertConfig, Trainer, TrainingArguments\r\n",
        "\r\n",
        "from datasets import load_metric\r\n",
        "metric = load_metric(\"accuracy\")\r\n",
        "\r\n",
        "batch_size = 1\r\n",
        "lr = 1e-5/8\r\n",
        "\r\n",
        "args = TrainingArguments(\r\n",
        "    \"test\",\r\n",
        "    evaluation_strategy = \"steps\",\r\n",
        "    eval_steps=100,\r\n",
        "    logging_steps=100,\r\n",
        "    learning_rate=lr,\r\n",
        "    per_device_train_batch_size=batch_size,\r\n",
        "    per_device_eval_batch_size=batch_size,\r\n",
        "    num_train_epochs=5,\r\n",
        ")\r\n",
        "\r\n",
        "def compute_metrics(eval_pred):\r\n",
        "    predictions, labels = eval_pred\r\n",
        "    predictions = np.argmax(predictions, axis=1)\r\n",
        "    print(predictions)\r\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M3pp1HwJ9Bzv",
        "outputId": "b3b4e85f-fa47-4d5a-8e13-2317e12a2c94"
      },
      "source": [
        "config = BertPerformerConfig()\r\n",
        "\r\n",
        "config.max_position_embeddings = 2048\r\n",
        "\r\n",
        "model = BertPerformerForSequenceClassification(config)\r\n",
        "\r\n",
        "trainer = Trainer(\r\n",
        "    model,\r\n",
        "    args,\r\n",
        "    train_dataset=train_dataset,\r\n",
        "    eval_dataset=val_dataset,\r\n",
        "    tokenizer=tokenizer,\r\n",
        "    compute_metrics=compute_metrics\r\n",
        ")\r\n",
        "\r\n",
        "trainer.train()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='1201' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1201/2500 07:59 < 08:39, 2.50 it/s, Epoch 2.40/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.351600</td>\n",
              "      <td>0.744218</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.811500</td>\n",
              "      <td>10.192000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.962800</td>\n",
              "      <td>1.196507</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.659100</td>\n",
              "      <td>10.353000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.876400</td>\n",
              "      <td>1.015505</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.658500</td>\n",
              "      <td>10.354000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.455100</td>\n",
              "      <td>1.060035</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.658800</td>\n",
              "      <td>10.353000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.806100</td>\n",
              "      <td>1.083990</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.661400</td>\n",
              "      <td>10.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.675300</td>\n",
              "      <td>1.039088</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.663300</td>\n",
              "      <td>10.348000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.767900</td>\n",
              "      <td>0.983283</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.658600</td>\n",
              "      <td>10.353000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.520200</td>\n",
              "      <td>1.069610</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.660600</td>\n",
              "      <td>10.351000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.440300</td>\n",
              "      <td>1.115328</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.657900</td>\n",
              "      <td>10.354000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.769800</td>\n",
              "      <td>1.004918</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.656200</td>\n",
              "      <td>10.356000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.792000</td>\n",
              "      <td>0.949466</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.657000</td>\n",
              "      <td>10.355000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='74' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 74/100 00:06 < 00:02, 10.50 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(100, 2) (100,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(100, 2) (100,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(100, 2) (100,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(100, 2) (100,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(100, 2) (100,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(100, 2) (100,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(100, 2) (100,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(100, 2) (100,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(100, 2) (100,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(100, 2) (100,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(100, 2) (100,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8470dd0a6316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1001\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_epoch_stop\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_training_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m         )\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                 \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \"\"\"\n\u001b[1;32m   1751\u001b[0m         \u001b[0mhas_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_keys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m                 \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_past\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "dg5T7ttk9oyO",
        "outputId": "d715fd0b-d4c6-4f38-deee-568fdcfe20ef"
      },
      "source": [
        "config = BertConfig()\r\n",
        "\r\n",
        "config.max_position_embeddings = 2048\r\n",
        "\r\n",
        "model = BertForSequenceClassification(config)\r\n",
        "\r\n",
        "trainer = Trainer(\r\n",
        "    model,\r\n",
        "    args,\r\n",
        "    train_dataset=train_dataset,\r\n",
        "    eval_dataset=val_dataset,\r\n",
        "    tokenizer=tokenizer,\r\n",
        "    compute_metrics=compute_metrics\r\n",
        ")\r\n",
        "\r\n",
        "trainer.train()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='308' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 308/2500 02:42 < 19:21, 1.89 it/s, Epoch 0.61/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.320000</td>\n",
              "      <td>0.730928</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>12.890400</td>\n",
              "      <td>7.758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.945000</td>\n",
              "      <td>1.194015</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>12.887500</td>\n",
              "      <td>7.759000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.875600</td>\n",
              "      <td>1.001647</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>12.885900</td>\n",
              "      <td>7.760000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bb6f142e8da3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "62i2iXATH-CS",
        "outputId": "4640c13b-d4be-4eeb-ae0b-98c766aa1750"
      },
      "source": [
        "config = BertPerformerConfig.from_pretrained(\"bert-base-uncased\")\r\n",
        "\r\n",
        "model = BertPerformerForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)\r\n",
        "\r\n",
        "keep_weights = True\r\n",
        "if keep_weights:\r\n",
        "    state_dict = model.state_dict()\r\n",
        "    encoder_pos = state_dict['bert.embeddings.position_embeddings.weight']\r\n",
        "    to_append = encoder_pos[2:]\r\n",
        "    new_encoder_pos = torch.cat((encoder_pos, to_append, to_append, to_append, to_append[:6]))\r\n",
        "\r\n",
        "model.bert.embeddings.position_embeddings = torch.nn.Embedding(2048, 768)\r\n",
        "\r\n",
        "if keep_weights:\r\n",
        "    state_dict['bert.embeddings.position_embeddings.weight'] = new_encoder_pos\r\n",
        "    model.load_state_dict(state_dict)\r\n",
        "\r\n",
        "model.bert.embeddings.position_ids = torch.arange(2048).expand((1, -1))\r\n",
        "\r\n",
        "# Is it still a buffer?\r\n",
        "for i in model.buffers():\r\n",
        "  print(i)\r\n",
        "\r\n",
        "\r\n",
        "trainer = Trainer(\r\n",
        "    model,\r\n",
        "    args,\r\n",
        "    train_dataset=train_dataset,\r\n",
        "    eval_dataset=val_dataset,\r\n",
        "    tokenizer=tokenizer,\r\n",
        "    compute_metrics=compute_metrics\r\n",
        ")\r\n",
        "\r\n",
        "trainer.train()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertPerformerForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertPerformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertPerformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertPerformerForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.attention.self.performer_attention.random_features', 'bert.encoder.layer.1.attention.self.performer_attention.random_features', 'bert.encoder.layer.2.attention.self.performer_attention.random_features', 'bert.encoder.layer.3.attention.self.performer_attention.random_features', 'bert.encoder.layer.4.attention.self.performer_attention.random_features', 'bert.encoder.layer.5.attention.self.performer_attention.random_features', 'bert.encoder.layer.6.attention.self.performer_attention.random_features', 'bert.encoder.layer.7.attention.self.performer_attention.random_features', 'bert.encoder.layer.8.attention.self.performer_attention.random_features', 'bert.encoder.layer.9.attention.self.performer_attention.random_features', 'bert.encoder.layer.10.attention.self.performer_attention.random_features', 'bert.encoder.layer.11.attention.self.performer_attention.random_features', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[   0,    1,    2,  ..., 2045, 2046, 2047]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='1011' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1011/2500 06:54 < 10:11, 2.44 it/s, Epoch 2.02/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.773500</td>\n",
              "      <td>0.581730</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.804200</td>\n",
              "      <td>10.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.595400</td>\n",
              "      <td>0.551279</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.657000</td>\n",
              "      <td>10.355000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.892200</td>\n",
              "      <td>0.537189</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.658200</td>\n",
              "      <td>10.354000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.836500</td>\n",
              "      <td>0.592185</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.659300</td>\n",
              "      <td>10.353000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.122900</td>\n",
              "      <td>0.716533</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.660000</td>\n",
              "      <td>10.352000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.133400</td>\n",
              "      <td>0.648080</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.661800</td>\n",
              "      <td>10.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.158000</td>\n",
              "      <td>0.643724</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.660200</td>\n",
              "      <td>10.352000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.115900</td>\n",
              "      <td>0.787727</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.656100</td>\n",
              "      <td>10.356000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.067100</td>\n",
              "      <td>0.848879</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.661600</td>\n",
              "      <td>10.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.202700</td>\n",
              "      <td>0.782372</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>9.657000</td>\n",
              "      <td>10.355000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-37a7cf2d1e18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m    993\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/transformers/src/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "zrWUitaPGTyz",
        "outputId": "1241cf26-4dee-444c-bfe4-9bb5a3d17b49"
      },
      "source": [
        "config = BertConfig.from_pretrained(\"bert-base-uncased\")\r\n",
        "\r\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", config=config)\r\n",
        "\r\n",
        "keep_weights = True\r\n",
        "if keep_weights:\r\n",
        "    state_dict = model.state_dict()\r\n",
        "    encoder_pos = state_dict['bert.embeddings.position_embeddings.weight']\r\n",
        "    to_append = encoder_pos[2:]\r\n",
        "    new_encoder_pos = torch.cat((encoder_pos, to_append, to_append, to_append, to_append[:6]))\r\n",
        "\r\n",
        "model.bert.embeddings.position_embeddings = torch.nn.Embedding(2048, 768)\r\n",
        "\r\n",
        "if keep_weights:\r\n",
        "    state_dict['bert.embeddings.position_embeddings.weight'] = new_encoder_pos\r\n",
        "    model.load_state_dict(state_dict)\r\n",
        "\r\n",
        "model.bert.embeddings.position_ids = torch.arange(2048).expand((1, -1))\r\n",
        "\r\n",
        "# Is it still a buffer?\r\n",
        "for i in model.buffers():\r\n",
        "  print(i)\r\n",
        "\r\n",
        "\r\n",
        "trainer = Trainer(\r\n",
        "    model,\r\n",
        "    args,\r\n",
        "    train_dataset=train_dataset,\r\n",
        "    eval_dataset=val_dataset,\r\n",
        "    tokenizer=tokenizer,\r\n",
        "    compute_metrics=compute_metrics\r\n",
        ")\r\n",
        "\r\n",
        "trainer.train()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='632' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 632/2500 05:36 < 16:38, 1.87 it/s, Epoch 1.26/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.752300</td>\n",
              "      <td>0.790338</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>12.884200</td>\n",
              "      <td>7.761000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.542581</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>12.883600</td>\n",
              "      <td>7.762000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.709700</td>\n",
              "      <td>0.537961</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>12.878700</td>\n",
              "      <td>7.765000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.604200</td>\n",
              "      <td>0.507491</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>12.881200</td>\n",
              "      <td>7.763000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.566700</td>\n",
              "      <td>0.546589</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>12.888900</td>\n",
              "      <td>7.759000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.613500</td>\n",
              "      <td>0.500420</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>12.881100</td>\n",
              "      <td>7.763000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1]\n",
            "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0\n",
            " 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1\n",
            " 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 0]\n",
            "[0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-ae2eb071691b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7kmJvteHH81"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZzLI2YtIxrU"
      },
      "source": [
        "##### TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXHMIqOsJPnq"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "batch_size = 8\r\n",
        "lr = 1e-5#/8\r\n",
        "\r\n",
        "def to_tf(ds, seq_len):\r\n",
        "    \"\"\"\r\n",
        "    Creates a TF Dataset given basic tokenizer() encoding\r\n",
        "    \"\"\"\r\n",
        "    # Turn into TF Tensors\r\n",
        "    ds.set_format('tensorflow', columns=['input_ids', 'attention_mask', 'labels'])\r\n",
        "    # Extract TF Tensors\r\n",
        "    features = {x: ds[x].to_tensor(default_value=0, shape=[None, seq_len]) for x in ['input_ids', 'attention_mask']}\r\n",
        "    # Label is not a ragged tensor like the others & hence we separate it \r\n",
        "    tfds = tf.data.Dataset.from_tensor_slices((features, ds[\"labels\"]))\r\n",
        "    return tfds\r\n",
        "\r\n",
        "train_ds = to_tf(train_dataset, 2048).shuffle(1000).batch(batch_size, drop_remainder=True)\r\n",
        "val_ds = to_tf(val_dataset, 2048).batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EjeVrV-IyxT"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification, TFBertPerformerForSequenceClassification, BertPerformerConfig, BertConfig\r\n",
        "\r\n",
        "\r\n",
        "class WrapperFinetuning(tf.keras.Model):\r\n",
        "    def __init__(self, model, *args, **kwargs):\r\n",
        "        super().__init__(*args, **kwargs)\r\n",
        "        self.model = model\r\n",
        "        # Track loss (Loss itself its CategoricalCrossEnt.)\r\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name='loss') \r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def train_step(self, data):\r\n",
        "        # Data is a tuple of x, y for the CMNLI Finetuning data\r\n",
        "        x, y = data\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            # Forward pass\r\n",
        "            y_pred = self.model(x, training=True).logits\r\n",
        "            loss = self.compute_loss(y, y_pred)\r\n",
        "            # Reduce loss to single digit\r\n",
        "            loss = tf.reduce_mean(loss)\r\n",
        "        # Compute gradients\r\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\r\n",
        "        # Update weights\r\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n",
        "        # Update loss tracker\r\n",
        "        self.loss_tracker.update_state(loss)  \r\n",
        "        # Update metrics\r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def test_step(self, data):\r\n",
        "        x, y = data\r\n",
        "        # Compute predictions\r\n",
        "        y_pred = self.model(x, training=False).logits\r\n",
        "        loss = self.compute_loss(y, y_pred)\r\n",
        "        # Updates the metrics tracking the loss\r\n",
        "        self.loss_tracker.update_state(loss)  \r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "    def compute_loss(self, labels, logits):\r\n",
        "        if len(shape_list(logits)) == 1 or shape_list(logits)[1] == 1:\r\n",
        "            loss_fn = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\r\n",
        "        else:\r\n",
        "            # We use the below, as 3 labels\r\n",
        "            loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "                from_logits=True, reduction=tf.keras.losses.Reduction.NONE\r\n",
        "            )\r\n",
        "\r\n",
        "        return loss_fn(labels, logits)\r\n",
        "\r\n",
        "def shape_list(tensor: tf.Tensor):\r\n",
        "    \"\"\"\r\n",
        "    Deal with dynamic shape in tensorflow cleanly.\r\n",
        "    Args:\r\n",
        "        tensor (:obj:`tf.Tensor`): The tensor we want the shape of.\r\n",
        "    Returns:\r\n",
        "        :obj:`List[int]`: The shape of the tensor as a list.\r\n",
        "    \"\"\"\r\n",
        "    dynamic = tf.shape(tensor)\r\n",
        "\r\n",
        "    if tensor.shape == tf.TensorShape(None):\r\n",
        "        return dynamic\r\n",
        "\r\n",
        "    static = tensor.shape.as_list()\r\n",
        "\r\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKfPACMGOFye",
        "outputId": "5c17ee5f-6dd2-4501-eb81-7b58a878524a"
      },
      "source": [
        "for i in train_ds.take(1):\r\n",
        "  print(i)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'input_ids': <tf.Tensor: shape=(8, 2048), dtype=int32, numpy=\n",
            "array([[  101, 13857,  8112, ...,     0,     0,     0],\n",
            "       [  101,  1004,  1001, ...,     0,     0,     0],\n",
            "       [  101,  1006, 27166, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  2045,  2038, ...,     0,     0,     0],\n",
            "       [  101, 18079,  1012, ...,  1010,  6699,   102],\n",
            "       [  101,  2280, 11026, ...,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(8, 2048), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 1, 1, 1],\n",
            "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}, <tf.Tensor: shape=(8,), dtype=int64, numpy=array([1, 1, 0, 1, 1, 1, 0, 0])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dz_0bl7gW-6"
      },
      "source": [
        "###### BERTPerformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdQdMWDsfKzG",
        "outputId": "cca141ce-8335-44d2-8f0f-8eced29c3ed8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Performer BS 8, Pretrained + copy over Pos\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    model_tf = TFBertPerformerForSequenceClassification.from_pretrained(\"bert-base-uncased\")\r\n",
        "\r\n",
        "    if True:\r\n",
        "        # Reinitialize Pos Embeddings - This is necessary even on GPU if it throws no error as\r\n",
        "\r\n",
        "        # On tf.gather:\r\n",
        "        # Caution: On CPU, if an out of bound index is found, an error is raised. \r\n",
        "        # On GPU, if an out of bound index is found, a 0 is stored in the corresponding output value.\r\n",
        "\r\n",
        "        print(\"Old pos:\", tf.shape(model_tf.bert.embeddings.position_embeddings))\r\n",
        "        encoder_pos = tf.identity(model_tf.bert.embeddings.position_embeddings)\r\n",
        "        to_append = tf.identity(model_tf.bert.embeddings.position_embeddings[2:])\r\n",
        "        new_encoder_pos = tf.concat((encoder_pos, to_append, to_append, to_append, to_append[:6]), axis=0)\r\n",
        "\r\n",
        "        model_tf.bert.embeddings.position_embeddings = new_encoder_pos\r\n",
        "\r\n",
        "        print(\"New pos\", tf.shape(model_tf.bert.embeddings.position_embeddings))\r\n",
        "\r\n",
        "\r\n",
        "    model_tf = WrapperFinetuning(model_tf)\r\n",
        "\r\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "    model_tf.compile(optimizer=optimizer, metrics=['accuracy'])\r\n",
        "    \r\n",
        "model_tf.fit(train_ds, epochs=5, validation_data=val_ds)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertPerformerForSequenceClassification.\n",
            "\n",
            "WARNING:transformers.modeling_tf_utils:All model checkpoint layers were used when initializing TFBertPerformerForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertPerformerForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:transformers.modeling_tf_utils:Some layers of TFBertPerformerForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Old pos: tf.Tensor([512 768], shape=(2,), dtype=int32)\n",
            "New pos tf.Tensor([2048  768], shape=(2,), dtype=int32)\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - ETA: 0s - accuracy: 0.5280 - loss: 0.6772WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 94s 322ms/step - accuracy: 0.5285 - loss: 0.6772 - val_accuracy: 0.7604 - val_loss: 0.5508\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 10s 160ms/step - accuracy: 0.6939 - loss: 0.5796 - val_accuracy: 0.7604 - val_loss: 0.5261\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 10s 160ms/step - accuracy: 0.7482 - loss: 0.5183 - val_accuracy: 0.7188 - val_loss: 0.5421\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 10s 159ms/step - accuracy: 0.8468 - loss: 0.3796 - val_accuracy: 0.7917 - val_loss: 0.4287\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 10s 159ms/step - accuracy: 0.8607 - loss: 0.3126 - val_accuracy: 0.8333 - val_loss: 0.4273\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f853954bb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upLEVjr2XvSv",
        "outputId": "927b2562-db89-4043-e89b-be625af8ea41"
      },
      "source": [
        "# Performer BS 8 Pretrained\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    model_tf = TFBertPerformerForSequenceClassification.from_pretrained(\"bert-base-uncased\")\r\n",
        "\r\n",
        "    if True:\r\n",
        "        # Reinitialize Pos Embeddings - This is necessary even on GPU if it throws no error as\r\n",
        "\r\n",
        "        # On tf.gather:\r\n",
        "        # Caution: On CPU, if an out of bound index is found, an error is raised. \r\n",
        "        # On GPU, if an out of bound index is found, a 0 is stored in the corresponding output value.\r\n",
        "\r\n",
        "        from transformers.modeling_tf_utils import get_initializer\r\n",
        "\r\n",
        "        config = model_tf.config\r\n",
        "        model_tf.bert.embeddings.position_embeddings = model_tf.bert.embeddings.add_weight(\r\n",
        "                                                        name=\"embeddings\",\r\n",
        "                                                        shape=[2048, 768],\r\n",
        "                                                        initializer=get_initializer(initializer_range=config.initializer_range),\r\n",
        "                                                        )\r\n",
        "\r\n",
        "    model_tf = WrapperFinetuning(model_tf)\r\n",
        "\r\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "    model_tf.compile(optimizer=optimizer, metrics=['accuracy'])\r\n",
        "    \r\n",
        "model_tf.fit(train_ds, epochs=5, validation_data=val_ds)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertPerformerForSequenceClassification.\n",
            "\n",
            "WARNING:transformers.modeling_tf_utils:All model checkpoint layers were used when initializing TFBertPerformerForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertPerformerForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:transformers.modeling_tf_utils:Some layers of TFBertPerformerForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - ETA: 0s - accuracy: 0.4936 - loss: 0.6538WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 84s 297ms/step - accuracy: 0.4952 - loss: 0.6538 - val_accuracy: 0.7604 - val_loss: 0.5273\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 10s 159ms/step - accuracy: 0.6486 - loss: 0.5869 - val_accuracy: 0.6250 - val_loss: 0.5955\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 11s 179ms/step - accuracy: 0.7689 - loss: 0.4924 - val_accuracy: 0.7708 - val_loss: 0.4706\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 10s 159ms/step - accuracy: 0.8124 - loss: 0.4130 - val_accuracy: 0.7604 - val_loss: 0.4601\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 10s 160ms/step - accuracy: 0.7854 - loss: 0.4757 - val_accuracy: 0.7708 - val_loss: 0.5778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0c1201c210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfkxkG-GZRYa",
        "outputId": "6a144504-aff4-476c-decb-c4ae420c6b0b"
      },
      "source": [
        "# Performer BS 8, Not Pretrained\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    config = BertPerformerConfig()\r\n",
        "    config.max_position_embeddings = 2048\r\n",
        "    model_tf = TFBertPerformerForSequenceClassification(config)\r\n",
        "\r\n",
        "    if False:\r\n",
        "        # Reinitialize Pos Embeddings - This is necessary even on GPU if it throws no error as\r\n",
        "\r\n",
        "        # On tf.gather:\r\n",
        "        # Caution: On CPU, if an out of bound index is found, an error is raised. \r\n",
        "        # On GPU, if an out of bound index is found, a 0 is stored in the corresponding output value.\r\n",
        "\r\n",
        "        from transformers.modeling_tf_utils import get_initializer\r\n",
        "\r\n",
        "        config = model_tf.config\r\n",
        "        model_tf.bert.embeddings.position_embeddings = model_tf.bert.embeddings.add_weight(\r\n",
        "                                                        name=\"embeddings\",\r\n",
        "                                                        shape=[2048, 768],\r\n",
        "                                                        initializer=get_initializer(initializer_range=config.initializer_range),\r\n",
        "                                                        )\r\n",
        "\r\n",
        "    model_tf = WrapperFinetuning(model_tf)\r\n",
        "\r\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "    model_tf.compile(optimizer=optimizer, metrics=['accuracy'])\r\n",
        "    \r\n",
        "model_tf.fit(train_ds, epochs=5, validation_data=val_ds)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - ETA: 0s - accuracy: 0.5222 - loss: 0.6974WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 90s 301ms/step - accuracy: 0.5229 - loss: 0.6974 - val_accuracy: 0.7604 - val_loss: 0.5893\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 10s 157ms/step - accuracy: 0.6251 - loss: 0.6840 - val_accuracy: 0.7604 - val_loss: 0.5647\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 10s 158ms/step - accuracy: 0.5583 - loss: 0.6829 - val_accuracy: 0.7604 - val_loss: 0.5633\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 10s 159ms/step - accuracy: 0.5888 - loss: 0.6657 - val_accuracy: 0.7604 - val_loss: 0.5429\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 10s 161ms/step - accuracy: 0.6078 - loss: 0.6380 - val_accuracy: 0.7500 - val_loss: 0.4842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8534af4810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVrUtZOkgUqg"
      },
      "source": [
        "###### BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_4s3fBdgbmo",
        "outputId": "c76d1b00-cccc-4ea1-fbac-f10437b3367a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# BERT BS 8, Pretrained + copy over Pos\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    model_tf = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\r\n",
        "\r\n",
        "    if True:\r\n",
        "        # Reinitialize Pos Embeddings - This is necessary even on GPU if it throws no error as\r\n",
        "\r\n",
        "        # On tf.gather:\r\n",
        "        # Caution: On CPU, if an out of bound index is found, an error is raised. \r\n",
        "        # On GPU, if an out of bound index is found, a 0 is stored in the corresponding output value.\r\n",
        "\r\n",
        "        print(\"Old pos:\", tf.shape(model_tf.bert.embeddings.position_embeddings))\r\n",
        "        encoder_pos = tf.identity(model_tf.bert.embeddings.position_embeddings)\r\n",
        "        to_append = tf.identity(model_tf.bert.embeddings.position_embeddings[2:])\r\n",
        "        new_encoder_pos = tf.concat((encoder_pos, to_append, to_append, to_append, to_append[:6]), axis=0)\r\n",
        "\r\n",
        "        model_tf.bert.embeddings.position_embeddings = new_encoder_pos\r\n",
        "\r\n",
        "        print(\"New pos\", tf.shape(model_tf.bert.embeddings.position_embeddings))\r\n",
        "\r\n",
        "\r\n",
        "    model_tf = WrapperFinetuning(model_tf)\r\n",
        "\r\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "    model_tf.compile(optimizer=optimizer, metrics=['accuracy'])\r\n",
        "    \r\n",
        "model_tf.fit(train_ds, epochs=5, validation_data=val_ds)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "WARNING:transformers.modeling_tf_utils:All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:transformers.modeling_tf_utils:Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Old pos: tf.Tensor([512 768], shape=(2,), dtype=int32)\n",
            "New pos tf.Tensor([2048  768], shape=(2,), dtype=int32)\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - ETA: 0s - accuracy: 0.6327 - loss: 0.6000WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r62/62 [==============================] - 83s 368ms/step - accuracy: 0.6334 - loss: 0.6000 - val_accuracy: 0.6979 - val_loss: 0.5356\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 15s 249ms/step - accuracy: 0.7400 - loss: 0.5345 - val_accuracy: 0.7396 - val_loss: 0.4495\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 17s 273ms/step - accuracy: 0.8152 - loss: 0.4666 - val_accuracy: 0.8125 - val_loss: 0.4123\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 15s 250ms/step - accuracy: 0.8800 - loss: 0.3946 - val_accuracy: 0.7917 - val_loss: 0.4052\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 15s 249ms/step - accuracy: 0.9033 - loss: 0.3048 - val_accuracy: 0.8333 - val_loss: 0.3883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f85309411d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9_GtkrDV87W",
        "outputId": "5267e170-5aca-4098-8ffb-cccbf334d2c3"
      },
      "source": [
        "# BERT BS8 Pretrained\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    model_tf = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\r\n",
        "\r\n",
        "    if True:\r\n",
        "        # Reinitialize Pos Embeddings - This is necessary even on GPU if it throws no error as\r\n",
        "\r\n",
        "        # On tf.gather:\r\n",
        "        # Caution: On CPU, if an out of bound index is found, an error is raised. \r\n",
        "        # On GPU, if an out of bound index is found, a 0 is stored in the corresponding output value.\r\n",
        "\r\n",
        "        from transformers.modeling_tf_utils import get_initializer\r\n",
        "\r\n",
        "        config = model_tf.config\r\n",
        "        model_tf.bert.embeddings.position_embeddings = model_tf.bert.embeddings.add_weight(\r\n",
        "                                                        name=\"embeddings\",\r\n",
        "                                                        shape=[2048, 768],\r\n",
        "                                                        initializer=get_initializer(initializer_range=config.initializer_range),\r\n",
        "                                                        )\r\n",
        "\r\n",
        "    model_tf = WrapperFinetuning(model_tf)\r\n",
        "\r\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "    model_tf.compile(optimizer=optimizer, metrics=['accuracy'])\r\n",
        "    \r\n",
        "model_tf.fit(train_ds, epochs=5, validation_data=val_ds)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "WARNING:transformers.modeling_tf_utils:All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:transformers.modeling_tf_utils:Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - ETA: 0s - accuracy: 0.5867 - loss: 0.6654WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r62/62 [==============================] - 86s 369ms/step - accuracy: 0.5868 - loss: 0.6654 - val_accuracy: 0.7292 - val_loss: 0.5951\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 15s 250ms/step - accuracy: 0.6497 - loss: 0.6247 - val_accuracy: 0.7604 - val_loss: 0.5461\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 15s 247ms/step - accuracy: 0.7366 - loss: 0.5483 - val_accuracy: 0.8021 - val_loss: 0.4614\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 15s 247ms/step - accuracy: 0.7436 - loss: 0.4750 - val_accuracy: 0.7500 - val_loss: 0.5288\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 15s 248ms/step - accuracy: 0.8457 - loss: 0.4279 - val_accuracy: 0.8229 - val_loss: 0.4072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8544170a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNQOt6f_bYR2",
        "outputId": "68f0dd83-54d9-4a08-e64f-0a2526f61e7b"
      },
      "source": [
        "# BERT BS8 NOT Pretrained\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    model_tf = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\r\n",
        "\r\n",
        "    config = BertConfig()\r\n",
        "    config.max_position_embeddings = 2048\r\n",
        "    model_tf = TFBertForSequenceClassification(config)\r\n",
        "\r\n",
        "    if False:\r\n",
        "        # Reinitialize Pos Embeddings - This is necessary even on GPU if it throws no error as\r\n",
        "\r\n",
        "        # On tf.gather:\r\n",
        "        # Caution: On CPU, if an out of bound index is found, an error is raised. \r\n",
        "        # On GPU, if an out of bound index is found, a 0 is stored in the corresponding output value.\r\n",
        "\r\n",
        "        from transformers.modeling_tf_utils import get_initializer\r\n",
        "\r\n",
        "        config = model_tf.config\r\n",
        "        model_tf.bert.embeddings.position_embeddings = model_tf.bert.embeddings.add_weight(\r\n",
        "                                                        name=\"embeddings\",\r\n",
        "                                                        shape=[2048, 768],\r\n",
        "                                                        initializer=get_initializer(initializer_range=config.initializer_range),\r\n",
        "                                                        )\r\n",
        "\r\n",
        "    model_tf = WrapperFinetuning(model_tf)\r\n",
        "\r\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "    model_tf.compile(optimizer=optimizer, metrics=['accuracy'])\r\n",
        "    \r\n",
        "model_tf.fit(train_ds, epochs=5, validation_data=val_ds)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "WARNING:transformers.modeling_tf_utils:All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:transformers.modeling_tf_utils:Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - ETA: 0s - accuracy: 0.5064 - loss: 0.7363WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r62/62 [==============================] - 86s 367ms/step - accuracy: 0.5065 - loss: 0.7363 - val_accuracy: 0.7604 - val_loss: 0.5575\n",
            "Epoch 2/5\n",
            "62/62 [==============================] - 15s 247ms/step - accuracy: 0.5972 - loss: 0.6919 - val_accuracy: 0.7604 - val_loss: 0.6682\n",
            "Epoch 3/5\n",
            "62/62 [==============================] - 16s 260ms/step - accuracy: 0.5919 - loss: 0.6795 - val_accuracy: 0.7604 - val_loss: 0.5852\n",
            "Epoch 4/5\n",
            "62/62 [==============================] - 15s 249ms/step - accuracy: 0.6174 - loss: 0.6903 - val_accuracy: 0.7604 - val_loss: 0.6149\n",
            "Epoch 5/5\n",
            "62/62 [==============================] - 15s 248ms/step - accuracy: 0.6272 - loss: 0.6827 - val_accuracy: 0.2396 - val_loss: 0.7308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f854147f4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}