{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPTCloudPipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lo6Yrb8Jop44"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9bd3dbf53b2f4e38ae111a4451a6c1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53d032db0abb4a1aa4e38dd1569f7447",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bc1ae04d61db43a58dfd224fdf2117b5",
              "IPY_MODEL_78dc3c317d414bb9a6498b18b032c226"
            ]
          }
        },
        "53d032db0abb4a1aa4e38dd1569f7447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc1ae04d61db43a58dfd224fdf2117b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6b03e73a9bf24e999b8181445cc30baf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 911,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 911,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f2524e83b764122a0c048a7f3d6276f"
          }
        },
        "78dc3c317d414bb9a6498b18b032c226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f9d02ab1b984106a60a3ced2215096b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 911/911 [00:00&lt;00:00, 29.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6757791ca9b54fe18937b7a2914f54b8"
          }
        },
        "6b03e73a9bf24e999b8181445cc30baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f2524e83b764122a0c048a7f3d6276f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f9d02ab1b984106a60a3ced2215096b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6757791ca9b54fe18937b7a2914f54b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8odHPIsA_7y5"
      },
      "source": [
        "##### Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WK2z-HauoBx",
        "outputId": "900f6f98-e5e7-43f9-9f41-5e65e2248087"
      },
      "source": [
        "!git clone https://github.com/Muennighoff/cn_performer\r\n",
        "%cd cn_performer\r\n",
        "!pip3 install -q -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cn_performer'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 80 (delta 24), reused 70 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (80/80), done.\n",
            "/content/cn_performer\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 13.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 11.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 52.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 52.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 47.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 54.7MB/s \n",
            "\u001b[?25h  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo6Yrb8Jop44"
      },
      "source": [
        "##### Preprocessing (Ideally done in the Cloud)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rZvTlrAuqrw"
      },
      "source": [
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "!gcloud init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2Gf2cauutQ4",
        "outputId": "d860fff0-edc0-47d9-8ef0-c4da74f6c866"
      },
      "source": [
        "!mkdir ./data/\r\n",
        "!gsutil cp gs://clue-corpus2020/CLUECorpus2020/train_clue_pretrain_train_0000.zip ./data/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./data/’: File exists\n",
            "Copying gs://clue-corpus2020/CLUECorpus2020/train_clue_pretrain_train_0000.zip...\n",
            "\n",
            "Operation completed over 1 objects/1.0 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdSBtmdku8kw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4543199c-61ab-4cb4-b863-6c49fdb3f643"
      },
      "source": [
        "!unzip ./data/*.zip -d ./data/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./data/train_clue_pretrain_train_0000.zip\n",
            "  inflating: ./data/clue_pretrain_0000000.txt  \n",
            "  inflating: ./data/clue_pretrain_0000001.txt  \n",
            "  inflating: ./data/clue_pretrain_0000002.txt  \n",
            "  inflating: ./data/clue_pretrain_0000003.txt  \n",
            "  inflating: ./data/clue_pretrain_0000004.txt  \n",
            "  inflating: ./data/clue_pretrain_0000005.txt  \n",
            "  inflating: ./data/clue_pretrain_0000006.txt  \n",
            "  inflating: ./data/clue_pretrain_0000007.txt  \n",
            "  inflating: ./data/clue_pretrain_0000008.txt  \n",
            "  inflating: ./data/clue_pretrain_0000009.txt  \n",
            "  inflating: ./data/clue_pretrain_0000010.txt  \n",
            "  inflating: ./data/clue_pretrain_0000011.txt  \n",
            "  inflating: ./data/clue_pretrain_0000012.txt  \n",
            "  inflating: ./data/clue_pretrain_0000013.txt  \n",
            "  inflating: ./data/clue_pretrain_0000014.txt  \n",
            "  inflating: ./data/clue_pretrain_0000015.txt  \n",
            "  inflating: ./data/clue_pretrain_0000016.txt  \n",
            "  inflating: ./data/clue_pretrain_0000017.txt  \n",
            "  inflating: ./data/clue_pretrain_0000018.txt  \n",
            "  inflating: ./data/clue_pretrain_0000019.txt  \n",
            "  inflating: ./data/clue_pretrain_0000020.txt  \n",
            "  inflating: ./data/clue_pretrain_0000021.txt  \n",
            "  inflating: ./data/clue_pretrain_0000022.txt  \n",
            "  inflating: ./data/clue_pretrain_0000023.txt  \n",
            "  inflating: ./data/clue_pretrain_0000024.txt  \n",
            "  inflating: ./data/clue_pretrain_0000025.txt  \n",
            "  inflating: ./data/clue_pretrain_0000026.txt  \n",
            "  inflating: ./data/clue_pretrain_0000027.txt  \n",
            "  inflating: ./data/clue_pretrain_0000028.txt  \n",
            "  inflating: ./data/clue_pretrain_0000029.txt  \n",
            "  inflating: ./data/clue_pretrain_0000030.txt  \n",
            "  inflating: ./data/clue_pretrain_0000031.txt  \n",
            "  inflating: ./data/clue_pretrain_0000032.txt  \n",
            "  inflating: ./data/clue_pretrain_0000033.txt  \n",
            "  inflating: ./data/clue_pretrain_0000034.txt  \n",
            "  inflating: ./data/clue_pretrain_0000035.txt  \n",
            "  inflating: ./data/clue_pretrain_0000036.txt  \n",
            "  inflating: ./data/clue_pretrain_0000037.txt  \n",
            "  inflating: ./data/clue_pretrain_0000038.txt  \n",
            "  inflating: ./data/clue_pretrain_0000039.txt  \n",
            "  inflating: ./data/clue_pretrain_0000040.txt  \n",
            "  inflating: ./data/clue_pretrain_0000041.txt  \n",
            "  inflating: ./data/clue_pretrain_0000042.txt  \n",
            "  inflating: ./data/clue_pretrain_0000043.txt  \n",
            "  inflating: ./data/clue_pretrain_0000044.txt  \n",
            "  inflating: ./data/clue_pretrain_0000045.txt  \n",
            "  inflating: ./data/clue_pretrain_0000046.txt  \n",
            "  inflating: ./data/clue_pretrain_0000047.txt  \n",
            "  inflating: ./data/clue_pretrain_0000048.txt  \n",
            "  inflating: ./data/clue_pretrain_0000049.txt  \n",
            "  inflating: ./data/clue_pretrain_0000050.txt  \n",
            "  inflating: ./data/clue_pretrain_0000051.txt  \n",
            "  inflating: ./data/clue_pretrain_0000052.txt  \n",
            "  inflating: ./data/clue_pretrain_0000053.txt  \n",
            "  inflating: ./data/clue_pretrain_0000054.txt  \n",
            "  inflating: ./data/clue_pretrain_0000055.txt  \n",
            "  inflating: ./data/clue_pretrain_0000056.txt  \n",
            "  inflating: ./data/clue_pretrain_0000057.txt  \n",
            "  inflating: ./data/clue_pretrain_0000058.txt  \n",
            "  inflating: ./data/clue_pretrain_0000059.txt  \n",
            "  inflating: ./data/clue_pretrain_0000060.txt  \n",
            "  inflating: ./data/clue_pretrain_0000061.txt  \n",
            "  inflating: ./data/clue_pretrain_0000062.txt  \n",
            "  inflating: ./data/clue_pretrain_0000063.txt  \n",
            "  inflating: ./data/clue_pretrain_0000064.txt  \n",
            "  inflating: ./data/clue_pretrain_0000065.txt  \n",
            "  inflating: ./data/clue_pretrain_0000066.txt  \n",
            "  inflating: ./data/clue_pretrain_0000067.txt  \n",
            "  inflating: ./data/clue_pretrain_0000068.txt  \n",
            "  inflating: ./data/clue_pretrain_0000069.txt  \n",
            "  inflating: ./data/clue_pretrain_0000070.txt  \n",
            "  inflating: ./data/clue_pretrain_0000071.txt  \n",
            "  inflating: ./data/clue_pretrain_0000072.txt  \n",
            "  inflating: ./data/clue_pretrain_0000073.txt  \n",
            "  inflating: ./data/clue_pretrain_0000074.txt  \n",
            "  inflating: ./data/clue_pretrain_0000075.txt  \n",
            "  inflating: ./data/clue_pretrain_0000076.txt  \n",
            "  inflating: ./data/clue_pretrain_0000077.txt  \n",
            "  inflating: ./data/clue_pretrain_0000078.txt  \n",
            "  inflating: ./data/clue_pretrain_0000079.txt  \n",
            "  inflating: ./data/clue_pretrain_0000080.txt  \n",
            "  inflating: ./data/clue_pretrain_0000081.txt  \n",
            "  inflating: ./data/clue_pretrain_0000082.txt  \n",
            "  inflating: ./data/clue_pretrain_0000083.txt  \n",
            "  inflating: ./data/clue_pretrain_0000084.txt  \n",
            "  inflating: ./data/clue_pretrain_0000085.txt  \n",
            "  inflating: ./data/clue_pretrain_0000086.txt  \n",
            "  inflating: ./data/clue_pretrain_0000087.txt  \n",
            "  inflating: ./data/clue_pretrain_0000088.txt  \n",
            "  inflating: ./data/clue_pretrain_0000089.txt  \n",
            "  inflating: ./data/clue_pretrain_0000090.txt  \n",
            "  inflating: ./data/clue_pretrain_0000091.txt  \n",
            "  inflating: ./data/clue_pretrain_0000092.txt  \n",
            "  inflating: ./data/clue_pretrain_0000093.txt  \n",
            "  inflating: ./data/clue_pretrain_0000094.txt  \n",
            "  inflating: ./data/clue_pretrain_0000095.txt  \n",
            "  inflating: ./data/clue_pretrain_0000096.txt  \n",
            "  inflating: ./data/clue_pretrain_0000097.txt  \n",
            "  inflating: ./data/clue_pretrain_0000098.txt  \n",
            "  inflating: ./data/clue_pretrain_0000099.txt  \n",
            "  inflating: ./data/clue_pretrain_0000100.txt  \n",
            "  inflating: ./data/clue_pretrain_0000101.txt  \n",
            "  inflating: ./data/clue_pretrain_0000102.txt  \n",
            "  inflating: ./data/clue_pretrain_0000103.txt  \n",
            "  inflating: ./data/clue_pretrain_0000104.txt  \n",
            "  inflating: ./data/clue_pretrain_0000105.txt  \n",
            "  inflating: ./data/clue_pretrain_0000106.txt  \n",
            "  inflating: ./data/clue_pretrain_0000107.txt  \n",
            "  inflating: ./data/clue_pretrain_0000108.txt  \n",
            "  inflating: ./data/clue_pretrain_0000109.txt  \n",
            "  inflating: ./data/clue_pretrain_0000110.txt  \n",
            "  inflating: ./data/clue_pretrain_0000111.txt  \n",
            "  inflating: ./data/clue_pretrain_0000112.txt  \n",
            "  inflating: ./data/clue_pretrain_0000113.txt  \n",
            "  inflating: ./data/clue_pretrain_0000114.txt  \n",
            "  inflating: ./data/clue_pretrain_0000115.txt  \n",
            "  inflating: ./data/clue_pretrain_0000116.txt  \n",
            "  inflating: ./data/clue_pretrain_0000117.txt  \n",
            "  inflating: ./data/clue_pretrain_0000118.txt  \n",
            "  inflating: ./data/clue_pretrain_0000119.txt  \n",
            "  inflating: ./data/clue_pretrain_0000120.txt  \n",
            "  inflating: ./data/clue_pretrain_0000121.txt  \n",
            "  inflating: ./data/clue_pretrain_0000122.txt  \n",
            "  inflating: ./data/clue_pretrain_0000123.txt  \n",
            "  inflating: ./data/clue_pretrain_0000124.txt  \n",
            "  inflating: ./data/clue_pretrain_0000125.txt  \n",
            "  inflating: ./data/clue_pretrain_0000126.txt  \n",
            "  inflating: ./data/clue_pretrain_0000127.txt  \n",
            "  inflating: ./data/clue_pretrain_0000128.txt  \n",
            "  inflating: ./data/clue_pretrain_0000129.txt  \n",
            "  inflating: ./data/clue_pretrain_0000130.txt  \n",
            "  inflating: ./data/clue_pretrain_0000131.txt  \n",
            "  inflating: ./data/clue_pretrain_0000132.txt  \n",
            "  inflating: ./data/clue_pretrain_0000133.txt  \n",
            "  inflating: ./data/clue_pretrain_0000134.txt  \n",
            "  inflating: ./data/clue_pretrain_0000135.txt  \n",
            "  inflating: ./data/clue_pretrain_0000136.txt  \n",
            "  inflating: ./data/clue_pretrain_0000137.txt  \n",
            "  inflating: ./data/clue_pretrain_0000138.txt  \n",
            "  inflating: ./data/clue_pretrain_0000139.txt  \n",
            "  inflating: ./data/clue_pretrain_0000140.txt  \n",
            "  inflating: ./data/clue_pretrain_0000141.txt  \n",
            "  inflating: ./data/clue_pretrain_0000142.txt  \n",
            "  inflating: ./data/clue_pretrain_0000143.txt  \n",
            "  inflating: ./data/clue_pretrain_0000144.txt  \n",
            "  inflating: ./data/clue_pretrain_0000145.txt  \n",
            "  inflating: ./data/clue_pretrain_0000146.txt  \n",
            "  inflating: ./data/clue_pretrain_0000147.txt  \n",
            "  inflating: ./data/clue_pretrain_0000148.txt  \n",
            "  inflating: ./data/clue_pretrain_0000149.txt  \n",
            "  inflating: ./data/clue_pretrain_0000150.txt  \n",
            "  inflating: ./data/clue_pretrain_0000151.txt  \n",
            "  inflating: ./data/clue_pretrain_0000152.txt  \n",
            "  inflating: ./data/clue_pretrain_0000153.txt  \n",
            "  inflating: ./data/clue_pretrain_0000154.txt  \n",
            "  inflating: ./data/clue_pretrain_0000155.txt  \n",
            "  inflating: ./data/clue_pretrain_0000156.txt  \n",
            "  inflating: ./data/clue_pretrain_0000157.txt  \n",
            "  inflating: ./data/clue_pretrain_0000158.txt  \n",
            "  inflating: ./data/clue_pretrain_0000159.txt  \n",
            "  inflating: ./data/clue_pretrain_0000160.txt  \n",
            "  inflating: ./data/clue_pretrain_0000161.txt  \n",
            "  inflating: ./data/clue_pretrain_0000162.txt  \n",
            "  inflating: ./data/clue_pretrain_0000163.txt  \n",
            "  inflating: ./data/clue_pretrain_0000164.txt  \n",
            "  inflating: ./data/clue_pretrain_0000165.txt  \n",
            "  inflating: ./data/clue_pretrain_0000166.txt  \n",
            "  inflating: ./data/clue_pretrain_0000167.txt  \n",
            "  inflating: ./data/clue_pretrain_0000168.txt  \n",
            "  inflating: ./data/clue_pretrain_0000169.txt  \n",
            "  inflating: ./data/clue_pretrain_0000170.txt  \n",
            "  inflating: ./data/clue_pretrain_0000171.txt  \n",
            "  inflating: ./data/clue_pretrain_0000172.txt  \n",
            "  inflating: ./data/clue_pretrain_0000173.txt  \n",
            "  inflating: ./data/clue_pretrain_0000174.txt  \n",
            "  inflating: ./data/clue_pretrain_0000175.txt  \n",
            "  inflating: ./data/clue_pretrain_0000176.txt  \n",
            "  inflating: ./data/clue_pretrain_0000177.txt  \n",
            "  inflating: ./data/clue_pretrain_0000178.txt  \n",
            "  inflating: ./data/clue_pretrain_0000179.txt  \n",
            "  inflating: ./data/clue_pretrain_0000180.txt  \n",
            "  inflating: ./data/clue_pretrain_0000181.txt  \n",
            "  inflating: ./data/clue_pretrain_0000182.txt  \n",
            "  inflating: ./data/clue_pretrain_0000183.txt  \n",
            "  inflating: ./data/clue_pretrain_0000184.txt  \n",
            "  inflating: ./data/clue_pretrain_0000185.txt  \n",
            "  inflating: ./data/clue_pretrain_0000186.txt  \n",
            "  inflating: ./data/clue_pretrain_0000187.txt  \n",
            "  inflating: ./data/clue_pretrain_0000188.txt  \n",
            "  inflating: ./data/clue_pretrain_0000189.txt  \n",
            "  inflating: ./data/clue_pretrain_0000190.txt  \n",
            "  inflating: ./data/clue_pretrain_0000191.txt  \n",
            "  inflating: ./data/clue_pretrain_0000192.txt  \n",
            "  inflating: ./data/clue_pretrain_0000193.txt  \n",
            "  inflating: ./data/clue_pretrain_0000194.txt  \n",
            "  inflating: ./data/clue_pretrain_0000195.txt  \n",
            "  inflating: ./data/clue_pretrain_0000196.txt  \n",
            "  inflating: ./data/clue_pretrain_0000197.txt  \n",
            "  inflating: ./data/clue_pretrain_0000198.txt  \n",
            "  inflating: ./data/clue_pretrain_0000199.txt  \n",
            "  inflating: ./data/clue_pretrain_0000200.txt  \n",
            "  inflating: ./data/clue_pretrain_0000201.txt  \n",
            "  inflating: ./data/clue_pretrain_0000202.txt  \n",
            "  inflating: ./data/clue_pretrain_0000203.txt  \n",
            "  inflating: ./data/clue_pretrain_0000204.txt  \n",
            "  inflating: ./data/clue_pretrain_0000205.txt  \n",
            "  inflating: ./data/clue_pretrain_0000206.txt  \n",
            "  inflating: ./data/clue_pretrain_0000207.txt  \n",
            "  inflating: ./data/clue_pretrain_0000208.txt  \n",
            "  inflating: ./data/clue_pretrain_0000209.txt  \n",
            "  inflating: ./data/clue_pretrain_0000210.txt  \n",
            "  inflating: ./data/clue_pretrain_0000211.txt  \n",
            "  inflating: ./data/clue_pretrain_0000212.txt  \n",
            "  inflating: ./data/clue_pretrain_0000213.txt  \n",
            "  inflating: ./data/clue_pretrain_0000214.txt  \n",
            "  inflating: ./data/clue_pretrain_0000215.txt  \n",
            "  inflating: ./data/clue_pretrain_0000216.txt  \n",
            "  inflating: ./data/clue_pretrain_0000217.txt  \n",
            "  inflating: ./data/clue_pretrain_0000218.txt  \n",
            "  inflating: ./data/clue_pretrain_0000219.txt  \n",
            "  inflating: ./data/clue_pretrain_0000220.txt  \n",
            "  inflating: ./data/clue_pretrain_0000221.txt  \n",
            "  inflating: ./data/clue_pretrain_0000222.txt  \n",
            "  inflating: ./data/clue_pretrain_0000223.txt  \n",
            "  inflating: ./data/clue_pretrain_0000224.txt  \n",
            "  inflating: ./data/clue_pretrain_0000225.txt  \n",
            "  inflating: ./data/clue_pretrain_0000226.txt  \n",
            "  inflating: ./data/clue_pretrain_0000227.txt  \n",
            "  inflating: ./data/clue_pretrain_0000228.txt  \n",
            "  inflating: ./data/clue_pretrain_0000229.txt  \n",
            "  inflating: ./data/clue_pretrain_0000230.txt  \n",
            "  inflating: ./data/clue_pretrain_0000231.txt  \n",
            "  inflating: ./data/clue_pretrain_0000232.txt  \n",
            "  inflating: ./data/clue_pretrain_0000233.txt  \n",
            "  inflating: ./data/clue_pretrain_0000234.txt  \n",
            "  inflating: ./data/clue_pretrain_0000235.txt  \n",
            "  inflating: ./data/clue_pretrain_0000236.txt  \n",
            "  inflating: ./data/clue_pretrain_0000237.txt  \n",
            "  inflating: ./data/clue_pretrain_0000238.txt  \n",
            "  inflating: ./data/clue_pretrain_0000239.txt  \n",
            "  inflating: ./data/clue_pretrain_0000240.txt  \n",
            "  inflating: ./data/clue_pretrain_0000241.txt  \n",
            "  inflating: ./data/clue_pretrain_0000242.txt  \n",
            "  inflating: ./data/clue_pretrain_0000243.txt  \n",
            "  inflating: ./data/clue_pretrain_0000244.txt  \n",
            "  inflating: ./data/clue_pretrain_0000245.txt  \n",
            "  inflating: ./data/clue_pretrain_0000246.txt  \n",
            "  inflating: ./data/clue_pretrain_0000247.txt  \n",
            "  inflating: ./data/clue_pretrain_0000248.txt  \n",
            "  inflating: ./data/clue_pretrain_0000249.txt  \n",
            "  inflating: ./data/clue_pretrain_0000250.txt  \n",
            "  inflating: ./data/clue_pretrain_0000251.txt  \n",
            "  inflating: ./data/clue_pretrain_0000252.txt  \n",
            "  inflating: ./data/clue_pretrain_0000253.txt  \n",
            "  inflating: ./data/clue_pretrain_0000254.txt  \n",
            "  inflating: ./data/clue_pretrain_0000255.txt  \n",
            "  inflating: ./data/clue_pretrain_0000256.txt  \n",
            "  inflating: ./data/clue_pretrain_0000257.txt  \n",
            "  inflating: ./data/clue_pretrain_0000258.txt  \n",
            "  inflating: ./data/clue_pretrain_0000259.txt  \n",
            "  inflating: ./data/clue_pretrain_0000260.txt  \n",
            "  inflating: ./data/clue_pretrain_0000261.txt  \n",
            "  inflating: ./data/clue_pretrain_0000262.txt  \n",
            "  inflating: ./data/clue_pretrain_0000263.txt  \n",
            "  inflating: ./data/clue_pretrain_0000264.txt  \n",
            "  inflating: ./data/clue_pretrain_0000265.txt  \n",
            "  inflating: ./data/clue_pretrain_0000266.txt  \n",
            "  inflating: ./data/clue_pretrain_0000267.txt  \n",
            "  inflating: ./data/clue_pretrain_0000268.txt  \n",
            "  inflating: ./data/clue_pretrain_0000269.txt  \n",
            "  inflating: ./data/clue_pretrain_0000270.txt  \n",
            "  inflating: ./data/clue_pretrain_0000271.txt  \n",
            "  inflating: ./data/clue_pretrain_0000272.txt  \n",
            "  inflating: ./data/clue_pretrain_0000273.txt  \n",
            "  inflating: ./data/clue_pretrain_0000274.txt  \n",
            "  inflating: ./data/clue_pretrain_0000275.txt  \n",
            "  inflating: ./data/clue_pretrain_0000276.txt  \n",
            "  inflating: ./data/clue_pretrain_0000277.txt  \n",
            "  inflating: ./data/clue_pretrain_0000278.txt  \n",
            "  inflating: ./data/clue_pretrain_0000279.txt  \n",
            "  inflating: ./data/clue_pretrain_0000280.txt  \n",
            "  inflating: ./data/clue_pretrain_0000281.txt  \n",
            "  inflating: ./data/clue_pretrain_0000282.txt  \n",
            "  inflating: ./data/clue_pretrain_0000283.txt  \n",
            "  inflating: ./data/clue_pretrain_0000284.txt  \n",
            "  inflating: ./data/clue_pretrain_0000285.txt  \n",
            "  inflating: ./data/clue_pretrain_0000286.txt  \n",
            "  inflating: ./data/clue_pretrain_0000287.txt  \n",
            "  inflating: ./data/clue_pretrain_0000288.txt  \n",
            "  inflating: ./data/clue_pretrain_0000289.txt  \n",
            "  inflating: ./data/clue_pretrain_0000290.txt  \n",
            "  inflating: ./data/clue_pretrain_0000291.txt  \n",
            "  inflating: ./data/clue_pretrain_0000292.txt  \n",
            "  inflating: ./data/clue_pretrain_0000293.txt  \n",
            "  inflating: ./data/clue_pretrain_0000294.txt  \n",
            "  inflating: ./data/clue_pretrain_0000295.txt  \n",
            "  inflating: ./data/clue_pretrain_0000296.txt  \n",
            "  inflating: ./data/clue_pretrain_0000297.txt  \n",
            "  inflating: ./data/clue_pretrain_0000298.txt  \n",
            "  inflating: ./data/clue_pretrain_0000299.txt  \n",
            "  inflating: ./data/clue_pretrain_0000300.txt  \n",
            "  inflating: ./data/clue_pretrain_0000301.txt  \n",
            "  inflating: ./data/clue_pretrain_0000302.txt  \n",
            "  inflating: ./data/clue_pretrain_0000303.txt  \n",
            "  inflating: ./data/clue_pretrain_0000304.txt  \n",
            "  inflating: ./data/clue_pretrain_0000305.txt  \n",
            "  inflating: ./data/clue_pretrain_0000306.txt  \n",
            "  inflating: ./data/clue_pretrain_0000307.txt  \n",
            "  inflating: ./data/clue_pretrain_0000308.txt  \n",
            "  inflating: ./data/clue_pretrain_0000309.txt  \n",
            "  inflating: ./data/clue_pretrain_0000310.txt  \n",
            "  inflating: ./data/clue_pretrain_0000311.txt  \n",
            "  inflating: ./data/clue_pretrain_0000312.txt  \n",
            "  inflating: ./data/clue_pretrain_0000313.txt  \n",
            "  inflating: ./data/clue_pretrain_0000314.txt  \n",
            "  inflating: ./data/clue_pretrain_0000315.txt  \n",
            "  inflating: ./data/clue_pretrain_0000316.txt  \n",
            "  inflating: ./data/clue_pretrain_0000317.txt  \n",
            "  inflating: ./data/clue_pretrain_0000318.txt  \n",
            "  inflating: ./data/clue_pretrain_0000319.txt  \n",
            "  inflating: ./data/clue_pretrain_0000320.txt  \n",
            "  inflating: ./data/clue_pretrain_0000321.txt  \n",
            "  inflating: ./data/clue_pretrain_0000322.txt  \n",
            "  inflating: ./data/clue_pretrain_0000323.txt  \n",
            "  inflating: ./data/clue_pretrain_0000324.txt  \n",
            "  inflating: ./data/clue_pretrain_0000325.txt  \n",
            "  inflating: ./data/clue_pretrain_0000326.txt  \n",
            "  inflating: ./data/clue_pretrain_0000327.txt  \n",
            "  inflating: ./data/clue_pretrain_0000328.txt  \n",
            "  inflating: ./data/clue_pretrain_0000329.txt  \n",
            "  inflating: ./data/clue_pretrain_0000330.txt  \n",
            "  inflating: ./data/clue_pretrain_0000331.txt  \n",
            "  inflating: ./data/clue_pretrain_0000332.txt  \n",
            "  inflating: ./data/clue_pretrain_0000333.txt  \n",
            "  inflating: ./data/clue_pretrain_0000334.txt  \n",
            "  inflating: ./data/clue_pretrain_0000335.txt  \n",
            "  inflating: ./data/clue_pretrain_0000336.txt  \n",
            "  inflating: ./data/clue_pretrain_0000337.txt  \n",
            "  inflating: ./data/clue_pretrain_0000338.txt  \n",
            "  inflating: ./data/clue_pretrain_0000339.txt  \n",
            "  inflating: ./data/clue_pretrain_0000340.txt  \n",
            "  inflating: ./data/clue_pretrain_0000341.txt  \n",
            "  inflating: ./data/clue_pretrain_0000342.txt  \n",
            "  inflating: ./data/clue_pretrain_0000343.txt  \n",
            "  inflating: ./data/clue_pretrain_0000344.txt  \n",
            "  inflating: ./data/clue_pretrain_0000345.txt  \n",
            "  inflating: ./data/clue_pretrain_0000346.txt  \n",
            "  inflating: ./data/clue_pretrain_0000347.txt  \n",
            "  inflating: ./data/clue_pretrain_0000348.txt  \n",
            "  inflating: ./data/clue_pretrain_0000349.txt  \n",
            "  inflating: ./data/clue_pretrain_0000350.txt  \n",
            "  inflating: ./data/clue_pretrain_0000351.txt  \n",
            "  inflating: ./data/clue_pretrain_0000352.txt  \n",
            "  inflating: ./data/clue_pretrain_0000353.txt  \n",
            "  inflating: ./data/clue_pretrain_0000354.txt  \n",
            "  inflating: ./data/clue_pretrain_0000355.txt  \n",
            "  inflating: ./data/clue_pretrain_0000356.txt  \n",
            "  inflating: ./data/clue_pretrain_0000357.txt  \n",
            "  inflating: ./data/clue_pretrain_0000358.txt  \n",
            "  inflating: ./data/clue_pretrain_0000359.txt  \n",
            "  inflating: ./data/clue_pretrain_0000360.txt  \n",
            "  inflating: ./data/clue_pretrain_0000361.txt  \n",
            "  inflating: ./data/clue_pretrain_0000362.txt  \n",
            "  inflating: ./data/clue_pretrain_0000363.txt  \n",
            "  inflating: ./data/clue_pretrain_0000364.txt  \n",
            "  inflating: ./data/clue_pretrain_0000365.txt  \n",
            "  inflating: ./data/clue_pretrain_0000366.txt  \n",
            "  inflating: ./data/clue_pretrain_0000367.txt  \n",
            "  inflating: ./data/clue_pretrain_0000368.txt  \n",
            "  inflating: ./data/clue_pretrain_0000369.txt  \n",
            "  inflating: ./data/clue_pretrain_0000370.txt  \n",
            "  inflating: ./data/clue_pretrain_0000371.txt  \n",
            "  inflating: ./data/clue_pretrain_0000372.txt  \n",
            "  inflating: ./data/clue_pretrain_0000373.txt  \n",
            "  inflating: ./data/clue_pretrain_0000374.txt  \n",
            "  inflating: ./data/clue_pretrain_0000375.txt  \n",
            "  inflating: ./data/clue_pretrain_0000376.txt  \n",
            "  inflating: ./data/clue_pretrain_0000377.txt  \n",
            "  inflating: ./data/clue_pretrain_0000378.txt  \n",
            "  inflating: ./data/clue_pretrain_0000379.txt  \n",
            "  inflating: ./data/clue_pretrain_0000380.txt  \n",
            "  inflating: ./data/clue_pretrain_0000381.txt  \n",
            "  inflating: ./data/clue_pretrain_0000382.txt  \n",
            "  inflating: ./data/clue_pretrain_0000383.txt  \n",
            "  inflating: ./data/clue_pretrain_0000384.txt  \n",
            "  inflating: ./data/clue_pretrain_0000385.txt  \n",
            "  inflating: ./data/clue_pretrain_0000386.txt  \n",
            "  inflating: ./data/clue_pretrain_0000387.txt  \n",
            "  inflating: ./data/clue_pretrain_0000388.txt  \n",
            "  inflating: ./data/clue_pretrain_0000389.txt  \n",
            "  inflating: ./data/clue_pretrain_0000390.txt  \n",
            "  inflating: ./data/clue_pretrain_0000391.txt  \n",
            "  inflating: ./data/clue_pretrain_0000392.txt  \n",
            "  inflating: ./data/clue_pretrain_0000393.txt  \n",
            "  inflating: ./data/clue_pretrain_0000394.txt  \n",
            "  inflating: ./data/clue_pretrain_0000395.txt  \n",
            "  inflating: ./data/clue_pretrain_0000396.txt  \n",
            "  inflating: ./data/clue_pretrain_0000397.txt  \n",
            "  inflating: ./data/clue_pretrain_0000398.txt  \n",
            "  inflating: ./data/clue_pretrain_0000399.txt  \n",
            "  inflating: ./data/clue_pretrain_0000400.txt  \n",
            "  inflating: ./data/clue_pretrain_0000401.txt  \n",
            "  inflating: ./data/clue_pretrain_0000402.txt  \n",
            "  inflating: ./data/clue_pretrain_0000403.txt  \n",
            "  inflating: ./data/clue_pretrain_0000404.txt  \n",
            "  inflating: ./data/clue_pretrain_0000405.txt  \n",
            "  inflating: ./data/clue_pretrain_0000406.txt  \n",
            "  inflating: ./data/clue_pretrain_0000407.txt  \n",
            "  inflating: ./data/clue_pretrain_0000408.txt  \n",
            "  inflating: ./data/clue_pretrain_0000409.txt  \n",
            "  inflating: ./data/clue_pretrain_0000410.txt  \n",
            "  inflating: ./data/clue_pretrain_0000411.txt  \n",
            "  inflating: ./data/clue_pretrain_0000412.txt  \n",
            "  inflating: ./data/clue_pretrain_0000413.txt  \n",
            "  inflating: ./data/clue_pretrain_0000414.txt  \n",
            "  inflating: ./data/clue_pretrain_0000415.txt  \n",
            "  inflating: ./data/clue_pretrain_0000416.txt  \n",
            "  inflating: ./data/clue_pretrain_0000417.txt  \n",
            "  inflating: ./data/clue_pretrain_0000418.txt  \n",
            "  inflating: ./data/clue_pretrain_0000419.txt  \n",
            "  inflating: ./data/clue_pretrain_0000420.txt  \n",
            "  inflating: ./data/clue_pretrain_0000421.txt  \n",
            "  inflating: ./data/clue_pretrain_0000422.txt  \n",
            "  inflating: ./data/clue_pretrain_0000423.txt  \n",
            "  inflating: ./data/clue_pretrain_0000424.txt  \n",
            "  inflating: ./data/clue_pretrain_0000425.txt  \n",
            "  inflating: ./data/clue_pretrain_0000426.txt  \n",
            "  inflating: ./data/clue_pretrain_0000427.txt  \n",
            "  inflating: ./data/clue_pretrain_0000428.txt  \n",
            "  inflating: ./data/clue_pretrain_0000429.txt  \n",
            "  inflating: ./data/clue_pretrain_0000430.txt  \n",
            "  inflating: ./data/clue_pretrain_0000431.txt  \n",
            "  inflating: ./data/clue_pretrain_0000432.txt  \n",
            "  inflating: ./data/clue_pretrain_0000433.txt  \n",
            "  inflating: ./data/clue_pretrain_0000434.txt  \n",
            "  inflating: ./data/clue_pretrain_0000435.txt  \n",
            "  inflating: ./data/clue_pretrain_0000436.txt  \n",
            "  inflating: ./data/clue_pretrain_0000437.txt  \n",
            "  inflating: ./data/clue_pretrain_0000438.txt  \n",
            "  inflating: ./data/clue_pretrain_0000439.txt  \n",
            "  inflating: ./data/clue_pretrain_0000440.txt  \n",
            "  inflating: ./data/clue_pretrain_0000441.txt  \n",
            "  inflating: ./data/clue_pretrain_0000442.txt  \n",
            "  inflating: ./data/clue_pretrain_0000443.txt  \n",
            "  inflating: ./data/clue_pretrain_0000444.txt  \n",
            "  inflating: ./data/clue_pretrain_0000445.txt  \n",
            "  inflating: ./data/clue_pretrain_0000446.txt  \n",
            "  inflating: ./data/clue_pretrain_0000447.txt  \n",
            "  inflating: ./data/clue_pretrain_0000448.txt  \n",
            "  inflating: ./data/clue_pretrain_0000449.txt  \n",
            "  inflating: ./data/clue_pretrain_0000450.txt  \n",
            "  inflating: ./data/clue_pretrain_0000451.txt  \n",
            "  inflating: ./data/clue_pretrain_0000452.txt  \n",
            "  inflating: ./data/clue_pretrain_0000453.txt  \n",
            "  inflating: ./data/clue_pretrain_0000454.txt  \n",
            "  inflating: ./data/clue_pretrain_0000455.txt  \n",
            "  inflating: ./data/clue_pretrain_0000456.txt  \n",
            "  inflating: ./data/clue_pretrain_0000457.txt  \n",
            "  inflating: ./data/clue_pretrain_0000458.txt  \n",
            "  inflating: ./data/clue_pretrain_0000459.txt  \n",
            "  inflating: ./data/clue_pretrain_0000460.txt  \n",
            "  inflating: ./data/clue_pretrain_0000461.txt  \n",
            "  inflating: ./data/clue_pretrain_0000462.txt  \n",
            "  inflating: ./data/clue_pretrain_0000463.txt  \n",
            "  inflating: ./data/clue_pretrain_0000464.txt  \n",
            "  inflating: ./data/clue_pretrain_0000465.txt  \n",
            "  inflating: ./data/clue_pretrain_0000466.txt  \n",
            "  inflating: ./data/clue_pretrain_0000467.txt  \n",
            "  inflating: ./data/clue_pretrain_0000468.txt  \n",
            "  inflating: ./data/clue_pretrain_0000469.txt  \n",
            "  inflating: ./data/clue_pretrain_0000470.txt  \n",
            "  inflating: ./data/clue_pretrain_0000471.txt  \n",
            "  inflating: ./data/clue_pretrain_0000472.txt  \n",
            "  inflating: ./data/clue_pretrain_0000473.txt  \n",
            "  inflating: ./data/clue_pretrain_0000474.txt  \n",
            "  inflating: ./data/clue_pretrain_0000475.txt  \n",
            "  inflating: ./data/clue_pretrain_0000476.txt  \n",
            "  inflating: ./data/clue_pretrain_0000477.txt  \n",
            "  inflating: ./data/clue_pretrain_0000478.txt  \n",
            "  inflating: ./data/clue_pretrain_0000479.txt  \n",
            "  inflating: ./data/clue_pretrain_0000480.txt  \n",
            "  inflating: ./data/clue_pretrain_0000481.txt  \n",
            "  inflating: ./data/clue_pretrain_0000482.txt  \n",
            "  inflating: ./data/clue_pretrain_0000483.txt  \n",
            "  inflating: ./data/clue_pretrain_0000484.txt  \n",
            "  inflating: ./data/clue_pretrain_0000485.txt  \n",
            "  inflating: ./data/clue_pretrain_0000486.txt  \n",
            "  inflating: ./data/clue_pretrain_0000487.txt  \n",
            "  inflating: ./data/clue_pretrain_0000488.txt  \n",
            "  inflating: ./data/clue_pretrain_0000489.txt  \n",
            "  inflating: ./data/clue_pretrain_0000490.txt  \n",
            "  inflating: ./data/clue_pretrain_0000491.txt  \n",
            "  inflating: ./data/clue_pretrain_0000492.txt  \n",
            "  inflating: ./data/clue_pretrain_0000493.txt  \n",
            "  inflating: ./data/clue_pretrain_0000494.txt  \n",
            "  inflating: ./data/clue_pretrain_0000495.txt  \n",
            "  inflating: ./data/clue_pretrain_0000496.txt  \n",
            "  inflating: ./data/clue_pretrain_0000497.txt  \n",
            "  inflating: ./data/clue_pretrain_0000498.txt  \n",
            "  inflating: ./data/clue_pretrain_0000499.txt  \n",
            "  inflating: ./data/clue_pretrain_0000500.txt  \n",
            "  inflating: ./data/clue_pretrain_0000501.txt  \n",
            "  inflating: ./data/clue_pretrain_0000502.txt  \n",
            "  inflating: ./data/clue_pretrain_0000503.txt  \n",
            "  inflating: ./data/clue_pretrain_0000504.txt  \n",
            "  inflating: ./data/clue_pretrain_0000505.txt  \n",
            "  inflating: ./data/clue_pretrain_0000506.txt  \n",
            "  inflating: ./data/clue_pretrain_0000507.txt  \n",
            "  inflating: ./data/clue_pretrain_0000508.txt  \n",
            "  inflating: ./data/clue_pretrain_0000509.txt  \n",
            "  inflating: ./data/clue_pretrain_0000510.txt  \n",
            "  inflating: ./data/clue_pretrain_0000511.txt  \n",
            "  inflating: ./data/clue_pretrain_0000512.txt  \n",
            "  inflating: ./data/clue_pretrain_0000513.txt  \n",
            "  inflating: ./data/clue_pretrain_0000514.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-ZyXAOzvBKV"
      },
      "source": [
        "# Metadata\r\n",
        "dataset_path = \"data\"\r\n",
        "dataset_name = \"clue\"\r\n",
        "out_name = dataset_name + \"_tokenized\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOr1_xLMvLab",
        "outputId": "dac23ebe-5cc0-41d7-902c-ed7b44d01678"
      },
      "source": [
        "# Launch tokenization & turning into .tfrecords\r\n",
        "!python data/create_tfrecords_causal.py --seq_len 512 --processes 2 --files_per 1 --input_dir /content/cn_performer/$dataset_path --output_dir $out_name"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-24 06:11:45.040642: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "Downloading: 100% 35.1k/35.1k [00:00<00:00, 415kB/s]\n",
            "Writing TFRecord Files to clue_tokenized. Parsed 11 input files. files_written : : 36126it [01:33, 396.12it/s]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 733, in next\n",
            "    item = self._items.popleft()\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"data/create_tfrecords_causal.py\", line 195, in create_tfrecords_mp\n",
            "    for results in pbar:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1104, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 737, in next\n",
            "    self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 296, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"data/create_tfrecords_causal.py\", line 218, in <module>\n",
            "    results = create_tfrecords_mp(files, args)\n",
            "  File \"data/create_tfrecords_causal.py\", line 199, in create_tfrecords_mp\n",
            "    return meta\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 623, in __exit__\n",
            "    self.terminate()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 548, in terminate\n",
            "    self._terminate()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 581, in _terminate_pool\n",
            "    cls._help_stuff_finish(inqueue, task_handler, len(pool))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 567, in _help_stuff_finish\n",
            "    while task_handler.is_alive() and inqueue._reader.poll():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 913, in wait\n",
            "Process ForkPoolWorker-1:\n",
            "    with _WaitSelector() as selector:\n",
            "  File \"/usr/lib/python3.7/selectors.py\", line 347, in __init__\n",
            "    def __init__(self):\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"data/create_tfrecords_causal.py\", line 157, in create_tfrecords\n",
            "    _tfrecord_count, input_ids_remainder = write_files(input_ids_list_array, files_per=args.files_per, output_dir=args.output_dir, out_name=args.name, start_no = tfrecord_count, process_no=process_no)\n",
            "  File \"data/create_tfrecords_causal.py\", line 78, in write_files\n",
            "    write_to_file(writer, input_ids)\n",
            "  File \"data/create_tfrecords_causal.py\", line 54, in write_to_file\n",
            "    tf_example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
            "KeyboardInterrupt\n",
            "0it [01:37, ?it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmSN1OJjok3W"
      },
      "source": [
        "##### Loading data back in from the Cloud & Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOgpyWyzxblW"
      },
      "source": [
        "# Load back in\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "\r\n",
        "def read_tfrecord(name, batch_size=8):\r\n",
        "    train_ds = tf.data.TFRecordDataset(name)\r\n",
        "\r\n",
        "    # Describe fts for successful decoding\r\n",
        "    # Note we need to add 1 here as we increased the chunk size when writing to account for labels\r\n",
        "    txt_feature_description = {\r\n",
        "        #'input_ids': tf.io.FixedLenFeature([2049], tf.int64, default_value=[0]*2049),\r\n",
        "        #'input_ids': tf.io.FixedLenFeature([1025], tf.int64, default_value=[0]*1025),\r\n",
        "        'input_ids': tf.io.FixedLenFeature([513], tf.int64, default_value=[0]*513),\r\n",
        "    }\r\n",
        "\r\n",
        "    def _parse_txt_function(example_proto):\r\n",
        "      return tf.io.parse_single_example(example_proto, txt_feature_description)\r\n",
        "\r\n",
        "    parsed_ds = train_ds.map(_parse_txt_function)\r\n",
        "\r\n",
        "    parsed_ds = parsed_ds.shuffle(1000).batch(batch_size)\r\n",
        "\r\n",
        "    return parsed_ds"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9HMckfbydK_"
      },
      "source": [
        "# Load 200MB Files from Cloud Bucket\r\n",
        "#FILENAME_PATTERN = f\"gs://exp_niklas/clue_tokenized200/*.tfrecords\"\r\n",
        "FILENAME_PATTERN = \"clue_tokenized/*\"\r\n",
        "filenames = tf.io.gfile.glob(FILENAME_PATTERN)\r\n",
        "train_ds = read_tfrecord(filenames, batch_size=1)\r\n",
        "\r\n",
        "# For TPU we need to read them in from the Cloud"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uoRF4Yh0mgQ"
      },
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Config"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSpBvJSUyjDO"
      },
      "source": [
        "# Train\r\n",
        "\r\n",
        "def create_model(pretrained=False):\r\n",
        "    \"\"\"\r\n",
        "    Creates Model\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    if pretrained:\r\n",
        "      # Seq Len of train_ds must be 1024\r\n",
        "      base_model = TFGPT2LMHeadModel.from_pretrained(\"mymusise/gpt2-medium-chinese\", return_dict=False)\r\n",
        "\r\n",
        "    else:\r\n",
        "      config = GPT2Config.from_pretrained(\"mymusise/gpt2-medium-chinese\")\r\n",
        "      config.n_ctx = 512\r\n",
        "      config.n_embd = 512\r\n",
        "      config.n_positions = 512\r\n",
        "\r\n",
        "      base_model = TFGPT2LMHeadModel(config)\r\n",
        "\r\n",
        "\r\n",
        "    model = Wrapper(base_model)\r\n",
        "    return model\r\n",
        "\r\n",
        "### Modelling - Static ###\r\n",
        "\r\n",
        "class Wrapper(tf.keras.Model):\r\n",
        "    def __init__(self, model, *args, **kwargs):\r\n",
        "        super().__init__(*args, **kwargs)\r\n",
        "        self.model = model\r\n",
        "        # Track loss (Loss itself its CategoricalCrossEnt.)\r\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name='loss') \r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def train_step(self, data):\r\n",
        "        # Data is a dictionary\r\n",
        "        x = data[\"input_ids\"][:, :-1]\r\n",
        "        y = data[\"input_ids\"][:, 1:]\r\n",
        "\r\n",
        "        print(x)\r\n",
        "        print(x.shape)\r\n",
        "\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            # Forward pass\r\n",
        "            y_pred = self.model(x, training=True)\r\n",
        "            # Compute the loss value.\r\n",
        "            y_pred = y_pred.logits\r\n",
        "            loss = self.compute_loss(y, y_pred)\r\n",
        "            # Reduce loss to single digit\r\n",
        "            loss = tf.reduce_mean(loss)\r\n",
        "\r\n",
        "        # Compute gradients\r\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\r\n",
        "        # Update weights\r\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n",
        "        # Update loss tracker\r\n",
        "        self.loss_tracker.update_state(loss)  \r\n",
        "        # Update metrics\r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "    def test_step(self, data):\r\n",
        "        # Data is a dictionary\r\n",
        "        x = data[\"input_ids\"][:, :-1]\r\n",
        "        y = data[\"input_ids\"][:, 1:]\r\n",
        "\r\n",
        "        # Compute predictions\r\n",
        "        y_pred = self.model(x, training=False)\r\n",
        "        y_pred = y_pred.logits\r\n",
        "        loss = self.compute_loss(y, y_pred)\r\n",
        "\r\n",
        "        # Updates the metrics tracking the loss\r\n",
        "        self.loss_tracker.update_state(loss)  \r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "    def compute_loss(self, labels, logits):\r\n",
        "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "            from_logits=True, reduction=tf.keras.losses.Reduction.NONE\r\n",
        "        )\r\n",
        "        # make sure only labels that are not equal to -100 do affect loss\r\n",
        "        active_loss = tf.not_equal(tf.reshape(labels, (-1,)), -100)\r\n",
        "        reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[2])), active_loss)\r\n",
        "        labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\r\n",
        "\r\n",
        "        return loss_fn(labels, reduced_logits)\r\n",
        "        \r\n",
        "def shape_list(tensor: tf.Tensor):\r\n",
        "    \"\"\"\r\n",
        "    Deal with dynamic shape in tensorflow cleanly.\r\n",
        "    Args:\r\n",
        "        tensor (:obj:`tf.Tensor`): The tensor we want the shape of.\r\n",
        "    Returns:\r\n",
        "        :obj:`List[int]`: The shape of the tensor as a list.\r\n",
        "\r\n",
        "    ### TODO: Move to compute_loss\r\n",
        "    \"\"\"\r\n",
        "    dynamic = tf.shape(tensor)\r\n",
        "\r\n",
        "    if tensor.shape == tf.TensorShape(None):\r\n",
        "        return dynamic\r\n",
        "\r\n",
        "    static = tensor.shape.as_list()\r\n",
        "\r\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831,
          "referenced_widgets": [
            "9bd3dbf53b2f4e38ae111a4451a6c1b0",
            "53d032db0abb4a1aa4e38dd1569f7447",
            "bc1ae04d61db43a58dfd224fdf2117b5",
            "78dc3c317d414bb9a6498b18b032c226",
            "6b03e73a9bf24e999b8181445cc30baf",
            "3f2524e83b764122a0c048a7f3d6276f",
            "8f9d02ab1b984106a60a3ced2215096b",
            "6757791ca9b54fe18937b7a2914f54b8"
          ]
        },
        "id": "3WfqpeH10cmE",
        "outputId": "8de48f81-198f-4dae-ecc9-323cadb33621"
      },
      "source": [
        "model = create_model()\r\n",
        "\r\n",
        "learning_rate = 1e-5\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\r\n",
        "model.compile(optimizer=optimizer,\r\n",
        "              metrics=['sparse_categorical_accuracy'])\r\n",
        "\r\n",
        "model.fit(train_ds,\r\n",
        "          epochs=5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bd3dbf53b2f4e38ae111a4451a6c1b0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=911.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "Tensor(\"strided_slice:0\", shape=(None, 512), dtype=int64)\n",
            "(None, 512)\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f6cc07c8bb0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f6cc07c8bb0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f6cdbb760e0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f6cdbb760e0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "Tensor(\"strided_slice:0\", shape=(None, 512), dtype=int64)\n",
            "(None, 512)\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "   6415/Unknown - 927s 135ms/step - sparse_categorical_accuracy: 0.0722 - loss: 6.4381"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-98300a8d48b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m model.fit(train_ds,\n\u001b[0;32m----> 9\u001b[0;31m           epochs=5)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVJJLNy_0iMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364fe922-cbf8-4522-9e91-281edb790619"
      },
      "source": [
        "from transformers import TextGenerationPipeline, BertTokenizerFast\r\n",
        "\r\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"mymusise/gpt2-medium-chinese\")\r\n",
        "model = create_model(pretrained=True)\r\n",
        "\r\n",
        "text_generater = TextGenerationPipeline(model.model, tokenizer)\r\n",
        "\r\n",
        "texts = [\r\n",
        "    '少年对面站着一位中年人，这位中年人两鬓略有些斑白，穿着一套青衫。尽管衣衫有些脱色，但却洗得很干净。',\r\n",
        "]\r\n",
        "\r\n",
        "for text in texts:\r\n",
        "    print(text_generater(text, max_length=120 + len(text), do_sample=True, top_k=10, no_repeat_ngram_size=3))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at mymusise/gpt2-medium-chinese.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[{'generated_text': '少年对面站着一位中年人，这位中年人两鬓略有些斑白，穿着一套青衫。尽管衣衫有些脱色，但却洗得很干净。 他 的 双 手 仍 旧 紧 握 在 胸 前 ， 一 个 劲 儿 地 往 后 推 ， “ 哎 呀 ！ ” 我 说 道 ： “ 你 好 啊 ！ 这 真 是 太 可 笑 了 — — 你 要 把 这 件 事 讲 给 别 人 听 ？ 不 过 ， 我 没 办 法 讲 出 来 — — 只 是 ， 我 不 知 道 为 什 么 我 才 想 到 那 些 。 你 要 是 能 够 帮 我 找 到 这 样 的 机 会 呢 — — ” “ 哦 — — 嗯 ， 当 然 啦 ， 当 时 我 不 愿 意 谈'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lkk4KBwcuicE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}