{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MaskedPretraining_Static.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IW0_DO17MLT0",
        "4lzKWR3FMJVQ",
        "ccXBubyiL8Ud"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "568322d56fb64758a5ecf8c6d8786cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c321328f0b2e40978237638f26c151a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_16ddcb359e7b4295910bccff5c61f335",
              "IPY_MODEL_7217f962054842799d48b6b558996053"
            ]
          }
        },
        "c321328f0b2e40978237638f26c151a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16ddcb359e7b4295910bccff5c61f335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8b499effc4914a7db2a943ef40945768",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2491,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2491,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94ddbe80ba0041209301cf506593c441"
          }
        },
        "7217f962054842799d48b6b558996053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08fafe75321045279e6c70b06052a81b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6.70k/? [00:01&lt;00:00, 3.91kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6bac16ec0e1d46688ba31bcd81202dd7"
          }
        },
        "8b499effc4914a7db2a943ef40945768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94ddbe80ba0041209301cf506593c441": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08fafe75321045279e6c70b06052a81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6bac16ec0e1d46688ba31bcd81202dd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c197461d1ff449ceb6f179452110b144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e2d2bfde68294103b752104e3f38097a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_60eeca88fb6647cda5e42bb12a2178b7",
              "IPY_MODEL_702df702f21a4c4e8e50e3be7f715c6e"
            ]
          }
        },
        "e2d2bfde68294103b752104e3f38097a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60eeca88fb6647cda5e42bb12a2178b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_88c3b9a1c5d44212a5e289c913fb49e2",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1798,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1798,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9c6c575ce7245b6987b3ea84ab470a1"
          }
        },
        "702df702f21a4c4e8e50e3be7f715c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19ef250902e54880a5059a4e89124c67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6.86k/? [00:00&lt;00:00, 154kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bc630b2bf3441ccaa3945156c66f6c3"
          }
        },
        "88c3b9a1c5d44212a5e289c913fb49e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9c6c575ce7245b6987b3ea84ab470a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19ef250902e54880a5059a4e89124c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bc630b2bf3441ccaa3945156c66f6c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5bd0e32b99743508baa38a048374ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57b613711bf14e87afe277b156fe5178",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ed5a35ae95744dfe8c8eb1acf468f976",
              "IPY_MODEL_ae5822b03a794e0e915b7dfa525e821c"
            ]
          }
        },
        "57b613711bf14e87afe277b156fe5178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed5a35ae95744dfe8c8eb1acf468f976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ee47c744b1d4b31be1a47b5bf84ebec",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1153662,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1153662,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37670b532a3c4e8b8d12062bac375d95"
          }
        },
        "ae5822b03a794e0e915b7dfa525e821c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_993bad1ce23b4b81a7dda9e6252d1eb5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.29M/? [00:00&lt;00:00, 7.62MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0f2347a456f40ae80291e27bff8eff2"
          }
        },
        "3ee47c744b1d4b31be1a47b5bf84ebec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37670b532a3c4e8b8d12062bac375d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "993bad1ce23b4b81a7dda9e6252d1eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0f2347a456f40ae80291e27bff8eff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2db23a2814474cafae655348e4ed5108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aafde8d1f7d24e649e6c08124f6165c5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9e611828f721498e86da2c50793f26d1",
              "IPY_MODEL_4aa41639b5f2425593a96b48fdba9845"
            ]
          }
        },
        "aafde8d1f7d24e649e6c08124f6165c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e611828f721498e86da2c50793f26d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1bb64d0a991545499216867caee3ccff",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 381112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 381112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68e49526016b44919f91300161fafbb8"
          }
        },
        "4aa41639b5f2425593a96b48fdba9845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35e1649ba23a4cb8ae6f51bb942a5a20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.09M/? [00:00&lt;00:00, 2.18MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d06e37f3a45e45239d1134b2872afd8f"
          }
        },
        "1bb64d0a991545499216867caee3ccff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68e49526016b44919f91300161fafbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35e1649ba23a4cb8ae6f51bb942a5a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d06e37f3a45e45239d1134b2872afd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef09d7c9ca0441779ad44e3dfd54bbca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dcf45aad48cb48319c5acae2dddb1988",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b55aff28610e484892c41d45b04f3b89",
              "IPY_MODEL_e12ac23fd6434e60b428eaa415f6ec50"
            ]
          }
        },
        "dcf45aad48cb48319c5acae2dddb1988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b55aff28610e484892c41d45b04f3b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_718a4b616e444f0dbe69cdbc57571568",
            "_dom_classes": [],
            "description": "Downloading: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 390071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 390071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e4fa47a6f0b4d7ca3535ba0d11dbc82"
          }
        },
        "e12ac23fd6434e60b428eaa415f6ec50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8aedd780d064644a38b0072590788cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.10M/? [00:00&lt;00:00, 7.65MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9368b07041545daa76d7c9a2a8b8deb"
          }
        },
        "718a4b616e444f0dbe69cdbc57571568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e4fa47a6f0b4d7ca3535ba0d11dbc82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8aedd780d064644a38b0072590788cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9368b07041545daa76d7c9a2a8b8deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0fa85e402a34724bd541535e58c80c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6d4251ed6fbc4c188593697a57230847",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8019e8b59a8f4909bf8895af95ea8ef2",
              "IPY_MODEL_5f415b97c5504a96ab043fd1c25d24da"
            ]
          }
        },
        "6d4251ed6fbc4c188593697a57230847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8019e8b59a8f4909bf8895af95ea8ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba5a2e7351ef4f62ad0f5b1df814c275",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3658d96f6e164ad29cdceea61051a9a7"
          }
        },
        "5f415b97c5504a96ab043fd1c25d24da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6088f03a11574df6817ca1ed2ff6bcf1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3138/0 [00:00&lt;00:00, 5754.32 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f88961e613df46c9b87828cbbd20ee18"
          }
        },
        "ba5a2e7351ef4f62ad0f5b1df814c275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3658d96f6e164ad29cdceea61051a9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6088f03a11574df6817ca1ed2ff6bcf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f88961e613df46c9b87828cbbd20ee18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4f80d88ef564cd09713001d81934760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8a282c3590ba4cbfb14398e2a866e3ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2645ba4a104347eab7a844cd296539fd",
              "IPY_MODEL_a9b4289851a94b0bb80f3dd252808335"
            ]
          }
        },
        "8a282c3590ba4cbfb14398e2a866e3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2645ba4a104347eab7a844cd296539fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e5c53175d5749c9ae56ab85370f9045",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_475a27b6d1a24d9ca27f77894ef8a647"
          }
        },
        "a9b4289851a94b0bb80f3dd252808335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a4eed4ad781483cb58127dfcc98252a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1045/0 [00:00&lt;00:00, 9856.63 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22c98f8644a5466e89f2a17e1123080d"
          }
        },
        "3e5c53175d5749c9ae56ab85370f9045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "475a27b6d1a24d9ca27f77894ef8a647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a4eed4ad781483cb58127dfcc98252a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22c98f8644a5466e89f2a17e1123080d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d18ae16c5bbd4c379f828edaa9b1e90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_02e4f4f9aa03476ea682a68a93d8879a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f8c23830bac64699ad05f0477b98dfd0",
              "IPY_MODEL_af9965a753f24379b5bbb4ac104ce212"
            ]
          }
        },
        "02e4f4f9aa03476ea682a68a93d8879a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8c23830bac64699ad05f0477b98dfd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_05ac339a51b54f5e85ad8ed6941b7d46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f22c1ff2783741098b863f0f7b2e09dc"
          }
        },
        "af9965a753f24379b5bbb4ac104ce212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_46f8933245c74a20b3c8c526f1e03023",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1046/0 [00:00&lt;00:00, 836.43 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61be8844dbff4cceb124a5564006d9d4"
          }
        },
        "05ac339a51b54f5e85ad8ed6941b7d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f22c1ff2783741098b863f0f7b2e09dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46f8933245c74a20b3c8c526f1e03023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61be8844dbff4cceb124a5564006d9d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b483d61fb0c54cb7842aa53d39691ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_acad8bd5b50f45d8bb17e22c5f2e8299",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a7f22a5b22f34be0bcb177cf4d25b62f",
              "IPY_MODEL_7816db73e742409c846ed6ecc171a6ff"
            ]
          }
        },
        "acad8bd5b50f45d8bb17e22c5f2e8299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7f22a5b22f34be0bcb177cf4d25b62f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_57c1fd09f3ea4fb58ebc630e45a61ba7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3138,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3138,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7de8697aeba425d838903bdf3da17a6"
          }
        },
        "7816db73e742409c846ed6ecc171a6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_56f78d3a6c014dbbb832246e648a8f9a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3138/3138 [05:13&lt;00:00, 10.00ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38355d10c07d4936b4f55fd977d6b1bc"
          }
        },
        "57c1fd09f3ea4fb58ebc630e45a61ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7de8697aeba425d838903bdf3da17a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56f78d3a6c014dbbb832246e648a8f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38355d10c07d4936b4f55fd977d6b1bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21918dda4c7e47efa352821504fbae13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57fef615ca9547fd97f8b897014006c1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a579ef37937545ff8d635340e3cf0c90",
              "IPY_MODEL_8c670412622a4b46896a8a8ef5f32578"
            ]
          }
        },
        "57fef615ca9547fd97f8b897014006c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a579ef37937545ff8d635340e3cf0c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d1ed8f2b1ce642549fa245b0295a243c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 624,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 624,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4393b5ab57104262a99312eb5c6fe3e3"
          }
        },
        "8c670412622a4b46896a8a8ef5f32578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7ca9773aa9f94e258f9d463e7e5d9598",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 624/624 [00:00&lt;00:00, 4.13kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c276c070caa14c69a1cebef75a18ca7c"
          }
        },
        "d1ed8f2b1ce642549fa245b0295a243c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4393b5ab57104262a99312eb5c6fe3e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ca9773aa9f94e258f9d463e7e5d9598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c276c070caa14c69a1cebef75a18ca7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "057c9a87a44a49299776c7868af8d183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b23ae96d04e0452389c7b01ba3713f0e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_951493546e0c4323a7b56f5addc0bb86",
              "IPY_MODEL_3279160bbaa141529ae23c90b1e0cbe5"
            ]
          }
        },
        "b23ae96d04e0452389c7b01ba3713f0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "951493546e0c4323a7b56f5addc0bb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fbe7712db72845f6ae57bc3ac3a59044",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f32008f9e04b43408aabeed7f921bb0a"
          }
        },
        "3279160bbaa141529ae23c90b1e0cbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_494f16ccf18f436c8512f45494f1c6af",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110k/110k [02:17&lt;00:00, 796B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d3579f3106f40a5bfb76808f5256287"
          }
        },
        "fbe7712db72845f6ae57bc3ac3a59044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f32008f9e04b43408aabeed7f921bb0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "494f16ccf18f436c8512f45494f1c6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d3579f3106f40a5bfb76808f5256287": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f4da41b4b5744da913ff07a24d72f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6233ecdbb1a9445b8186fe046a63864d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d313110761b4bbdb25f4d0113338253",
              "IPY_MODEL_2e16a035d2194664af1f253e0853d0ca"
            ]
          }
        },
        "6233ecdbb1a9445b8186fe046a63864d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d313110761b4bbdb25f4d0113338253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af0084681d5f42ba8374c2e0b9b75c15",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 268943,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 268943,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5436a00c2faf40d295057c5ea0bccb64"
          }
        },
        "2e16a035d2194664af1f253e0853d0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_47100ecd5e48476fb1c4e77b4a070454",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 269k/269k [02:16&lt;00:00, 1.97kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fabfd0d6ce14dd5b60b10bba9acfaf7"
          }
        },
        "af0084681d5f42ba8374c2e0b9b75c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5436a00c2faf40d295057c5ea0bccb64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47100ecd5e48476fb1c4e77b4a070454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fabfd0d6ce14dd5b60b10bba9acfaf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9962520077da4aecb473a36ec48ed99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c1396643605643449373a1f556d75a60",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03db9554d4c14282ac7549d8475ae167",
              "IPY_MODEL_092303ffa2be4c3bad630a0a1bdf1203"
            ]
          }
        },
        "c1396643605643449373a1f556d75a60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03db9554d4c14282ac7549d8475ae167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a77adb7390bf48ddbc28542790ba95a5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 164437832,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 164437832,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a6a143447cc4559887bdad2efb248e5"
          }
        },
        "092303ffa2be4c3bad630a0a1bdf1203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8eee2f7d988541aaae3a9638f6db6970",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 164M/164M [02:15&lt;00:00, 1.22MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5369bb8eb859478f86ba12fcb66a1ae6"
          }
        },
        "a77adb7390bf48ddbc28542790ba95a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a6a143447cc4559887bdad2efb248e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8eee2f7d988541aaae3a9638f6db6970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5369bb8eb859478f86ba12fcb66a1ae6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3273f1da65e432f9d9dcf93e14a07dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b253d683e9834c458804fab249a10d96",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_903596cf4f9940f4b14a4277d0312b8d",
              "IPY_MODEL_369fba7e21814c4f87b773518ad2fea1"
            ]
          }
        },
        "b253d683e9834c458804fab249a10d96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "903596cf4f9940f4b14a4277d0312b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70f8eb70939444dd8a34b7c9db6aefaa",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3138,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3138,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1147ec61e02a4faa92033e8ef623af23"
          }
        },
        "369fba7e21814c4f87b773518ad2fea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e49d9a21b1d842ecae8c60ff0fe47826",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3138/3138 [09:40&lt;00:00,  5.41ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_718e818c54d14271adbf3f3c8566308c"
          }
        },
        "70f8eb70939444dd8a34b7c9db6aefaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1147ec61e02a4faa92033e8ef623af23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e49d9a21b1d842ecae8c60ff0fe47826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "718e818c54d14271adbf3f3c8566308c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c475871932b445bfb429dc9717ec8b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1e93243c3eef4c0190f68e064a06552c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_817d82183113409b90656ee9587b897a",
              "IPY_MODEL_2e8bfbf265e441eca19fa4241bbedf40"
            ]
          }
        },
        "1e93243c3eef4c0190f68e064a06552c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "817d82183113409b90656ee9587b897a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dbd029a116e748febd6484e562be5d4c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_beaf0858ba19499cbe27930d4ab4a51d"
          }
        },
        "2e8bfbf265e441eca19fa4241bbedf40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3bb04dbe3e4a4d9185ad1c6cfd2a40cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 8.87kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b85b3a1d41164996a3ab423c48577d58"
          }
        },
        "dbd029a116e748febd6484e562be5d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "beaf0858ba19499cbe27930d4ab4a51d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3bb04dbe3e4a4d9185ad1c6cfd2a40cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b85b3a1d41164996a3ab423c48577d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOHUaZlzk7N2",
        "outputId": "c7373636-61f4-4599-c501-97716174dde3"
      },
      "source": [
        "!pip install -q transformers\r\n",
        "!pip install -q datasets\r\n",
        "!pip install -q ltp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 4.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 42.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 57.0MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 163kB 3.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.7MB 1.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 61.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 3.6MB/s \n",
            "\u001b[?25h  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T7jOv2qqgYP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW0_DO17MLT0"
      },
      "source": [
        "##### WWM Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qIxq8O7MRIK"
      },
      "source": [
        "## Whole Word Masking\r\n",
        "\r\n",
        "### WWM for CN\r\n",
        "\r\n",
        "# References:\r\n",
        "# https://github.com/brightmart/roberta_zh/blob/13f7849f0cb0e11573e032acddb35b83b096224e/create_pretraining_data.py\r\n",
        "# https://github.com/huggingface/transformers/blob/9152f16023b59d262b51573714b40325c8e49370/examples/legacy/run_chinese_ref.py#L78\r\n",
        "\r\n",
        "\r\n",
        "# 1) Generate ref ids based on LTP tokenizer > prepare_ref\r\n",
        "# 2) Generate mask for whole words\r\n",
        "# 3) Implement the masking\r\n",
        "\r\n",
        "from transformers import AutoTokenizer\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "from ltp import LTP\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "\r\n",
        "def random_word(tokens, ref_ids, tokenizer):\r\n",
        "    \"\"\"\r\n",
        "    Masking some random tokens for Language Model task with probabilities as in the original BERT paper.\r\n",
        "    :param tokens: list of str, tokenized sentence.\r\n",
        "    :param ref_ids: list of int, 1 is where to place a mask\r\n",
        "    :param tokenizer: Tokenizer, object used for tokenization (we need it's vocab here)\r\n",
        "    :return: (list of str, list of int), masked tokens and related labels for LM prediction\r\n",
        "    \"\"\"\r\n",
        "    output_label = []\r\n",
        "\r\n",
        "    for i, (token, ref_id) in enumerate(zip(tokens, ref_ids)):\r\n",
        "\r\n",
        "        prob = random.random()\r\n",
        "\r\n",
        "        if ref_id == 1:\r\n",
        "\r\n",
        "            # 80% randomly change token to mask token\r\n",
        "            if prob < 0.8:\r\n",
        "                tokens[i] = \"[MASK]\"\r\n",
        "\r\n",
        "            # 10% randomly change token to random token\r\n",
        "            elif prob < 0.9:\r\n",
        "                tokens[i] = random.choice(list(tokenizer.vocab.items()))[0]\r\n",
        "\r\n",
        "            # -> rest 10% randomly keep current token\r\n",
        "\r\n",
        "            # append current token to output (we will predict these later)\r\n",
        "            try:\r\n",
        "                output_label.append(tokenizer.vocab[token])\r\n",
        "            except KeyError:\r\n",
        "                # For unknown words (should not occur with BPE vocab)\r\n",
        "                output_label.append(tokenizer.vocab[\"[UNK]\"])\r\n",
        "        else:\r\n",
        "            # no masking token (will be ignored by loss function later)\r\n",
        "            output_label.append(-100)\r\n",
        "\r\n",
        "    return tokens, output_label\r\n",
        "\r\n",
        "def _is_chinese_char(cp):\r\n",
        "    \"\"\"\r\n",
        "    Checks whether CP is the codepoint of a CJK character.\r\n",
        "    \"\"\"\r\n",
        "    # This defines a \"chinese character\" as anything in the CJK Unicode block:\r\n",
        "    #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\r\n",
        "    #\r\n",
        "    # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\r\n",
        "    # despite its name. The modern Korean Hangul alphabet is a different block,\r\n",
        "    # as is Japanese Hiragana and Katakana. Those alphabets are used to write\r\n",
        "    # space-separated words, so they are not treated specially and handled\r\n",
        "    # like the all of the other languages.\r\n",
        "    if (\r\n",
        "        (cp >= 0x4E00 and cp <= 0x9FFF)\r\n",
        "        or (cp >= 0x3400 and cp <= 0x4DBF)  #\r\n",
        "        or (cp >= 0x20000 and cp <= 0x2A6DF)  #\r\n",
        "        or (cp >= 0x2A700 and cp <= 0x2B73F)  #\r\n",
        "        or (cp >= 0x2B740 and cp <= 0x2B81F)  #\r\n",
        "        or (cp >= 0x2B820 and cp <= 0x2CEAF)  #\r\n",
        "        or (cp >= 0xF900 and cp <= 0xFAFF)\r\n",
        "        or (cp >= 0x2F800 and cp <= 0x2FA1F)  #\r\n",
        "    ):  #\r\n",
        "        return True\r\n",
        "\r\n",
        "    return False\r\n",
        "\r\n",
        "\r\n",
        "def is_chinese(word):\r\n",
        "    \"\"\"\r\n",
        "    Args:\r\n",
        "      word: str\r\n",
        "    \"\"\"\r\n",
        "    # word like '180' or '身高' or '神'\r\n",
        "    for char in word:\r\n",
        "        char = ord(char)\r\n",
        "        if not _is_chinese_char(char):\r\n",
        "            return 0\r\n",
        "    return 1\r\n",
        "\r\n",
        "\r\n",
        "def get_chinese_word(tokens):\r\n",
        "    \"\"\"\r\n",
        "    Args:\r\n",
        "      List[str]\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    word_set = set()\r\n",
        "\r\n",
        "    for token in tokens:\r\n",
        "        chinese_word = len(token) > 1 and is_chinese(token)\r\n",
        "        if chinese_word:\r\n",
        "            word_set.add(token)\r\n",
        "    word_list = list(word_set)\r\n",
        "    return word_list\r\n",
        "\r\n",
        "\r\n",
        "def add_sub_symbol(bert_tokens, chinese_word_set):\r\n",
        "    \"\"\"\r\n",
        "    Args:\r\n",
        "      bert_tokens: List[str]\r\n",
        "      chinese_word_set: set\r\n",
        "    \"\"\"\r\n",
        "    if not chinese_word_set:\r\n",
        "        return bert_tokens\r\n",
        "    max_word_len = max([len(w) for w in chinese_word_set])\r\n",
        "\r\n",
        "    bert_word = bert_tokens\r\n",
        "    start, end = 0, len(bert_word)\r\n",
        "    while start < end:\r\n",
        "        single_word = True\r\n",
        "        if is_chinese(bert_word[start]):\r\n",
        "            l = min(end - start, max_word_len)\r\n",
        "            for i in range(l, 1, -1):\r\n",
        "                whole_word = \"\".join(bert_word[start : start + i])\r\n",
        "                if whole_word in chinese_word_set:\r\n",
        "                    for j in range(start + 1, start + i):\r\n",
        "                        bert_word[j] = \"##\" + bert_word[j]\r\n",
        "                    start = start + i\r\n",
        "                    single_word = False\r\n",
        "                    break\r\n",
        "        if single_word:\r\n",
        "            start += 1\r\n",
        "    return bert_word\r\n",
        "\r\n",
        "def prepare_ref(lines, ltp_tokenizer, bert_tokenizer):\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    Args:\r\n",
        "      lines: List[str] - e.g. [text1, text2]\r\n",
        "      ltp_tokenizer\r\n",
        "      bert_tokenizer\r\n",
        "\r\n",
        "    Returns:\r\n",
        "      ref_ids: List[List[int], ...]\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    ltp_res = []\r\n",
        "\r\n",
        "    for i in range(0, len(lines), 100):\r\n",
        "        res = ltp_tokenizer.seg(lines[i : i + 100])[0]\r\n",
        "        res = [get_chinese_word(r) for r in res]\r\n",
        "        ltp_res.extend(res)\r\n",
        "    assert len(ltp_res) == len(lines)\r\n",
        "\r\n",
        "    bert_res = []\r\n",
        "    for i in range(0, len(lines), 100):\r\n",
        "        res = bert_tokenizer(lines[i : i + 100], add_special_tokens=True, truncation=True, max_length=512)\r\n",
        "        bert_res.extend(res[\"input_ids\"])\r\n",
        "    assert len(bert_res) == len(lines)\r\n",
        "\r\n",
        "    ref_ids = []\r\n",
        "    for input_ids, chinese_word in zip(bert_res, ltp_res):\r\n",
        "\r\n",
        "        input_tokens = []\r\n",
        "        for id in input_ids:\r\n",
        "            token = bert_tokenizer._convert_id_to_token(id)\r\n",
        "            input_tokens.append(token)\r\n",
        "        input_tokens = add_sub_symbol(input_tokens, chinese_word)\r\n",
        "        ref_id = []\r\n",
        "        # We only save pos of chinese subwords start with ##, which mean is part of a whole word.\r\n",
        "        for i, token in enumerate(input_tokens):\r\n",
        "            if token[:2] == \"##\":\r\n",
        "                clean_token = token[2:]\r\n",
        "                # save chinese tokens' pos\r\n",
        "                if len(clean_token) == 1 and _is_chinese_char(ord(clean_token)):\r\n",
        "                    ref_id.append(i)\r\n",
        "        ref_ids.append(ref_id)\r\n",
        "\r\n",
        "    assert len(ref_ids) == len(bert_res)\r\n",
        "\r\n",
        "    return ref_ids\r\n",
        "\r\n",
        "\r\n",
        "def cn_whole_word_mask(input_tokens, ref_ids, max_predictions=512, mlm_probability=0.15):\r\n",
        "    \"\"\"\r\n",
        "    Masks whole words in CN based on the reference ids & the standard _whole_word_mask for BERT for one individual example.\r\n",
        "\r\n",
        "    Args:\r\n",
        "      input_tokens: List[str]\r\n",
        "      ref_tokens: List[int]\r\n",
        "\r\n",
        "    Returns:\r\n",
        "      input_tokens: List[int]\r\n",
        "\r\n",
        "    TODO:\r\n",
        "      We could save the LTP dependency by copying the function from: https://github.com/HIT-SCIR/ltp/blob/c47b3f455c07c5dcc186f2b674efde8c67612baf/ltp/algorithms/maximum_forward_matching.py#L75\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    for i in range(len(input_tokens)):\r\n",
        "        if i in ref_ids:\r\n",
        "            # We move it back by -1 as the ref_ids start at 1, not 0\r\n",
        "            input_tokens[i-1] = \"##\" + input_tokens[i-1]\r\n",
        "\r\n",
        "    input_tokens = _whole_word_mask(input_tokens)\r\n",
        "\r\n",
        "    return input_tokens\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def _whole_word_mask(input_tokens, max_predictions=512, mlm_probability=0.15):\r\n",
        "    \"\"\"\r\n",
        "    Get 0/1 labels for masked tokens with whole word mask proxy\r\n",
        "\r\n",
        "    Args:\r\n",
        "      input_tokens: List[str]\r\n",
        "\r\n",
        "    Outputs:\r\n",
        "      input_tokens: List[int]\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    cand_indexes = []\r\n",
        "    for (i, token) in enumerate(input_tokens):\r\n",
        "        if token == \"[CLS]\" or token == \"[SEP]\":\r\n",
        "            continue\r\n",
        "\r\n",
        "        if len(cand_indexes) >= 1 and token.startswith(\"##\"):\r\n",
        "            cand_indexes[-1].append(i)\r\n",
        "\r\n",
        "        else:\r\n",
        "            cand_indexes.append([i])\r\n",
        "\r\n",
        "    random.shuffle(cand_indexes)\r\n",
        "    num_to_predict = min(max_predictions, max(1, int(round(len(input_tokens) * mlm_probability))))\r\n",
        "    masked_lms = []\r\n",
        "    covered_indexes = set()\r\n",
        "    for index_set in cand_indexes:\r\n",
        "        if len(masked_lms) >= num_to_predict:\r\n",
        "            break\r\n",
        "        # If adding a whole-word mask would exceed the maximum number of\r\n",
        "        # predictions, then just skip this candidate.\r\n",
        "        if len(masked_lms) + len(index_set) > num_to_predict:\r\n",
        "            continue\r\n",
        "        is_any_index_covered = False\r\n",
        "        for index in index_set:\r\n",
        "            if index in covered_indexes:\r\n",
        "                is_any_index_covered = True\r\n",
        "                break\r\n",
        "        if is_any_index_covered:\r\n",
        "            continue\r\n",
        "        for index in index_set:\r\n",
        "            covered_indexes.add(index)\r\n",
        "            masked_lms.append(index)\r\n",
        "\r\n",
        "    assert len(covered_indexes) == len(masked_lms)\r\n",
        "    mask_labels = [1 if i in covered_indexes else 0 for i in range(len(input_tokens))]\r\n",
        "    return mask_labels\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class WWMTokenizer():\r\n",
        "    def __init__(self, col=\"text\", seq_len=512):\r\n",
        "        \"\"\"\r\n",
        "        Constructs Huggingface CN tokenizer & other\r\n",
        "\r\n",
        "            col: What column to tokenize if pretraining\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        self.tokenizer_cn = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\r\n",
        "        self.tokenizer_ltp = LTP(\"small\")\r\n",
        "        self.max_seq_length = seq_len\r\n",
        "        self.col = col\r\n",
        "\r\n",
        "    def tokenize_pretraining(self, example):\r\n",
        "        \"\"\"\r\n",
        "        Takes in an example & returns pretraining data\r\n",
        "\r\n",
        "        Args:\r\n",
        "            Example: dict with entry \"text\"\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            Dict of TF Tensors\r\n",
        "\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        inputs = example[self.col]\r\n",
        "    \r\n",
        "\r\n",
        "        ref_ids = prepare_ref([inputs], self.tokenizer_ltp, self.tokenizer_cn)\r\n",
        "\r\n",
        "        tokens = self.tokenizer_cn.tokenize(inputs)\r\n",
        "\r\n",
        "        if len(tokens) > self.max_seq_length - 2:\r\n",
        "            tokens = tokens[:(self.max_seq_length - 2)]\r\n",
        "            ref_ids = ref_ids[:(self.max_seq_length - 2)]\r\n",
        "\r\n",
        "        ref_ids = cn_whole_word_mask(tokens, ref_ids[0])\r\n",
        "        tokens, labels = random_word(tokens, ref_ids, self.tokenizer_cn)\r\n",
        "\r\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]']\r\n",
        "        lm_label_ids = ([-100] + labels + [-100])\r\n",
        "\r\n",
        "        input_ids = self.tokenizer_cn.convert_tokens_to_ids(tokens)\r\n",
        "\r\n",
        "        attention_mask = [1] * len(input_ids)\r\n",
        "        token_type_ids = [0] * len(input_ids)\r\n",
        "\r\n",
        "        while len(input_ids) < self.max_seq_length:\r\n",
        "            input_ids.append(0)\r\n",
        "            attention_mask.append(0)\r\n",
        "            token_type_ids.append(0)\r\n",
        "            lm_label_ids.append(-100)\r\n",
        "\r\n",
        "        assert len(input_ids) == self.max_seq_length\r\n",
        "        assert len(attention_mask) == self.max_seq_length\r\n",
        "        assert len(token_type_ids) == self.max_seq_length\r\n",
        "        assert len(lm_label_ids) == self.max_seq_length\r\n",
        "\r\n",
        "\r\n",
        "        outputs = {'input_ids': tf.constant(input_ids), 'attention_mask': tf.constant(attention_mask), \r\n",
        "                'token_type_ids': tf.constant(attention_mask), 'lm_label_ids': tf.constant(lm_label_ids)}\r\n",
        "\r\n",
        "        return outputs\r\n",
        "\r\n",
        "    def to_tf_dataset(self, dataset): \r\n",
        "        \"\"\"\r\n",
        "        Turns dataset into a TF compatible dataset\r\n",
        "        \"\"\"\r\n",
        "        columns = ['input_ids', 'attention_mask', 'token_type_ids', 'lm_label_ids']\r\n",
        "        dataset.set_format(type='tensorflow', columns=columns)\r\n",
        "\r\n",
        "        return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32, \r\n",
        "                      'token_type_ids':tf.int32, 'lm_label_ids':tf.int32}\r\n",
        "\r\n",
        "        return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]), \r\n",
        "                        'token_type_ids': tf.TensorShape([None]), 'lm_label_ids':tf.TensorShape([None])}\r\n",
        "\r\n",
        "        ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\r\n",
        "        return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lzKWR3FMJVQ"
      },
      "source": [
        "##### Performer Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZollJirsMRr-"
      },
      "source": [
        "# Config + Module for Performer Attention\r\n",
        "\r\n",
        "# Resources:\r\n",
        "# https://github.com/xl402/performer/blob/master/performer/networks/linear_attention.py\r\n",
        "# https://github.com/huggingface/transformers/blob/1c4236d8ef884f9f4cb1bf807ef622199c56df80/src/transformers/modeling_tf_performer_attention.py\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "import logging\r\n",
        "import math\r\n",
        "import random\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from typing import Callable, Sequence, Optional, Union\r\n",
        "\r\n",
        "from dataclasses import dataclass\r\n",
        "from enum import Enum\r\n",
        "\r\n",
        "from transformers.modeling_tf_utils import shape_list\r\n",
        "\r\n",
        "PerformerKernel = Enum('PerformerKernel', ['cosh', 'exp', 'elu', 'relu'])\r\n",
        "OrthogonalFeatureAlgorithm = Enum('OrthogonalFeatureAlgorithm', ['auto', 'kacs', 'qr'])\r\n",
        "\r\n",
        "\r\n",
        "@dataclass\r\n",
        "class PerformerAttentionConfig:\r\n",
        "    r\"\"\"\r\n",
        "    This is the configuration class to store the configuration of a :class:`~transformers.PerformerAttention` module.\r\n",
        "    It is used to define the behavior of a Performer/FAVOR+ attention module when it is initialized.\r\n",
        "    \r\n",
        "    Args:\r\n",
        "        attention_dropout (:obj:`float`, `optional`, defaults to 0.1):\r\n",
        "            The dropout ratio for the attention probabilities.\r\n",
        "        causal (:obj:`bool`, `optional`, defaults to False):\r\n",
        "            Whether to apply causal attention, where positions are prevented from attending to positions to ahead\r\n",
        "            of themselves in the sequence, using the prefix-sum method.\r\n",
        "        kernel_type (:obj:`Enum(PerformerKernel)`, `optional`, defaults to :obj:`'exp'`):\r\n",
        "            The type of kernel function to use for comparing the queries and keys. Possible options are :obj:`'exp'`,\r\n",
        "            :obj:`'cosh'`, and :obj:`'relu'`. The :obj:`'cosh'` option approximates softmax attention with a smaller\r\n",
        "            variance than :obj:`'exp'`, but at the cost of using twice as many random features. :obj:`'relu'` may result\r\n",
        "            in better performance than :obj:`'exp'` and :obj:`'cosh'` in certain circumstances, but it is not an\r\n",
        "            unbiased estimator of softmax attention and thus should not be used with pretrained models that were\r\n",
        "            pretrained with softmax attention.\r\n",
        "        kernel_epsilon (:obj:`float`, `optional`, defaults to 1e-4):\r\n",
        "            Stabilizer term added to the output of the kernel function to avoid dividing by very small numbers.\r\n",
        "        normalize_output (:obj:`bool`, `optional`, defaults to True):\r\n",
        "            Whether to ensure that the output vectors are convex combinations of the input vectors; that is, that the\r\n",
        "            rows of the implicit attention map sum to 1.\r\n",
        "        normalization_stabilizer (:obj:`float`, `optional`, defaults to 1e-6):\r\n",
        "            Stabilizer term used when normalizing the output to avoid dividing by very small numbers.\r\n",
        "        num_random_features (:obj:`int`, `optional`, defaults to None):\r\n",
        "            The dimensionality of the random feature vectors to use. When None, the dimensionality is set to\r\n",
        "            D * log(D), where D is the dimensionality of each attention head.\r\n",
        "        orthogonal_feature_algorithm (:obj:`Enum(OrthogonalFeatureAlgorithm)`, defaults to 'auto'):\r\n",
        "            The algorithm to use for generating random orthogonal features. Possible values are 'kacs', which uses a\r\n",
        "            Kac's random walk Markov chain; 'qr', which performs QR decomposition on a random Gaussian matrix at each\r\n",
        "            redraw; and 'auto', which is equivalent to 'kacs' on PyTorch and 'qr' on TensorFlow, since the Kac's random\r\n",
        "            walk algorithm is not supported on TensorFlow. Kac's is generally faster than QR, but successive samples\r\n",
        "            are correlated with each other.\r\n",
        "        use_recurrent_decoding (:obj:`bool`, `optional`, defaults to False):\r\n",
        "            Whether to use recurrent autoregressive decoding, as described in the 'Transformers are RNNs' paper. If\r\n",
        "            True, the PerformerAttention object will expect input tensors with a sequence length dimension of exactly 1,\r\n",
        "            and will output tensors with sequence length of 1. It will retain a recurrent hidden state between forward\r\n",
        "            passes that can be reset with the reset_recurrent_state() method.\r\n",
        "        use_thick_features (:obj:`bool`, `optional`, defaults to False):\r\n",
        "            Whether to generate a random feature tensor that has a batch dimension.\r\n",
        "        use_orthogonal_features (:obj:`bool`, `optional`, defaults to True):\r\n",
        "            Whether to use strictly orthogonal random features, as opposed to features drawn from a standard Gaussian\r\n",
        "            distribution. Orthogonal features result in outputs that more closely approximate softmax attention, but at\r\n",
        "            the cost of doing QR decomposition on the CPU every time the features are redrawn. Best combined with a\r\n",
        "            reasonably large value of :obj:`feature_redraw_interval` (1-5k).\r\n",
        "        use_linear_layers (:obj:`bool`, `optional`, defaults to True):\r\n",
        "            Whether to transform the Q, K, and V inputs with a Linear layer before applying attention. Setting this\r\n",
        "            to False may be useful if you want to use PerformerAttention as one component of a more complex\r\n",
        "            attention mechanism.\r\n",
        "        regularize_feature_norms (:obj:`bool`, `optional`, defaults to False):\r\n",
        "            Whether to ensure that the random feature vectors have a norm of sqrt(`d`), where `d` is the dimensionality\r\n",
        "            of each attention head.\r\n",
        "        feature_redraw_interval (:obj:`int`, `optional`, defaults to 100):\r\n",
        "            The number of forward passes after which the random feature matrix should be redrawn. If None, then the\r\n",
        "            feature matrix is never redrawn. When combined with :obj:`redraw_stochastically`, this parameter determines\r\n",
        "            the expected value of the redraw interval, rather than the interval itself.\r\n",
        "        redraw_stochastically (:obj:`bool`, `optional`, defaults to False):\r\n",
        "            If true, PerformerAttention will redraw its random features each forward pass with a probability equal to\r\n",
        "            (1 / :obj:`feature_redraw_interval`), instead of deterministically redrawing once every N passes. This could\r\n",
        "            be desirable in large models to ensure that the attention layers don't all redraw their features at the same\r\n",
        "            time.\r\n",
        "        redraw_verbose (:obj:`bool`, `optional`, defaults to False):\r\n",
        "            Whether to log a message when random features are redrawn during training.\r\n",
        "        dim (:obj:`int`, `optional`):\r\n",
        "            Dimensionality of the queries, keys, and values.\r\n",
        "        num_heads (:obj:`int`, `optional`):\r\n",
        "            Number of attention heads.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    attention_dropout: float = 0.1\r\n",
        "    kernel_type: Union[str, Callable, PerformerKernel] = PerformerKernel.exp\r\n",
        "\r\n",
        "    causal: bool = False\r\n",
        "    use_recurrent_decoding: bool = False\r\n",
        "\r\n",
        "    kernel_epsilon: float = 1e-4\r\n",
        "    normalize_output: bool = True\r\n",
        "    normalization_stabilizer: float = 1e-6\r\n",
        "\r\n",
        "    # The linear_layer_names parameter is needed to allow the PerformerAttention object to imitate the naming\r\n",
        "    # convention of arbitrary attention modules, and therefore load weights from pretrained models. It can either have\r\n",
        "    # 3 or 4 elements; if it has 3, then no output linear layer is used.\r\n",
        "    use_linear_layers: bool = True\r\n",
        "    linear_layer_names: Sequence[str] = ('q_linear', 'k_linear', 'v_linear', 'out_linear')\r\n",
        "\r\n",
        "    num_random_features: Optional[int] = None\r\n",
        "    use_thick_features: bool = False\r\n",
        "    regularize_feature_norms: bool = True\r\n",
        "\r\n",
        "    use_orthogonal_features: bool = True\r\n",
        "    orthogonal_feature_algorithm: Union[str, OrthogonalFeatureAlgorithm] = OrthogonalFeatureAlgorithm.auto\r\n",
        "\r\n",
        "    feature_redraw_interval: Optional[int] = 100\r\n",
        "    redraw_stochastically: bool = False\r\n",
        "    redraw_verbose: bool = False\r\n",
        "\r\n",
        "    # Optional here so the user doesn't have to set redundant parameters, but must be set by model before config is\r\n",
        "    # passed to PerformerAttention.__init__()\r\n",
        "    d_model: Optional[int] = None\r\n",
        "    num_heads: Optional[int] = None\r\n",
        "\r\n",
        "    # Make enums JSON serializable\r\n",
        "    def to_dict(self):\r\n",
        "        return {k: v.name if isinstance(v, Enum) else v for k, v in self.__dict__.items()}\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "KERNEL_CALLABLES = {\r\n",
        "    PerformerKernel.cosh: lambda x, h: tf.concat((tf.exp(h + x), tf.exp(h - x)), axis=-1),\r\n",
        "    PerformerKernel.exp: lambda x, h: tf.exp(h + x),  # Default\r\n",
        "    PerformerKernel.elu: lambda x: tf.nn.elu(x) + 1,\r\n",
        "    PerformerKernel.relu: tf.nn.relu\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "def resolve_enum(enum_class, value):\r\n",
        "    return enum_class[value] if isinstance(value, str) else value\r\n",
        "\r\n",
        "\r\n",
        "class TFPerformerAttention(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config: Optional[Union[dict, PerformerAttentionConfig]] = None, **kwargs):\r\n",
        "        super().__init__(name=kwargs.pop('name', None), dtype=kwargs.pop('dtype', None))\r\n",
        "\r\n",
        "        if isinstance(config, dict):\r\n",
        "            config = PerformerAttentionConfig(**config)\r\n",
        "        else:\r\n",
        "            config = config or PerformerAttentionConfig()\r\n",
        "\r\n",
        "        # kwargs take precedence over the default values that might be stored in the config object\r\n",
        "        for k, v in kwargs.items():\r\n",
        "            assert hasattr(config, k), f\"'{k}' is an invalid config parameter\"\r\n",
        "            setattr(config, k, v)\r\n",
        "\r\n",
        "        self.__dict__.update(config.__dict__)\r\n",
        "\r\n",
        "        assert self.num_heads and self.d_model, \"Num_heads and d_model must be non-None\"\r\n",
        "        assert self.d_model % self.num_heads == 0, \"Num_heads must divide d_model evenly\"\r\n",
        "        assert self.d_model > self.num_heads, \"Number of dimensions per head must be greater than 1\"\r\n",
        "        \r\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=self.attention_dropout)\r\n",
        "        self.calls_since_last_redraw = 0\r\n",
        "\r\n",
        "        self.orthogonal_feature_algorithm = resolve_enum(OrthogonalFeatureAlgorithm, self.orthogonal_feature_algorithm)\r\n",
        "        assert self.orthogonal_feature_algorithm != OrthogonalFeatureAlgorithm.kacs,\\\r\n",
        "            \"Kac's random walk is not supported in TensorFlow\"\r\n",
        "\r\n",
        "        # Create the feature matrix up front if we don't need to know what the batch dimension is;\r\n",
        "        # otherwise, lazily create it on the first forward pass\r\n",
        "        self.random_features = None\r\n",
        "        if not self.use_thick_features:\r\n",
        "            self._generate_feature_matrix(batch_size=1)\r\n",
        "\r\n",
        "        # Recurrent state\r\n",
        "        if self.use_recurrent_decoding:\r\n",
        "            self.s = None\r\n",
        "            self.z = None\r\n",
        "\r\n",
        "        if isinstance(self.kernel_type, Callable):\r\n",
        "            self.kernel_fn = self.kernel_type   # Allow for custom kernel types\r\n",
        "        else:\r\n",
        "            self.kernel_type = resolve_enum(PerformerKernel, self.kernel_type)\r\n",
        "            self.kernel_fn = KERNEL_CALLABLES[self.kernel_type]\r\n",
        "\r\n",
        "        if self.use_linear_layers:\r\n",
        "            for name in self.linear_layer_names:\r\n",
        "                setattr(self, name, tf.keras.layers.Dense(units=self.d_model))\r\n",
        "\r\n",
        "    def prune_heads(self, heads):\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "    def redraw_features_now(self):\r\n",
        "        \"\"\"\r\n",
        "        Immediately redraws the random features.\r\n",
        "        \"\"\"\r\n",
        "        batch = self.random_features.shape[0]\r\n",
        "        self._generate_feature_matrix(batch)\r\n",
        "\r\n",
        "        if self.redraw_verbose:\r\n",
        "            logging.getLogger().info(\"TFPerformerAttention: Just redrew random features.\")\r\n",
        "\r\n",
        "        self.calls_since_last_redraw = 0\r\n",
        "\r\n",
        "    def reset_recurrent_state(self):\r\n",
        "        \"\"\"\r\n",
        "        Resets the recurrent state kept by the model when use_recurrent_decoding == True\r\n",
        "        \"\"\"\r\n",
        "        self.s = None\r\n",
        "        self.z = None\r\n",
        "\r\n",
        "    def call(self, query, key, value, mask=None, head_mask=None, output_attentions=False):\r\n",
        "        \"\"\"\r\n",
        "        Parameters:\r\n",
        "            query: torch.tensor(bs, seq_length, dim)\r\n",
        "            key: torch.tensor(bs, seq_length, dim)\r\n",
        "            value: torch.tensor(bs, seq_length, dim)\r\n",
        "            mask: torch.tensor(bs, seq_length)\r\n",
        "        Returns:\r\n",
        "            weights: tf.tensor(bs, num_heads, seq_length, seq_length) Attention weights context: tf.tensor(bs,\r\n",
        "            seq_length, dim) Contextualized layer. Optional: only if `output_attentions=True`\r\n",
        "        \"\"\"\r\n",
        "        bs, q_length, dim = query.shape\r\n",
        "        dim_per_head = self.d_model // self.num_heads\r\n",
        "\r\n",
        "        def shape(x):\r\n",
        "            \"\"\" separate heads \"\"\"\r\n",
        "            # > Use shape_list instead of .shape\r\n",
        "            new_shape = tf.concat((shape_list(x)[:-1], tf.constant([self.num_heads, dim_per_head])), axis=0)\r\n",
        "            return tf.transpose(tf.reshape(x, new_shape), perm=[0, 2, 1, 3])\r\n",
        "\r\n",
        "        if self.use_linear_layers:\r\n",
        "            query, key, value = (getattr(self, name)(x) for name, x in\r\n",
        "                                 zip(self.linear_layer_names, (query, key, value)))\r\n",
        "        \r\n",
        "        # (bs, num_heads, q_length, dim_per_head)\r\n",
        "        query, key, value = (shape(x) for x in (query, key, value))\r\n",
        "\r\n",
        "        assert not output_attentions, \"Can't output attention maps when using Performer attention.\"\r\n",
        "        if self.use_recurrent_decoding:\r\n",
        "            assert q_length == 1, \"When use_recurrent_decoding == True, we only input and output one token at a time.\"\r\n",
        "        \r\n",
        "        self._redraw_features_if_needed(bs)\r\n",
        "        \r\n",
        "        # Get the transformed values of Q and K\r\n",
        "        q_prime, k_prime = self.get_projected_queries_and_keys(query, key)\r\n",
        "        return self.compute_attention_with_projected_queries_and_keys(q_prime, k_prime, value, mask, head_mask)\r\n",
        "\r\n",
        "    def get_projected_queries_and_keys(self, q, k):\r\n",
        "        \"\"\"\r\n",
        "        Turns Q into Q' and K into K' by multiplying them by the random feature tensor.\r\n",
        "        Parameters:\r\n",
        "            q: torch.tensor(bs, seq_length, dim)\r\n",
        "            k: torch.tensor(bs, seq_length, dim)\r\n",
        "        Returns:\r\n",
        "            q_prime: torch.tensor(bs, seq_length, num_features)\r\n",
        "            k_prime: torch.tensor(bs, seq_length, num_features)\r\n",
        "        \"\"\"\r\n",
        "        # Instead of dividing the product QK^T by sqrt(d), we divide Q and K by the 4th root of d.\r\n",
        "        q = q / (self.d_model ** 0.25)\r\n",
        "        k = k / (self.d_model ** 0.25)\r\n",
        "        \r\n",
        "        projected_q = q @ self.random_features\r\n",
        "        projected_k = k @ self.random_features\r\n",
        "        \r\n",
        "        # Special logic for kernels that attempt to approximate softmax\r\n",
        "        if self.kernel_type in (PerformerKernel.cosh, PerformerKernel.exp):\r\n",
        "            # The h(x) function is defined in Lemma 1 in Choromanski et al. pg. 4 as exp(-||x||**2 / 2). For numerical\r\n",
        "            # stability we leverage the fact that exp(x)*exp(y) = exp(x + y) here and delay computing the exp().\r\n",
        "            h_of_q = -tf.math.reduce_sum(q ** 2, axis=-1, keepdims=True) / 2\r\n",
        "            h_of_k = -tf.math.reduce_sum(k ** 2, axis=-1, keepdims=True) / 2\r\n",
        "            \r\n",
        "            # Compute the numerical stabilizer that we subtract from the input to exp(). For some reason the original\r\n",
        "            # Jax implementation uses different types of stabilizers for queries vs. keys, and we follow that here.\r\n",
        "            q_stabilizer = tf.math.reduce_max(h_of_q, axis=-1, keepdims=True)\r\n",
        "            \r\n",
        "            # This is just a scalar\r\n",
        "            k_stabilizer = tf.math.reduce_max(h_of_k)\r\n",
        "            \r\n",
        "            q_kernel_output = self.kernel_fn(projected_q - q_stabilizer, h_of_q)\r\n",
        "            k_kernel_output = self.kernel_fn(projected_k - k_stabilizer, h_of_k)\r\n",
        "            \r\n",
        "            # By multiplying by 1/sqrt(m), we ensure the final matrix product will contain a factor of 1/m. This means\r\n",
        "            # each row of Q'K'^T can be interpreted as an average over the exp(omega^T * q) * exp(omega^T * k) terms.\r\n",
        "            normalizing_constant = (q_kernel_output.shape[-1] ** -0.5)\r\n",
        "            \r\n",
        "            q_prime = normalizing_constant * (q_kernel_output + self.kernel_epsilon)\r\n",
        "            k_prime = normalizing_constant * (k_kernel_output + self.kernel_epsilon)\r\n",
        "            return q_prime, k_prime\r\n",
        "        \r\n",
        "        # Generalized attention (ReLU, ELU...)\r\n",
        "        else:\r\n",
        "            return tuple(self.kernel_fn(x) + self.kernel_epsilon for x in (projected_q, projected_k))\r\n",
        "\r\n",
        "    def compute_attention_with_projected_queries_and_keys(self, q_prime, k_prime, v, mask=None, head_mask=None):\r\n",
        "        \"\"\"\r\n",
        "        Computes the attention output given Q' and K' from the above get_projected_queries_and_keys method.\r\n",
        "        Parameters:\r\n",
        "            q_prime: tf.tensor(bs, seq_length, num_features)\r\n",
        "            k_prime: tf.tensor(bs, seq_length, num_features)\r\n",
        "            v: tf.tensor(bs, seq_length, dim)\r\n",
        "            mask: tf.tensor(bs, seq_length)\r\n",
        "        Returns:\r\n",
        "            V': tf.tensor(bs, seq_length, dim)\r\n",
        "        \"\"\"\r\n",
        "        # Apply the padding mask to K'. Also applying it to Q' would be redundant.\r\n",
        "        if mask is not None:\r\n",
        "            # If extended attention mask we need to reshape it to (bs, seq_len)\r\n",
        "            # Note: k_prime actual shape is (bs, ?, seq_length, num_features)\r\n",
        "            mask = tf.reshape(mask, shape=(shape_list(k_prime)[0], shape_list(k_prime)[2]))\r\n",
        "\r\n",
        "            k_prime *= tf.expand_dims(tf.expand_dims(mask, 1), -1)\r\n",
        "\r\n",
        "        k_prime_t = tf.linalg.matrix_transpose(k_prime)\r\n",
        "        output = self._numerator_for_projected_queries_and_keys(q_prime, k_prime_t, v)\r\n",
        "\r\n",
        "        if self.normalize_output:\r\n",
        "            output /= self._denominator_for_projected_queries_and_keys(q_prime, k_prime_t)\r\n",
        "\r\n",
        "        return self._finalize_attention_output(output, head_mask)\r\n",
        "\r\n",
        "    def _numerator_for_projected_queries_and_keys(self, q_prime, k_prime_t, v):\r\n",
        "        # Noncausal\r\n",
        "        if not self.causal:\r\n",
        "            return q_prime @ (k_prime_t @ v)\r\n",
        "\r\n",
        "        # Causal, during training\r\n",
        "        if not self.use_recurrent_decoding:\r\n",
        "            return _headwise_causal_numerator(q_prime, k_prime_t, v)\r\n",
        "\r\n",
        "        # Causal, at inference time\r\n",
        "        s_delta = k_prime_t @ v\r\n",
        "        self.s = s_delta if self.s is None else self.s + s_delta\r\n",
        "\r\n",
        "        return q_prime @ self.s\r\n",
        "\r\n",
        "    def _denominator_for_projected_queries_and_keys(self, q_prime, k_prime_t):\r\n",
        "        # Noncausal\r\n",
        "        if not self.causal:\r\n",
        "            denom = q_prime @ tf.math.reduce_sum(k_prime_t, axis=-1, keepdims=True)  # Sum over positions\r\n",
        "\r\n",
        "        # Causal, during training\r\n",
        "        elif not self.use_recurrent_decoding:\r\n",
        "            prefix_sums = tf.cumsum(k_prime_t, axis=-1)               # Cumsum over positions\r\n",
        "            denom = tf.einsum(\"bhlm,bhml->bhl\", q_prime, prefix_sums)\r\n",
        "            denom = tf.expand_dims(denom, axis=-1)\r\n",
        "\r\n",
        "        # Causal, at inference time\r\n",
        "        else:\r\n",
        "            self.z = k_prime_t if self.z is None else self.z + k_prime_t    # Incrementally sum over positions\r\n",
        "            denom = q_prime @ self.z\r\n",
        "\r\n",
        "        # Avoid dividing by very small numbers\r\n",
        "        extreme_vals = tf.cast(tf.math.abs(denom) <= self.normalization_stabilizer, denom.dtype)\r\n",
        "        return denom + 2 * self.normalization_stabilizer * extreme_vals\r\n",
        "    \r\n",
        "    def _finalize_attention_output(self, context, head_mask=None, att_map_to_output=None):\r\n",
        "        # Mask heads if we want to\r\n",
        "        if head_mask is not None:\r\n",
        "            context = context * head_mask\r\n",
        "\r\n",
        "        context = tf.transpose(context, perm=[0, 2, 1, 3])  # [...seq_len, num_heads, dim_per_head]\r\n",
        "\r\n",
        "        # Skip the reshaping as we expect [...seq_len, num_heads, dim_per_head]-like shape\r\n",
        "        # Applying the linear layer is the same w/ / w/o the reshape\r\n",
        "        #new_last_dim = shape_list(context)[-2] * shape_list(context)[-1]\r\n",
        "        #context = tf.reshape(context, shape_list(context)[:-2] + [new_last_dim])  # (bs, q_length, dim)\r\n",
        "\r\n",
        "        if self.use_linear_layers and len(self.linear_layer_names) > 3:\r\n",
        "            context = getattr(self, self.linear_layer_names[3])(context)  # (bs, q_length, dim)\r\n",
        "\r\n",
        "        if att_map_to_output:\r\n",
        "            return context, att_map_to_output\r\n",
        "        else:\r\n",
        "            return context,\r\n",
        "\r\n",
        "    def _generate_feature_matrix(self, batch_size):\r\n",
        "        dim_per_head = self.d_model // self.num_heads\r\n",
        "        num_rows = self.num_random_features or round(dim_per_head * math.log(dim_per_head))\r\n",
        "        batch = batch_size if self.use_thick_features else 1\r\n",
        "        \r\n",
        "        if not self.use_orthogonal_features:\r\n",
        "            final_tensor = tf.random.normal((batch, num_rows, dim_per_head))\r\n",
        "        else:\r\n",
        "            total_num_blocks = int(math.ceil(num_rows / dim_per_head))\r\n",
        "            extra_rows = total_num_blocks * dim_per_head - num_rows\r\n",
        "\r\n",
        "            blocks = [_get_orthogonal_block(batch, dim_per_head) for _ in range(total_num_blocks)]\r\n",
        "            if extra_rows > 0:\r\n",
        "                blocks[-1] = blocks[-1][:, extra_rows:]\r\n",
        "\r\n",
        "            final_tensor = tf.concat(blocks, axis=1)\r\n",
        "        \r\n",
        "            # This option yields SMREG\r\n",
        "            if self.regularize_feature_norms:\r\n",
        "                final_tensor *= dim_per_head ** 0.5\r\n",
        "            else:\r\n",
        "                # Hack to make the matrix columns have the norm we would expect them to have if they were sampled\r\n",
        "                # straight from a Gaussian, instead of being all norm 1 since they went through QR decomposition\r\n",
        "                multiplier = tf.norm(tf.random.normal((batch, num_rows, dim_per_head)), axis=-1)\r\n",
        "                final_tensor = tf.linalg.diag(multiplier) @ final_tensor\r\n",
        "\r\n",
        "        final_tensor = tf.expand_dims(final_tensor, axis=1)     # Add an attention head dimension\r\n",
        "        final_tensor = tf.linalg.matrix_transpose(final_tensor)\r\n",
        "        self.random_features = final_tensor\r\n",
        "    \r\n",
        "    def _redraw_features_if_needed(self, batch):\r\n",
        "        # We haven't created the projection matrix yet, let's create it\r\n",
        "        if self.random_features is None:\r\n",
        "            self._generate_feature_matrix(batch)\r\n",
        "        \r\n",
        "        elif self.feature_redraw_interval is not None:\r\n",
        "            if self.redraw_stochastically:\r\n",
        "                # random.random() returns a float between 0.0 and 1.0, so this expression\r\n",
        "                # evaluates to True with probability 1. / self.feature_redraw_interval\r\n",
        "                if random.random() < 1. / self.feature_redraw_interval:\r\n",
        "                    self.redraw_features_now()\r\n",
        "            \r\n",
        "            # It's time to redraw the projection matrix\r\n",
        "            elif self.calls_since_last_redraw >= self.feature_redraw_interval:\r\n",
        "                self.redraw_features_now()\r\n",
        "        \r\n",
        "            # Keep track of how many forward passes we do before we redraw again\r\n",
        "            else:\r\n",
        "                self.calls_since_last_redraw += 1\r\n",
        "\r\n",
        "\r\n",
        "def _get_orthogonal_block(batch, size):\r\n",
        "    with tf.device('/CPU:0'):\r\n",
        "        unstructured_block = tf.random.normal((batch, size, size))\r\n",
        "        orthog, r = tf.linalg.qr(unstructured_block)\r\n",
        "\r\n",
        "    return tf.linalg.matrix_transpose(orthog)\r\n",
        "\r\n",
        "\r\n",
        "def _headwise_causal_numerator(q_prime, k_prime_t, v):\r\n",
        "    results = []\r\n",
        "\r\n",
        "    # Iterate over the attention heads to avoid allocating a very large tensor\r\n",
        "    for head in range(q_prime.shape[1]):\r\n",
        "        # Outer products- a sorta biggish tensor\r\n",
        "        outer_prods = tf.einsum('bml,bld->blmd', k_prime_t[:, head], v[:, head])\r\n",
        "        prefix_sums = tf.cumsum(outer_prods, axis=1)\r\n",
        "\r\n",
        "        query_prods = tf.einsum('blmd,blm->bld', prefix_sums, q_prime[:, head])\r\n",
        "        results.append(tf.expand_dims(query_prods, axis=1))\r\n",
        "\r\n",
        "    return tf.concat(results, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccXBubyiL8Ud"
      },
      "source": [
        "##### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P1C9xdDL-Hg"
      },
      "source": [
        "import warnings\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from transformers.activations_tf import get_tf_activation\r\n",
        "from transformers.file_utils import (\r\n",
        "    MULTIPLE_CHOICE_DUMMY_INPUTS,\r\n",
        "    add_code_sample_docstrings,\r\n",
        "    add_start_docstrings,\r\n",
        "    add_start_docstrings_to_model_forward,\r\n",
        ")\r\n",
        "from transformers.modeling_tf_outputs import (\r\n",
        "    TFBaseModelOutput,\r\n",
        "    TFBaseModelOutputWithPooling,\r\n",
        "    TFMaskedLMOutput,\r\n",
        "    TFMultipleChoiceModelOutput,\r\n",
        "    TFQuestionAnsweringModelOutput,\r\n",
        "    TFSequenceClassifierOutput,\r\n",
        "    TFTokenClassifierOutput,\r\n",
        ")\r\n",
        "from transformers.modeling_tf_utils import (\r\n",
        "    TFMaskedLanguageModelingLoss,\r\n",
        "    TFMultipleChoiceLoss,\r\n",
        "    TFPreTrainedModel,\r\n",
        "    TFQuestionAnsweringLoss,\r\n",
        "    TFSequenceClassificationLoss,\r\n",
        "    TFTokenClassificationLoss,\r\n",
        "    get_initializer,\r\n",
        "    input_processing,\r\n",
        "    keras_serializable,\r\n",
        "    shape_list,\r\n",
        ")\r\n",
        "from transformers.utils import logging\r\n",
        "from transformers import RobertaConfig\r\n",
        "\r\n",
        "\r\n",
        "logger = logging.get_logger(__name__)\r\n",
        "\r\n",
        "_CONFIG_FOR_DOC = \"RobertaConfig\"\r\n",
        "_TOKENIZER_FOR_DOC = \"RobertaTokenizer\"\r\n",
        "\r\n",
        "TF_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST = [\r\n",
        "    \"roberta-base\",\r\n",
        "    \"roberta-large\",\r\n",
        "    \"roberta-large-mnli\",\r\n",
        "    \"distilroberta-base\",\r\n",
        "    # See all RoBERTa models at https://huggingface.co/models?filter=roberta\r\n",
        "]\r\n",
        "\r\n",
        "\r\n",
        "# Copied from transformers.models.bert.modeling_tf_bert.TFBertWordEmbeddings\r\n",
        "class TFRobertaWordEmbeddings(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, vocab_size: int, hidden_size: int, initializer_range: float, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.vocab_size = vocab_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.initializer_range = initializer_range\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        self.weight = self.add_weight(\r\n",
        "            name=\"weight\",\r\n",
        "            shape=[self.vocab_size, self.hidden_size],\r\n",
        "            initializer=get_initializer(initializer_range=self.initializer_range),\r\n",
        "        )\r\n",
        "\r\n",
        "        super().build(input_shape=input_shape)\r\n",
        "\r\n",
        "    def get_config(self):\r\n",
        "        config = {\r\n",
        "            \"vocab_size\": self.vocab_size,\r\n",
        "            \"hidden_size\": self.hidden_size,\r\n",
        "            \"initializer_range\": self.initializer_range,\r\n",
        "        }\r\n",
        "        base_config = super().get_config()\r\n",
        "\r\n",
        "        return dict(list(base_config.items()) + list(config.items()))\r\n",
        "\r\n",
        "    def call(self, input_ids):\r\n",
        "        flat_input_ids = tf.reshape(tensor=input_ids, shape=[-1])\r\n",
        "        embeddings = tf.gather(params=self.weight, indices=flat_input_ids)\r\n",
        "        embeddings = tf.reshape(\r\n",
        "            tensor=embeddings, shape=tf.concat(values=[shape_list(tensor=input_ids), [self.hidden_size]], axis=0)\r\n",
        "        )\r\n",
        "\r\n",
        "        embeddings.set_shape(shape=input_ids.shape.as_list() + [self.hidden_size])\r\n",
        "\r\n",
        "        return embeddings\r\n",
        "\r\n",
        "\r\n",
        "# Copied from transformers.models.bert.modeling_tf_bert.TFBertTokenTypeEmbeddings\r\n",
        "class TFRobertaTokenTypeEmbeddings(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, type_vocab_size: int, hidden_size: int, initializer_range: float, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.type_vocab_size = type_vocab_size\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.initializer_range = initializer_range\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        self.token_type_embeddings = self.add_weight(\r\n",
        "            name=\"embeddings\",\r\n",
        "            shape=[self.type_vocab_size, self.hidden_size],\r\n",
        "            initializer=get_initializer(initializer_range=self.initializer_range),\r\n",
        "        )\r\n",
        "\r\n",
        "        super().build(input_shape=input_shape)\r\n",
        "\r\n",
        "    def get_config(self):\r\n",
        "        config = {\r\n",
        "            \"type_vocab_size\": self.type_vocab_size,\r\n",
        "            \"hidden_size\": self.hidden_size,\r\n",
        "            \"initializer_range\": self.initializer_range,\r\n",
        "        }\r\n",
        "        base_config = super().get_config()\r\n",
        "\r\n",
        "        return dict(list(base_config.items()) + list(config.items()))\r\n",
        "\r\n",
        "    def call(self, token_type_ids):\r\n",
        "        flat_token_type_ids = tf.reshape(tensor=token_type_ids, shape=[-1])\r\n",
        "        one_hot_data = tf.one_hot(indices=flat_token_type_ids, depth=self.type_vocab_size, dtype=self._compute_dtype)\r\n",
        "        embeddings = tf.matmul(a=one_hot_data, b=self.token_type_embeddings)\r\n",
        "        embeddings = tf.reshape(\r\n",
        "            tensor=embeddings, shape=tf.concat(values=[shape_list(tensor=token_type_ids), [self.hidden_size]], axis=0)\r\n",
        "        )\r\n",
        "\r\n",
        "        embeddings.set_shape(shape=token_type_ids.shape.as_list() + [self.hidden_size])\r\n",
        "\r\n",
        "        return embeddings\r\n",
        "\r\n",
        "\r\n",
        "# Copied from transformers.models.longformer.modeling_tf_longformer.TFLongformerPositionEmbeddings\r\n",
        "class TFRobertaPositionEmbeddings(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, max_position_embeddings: int, hidden_size: int, initializer_range: float, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.max_position_embeddings = max_position_embeddings\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.initializer_range = initializer_range\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        self.position_embeddings = self.add_weight(\r\n",
        "            name=\"embeddings\",\r\n",
        "            shape=[self.max_position_embeddings, self.hidden_size],\r\n",
        "            initializer=get_initializer(initializer_range=self.initializer_range),\r\n",
        "        )\r\n",
        "\r\n",
        "        super().build(input_shape)\r\n",
        "\r\n",
        "    def get_config(self):\r\n",
        "        config = {\r\n",
        "            \"max_position_embeddings\": self.max_position_embeddings,\r\n",
        "            \"hidden_size\": self.hidden_size,\r\n",
        "            \"initializer_range\": self.initializer_range,\r\n",
        "        }\r\n",
        "        base_config = super().get_config()\r\n",
        "\r\n",
        "        return dict(list(base_config.items()) + list(config.items()))\r\n",
        "\r\n",
        "    def call(self, position_ids):\r\n",
        "        flat_position_ids = tf.reshape(tensor=position_ids, shape=[-1])\r\n",
        "        embeddings = tf.gather(params=self.position_embeddings, indices=flat_position_ids)\r\n",
        "        embeddings = tf.reshape(\r\n",
        "            tensor=embeddings, shape=tf.concat(values=[shape_list(tensor=position_ids), [self.hidden_size]], axis=0)\r\n",
        "        )\r\n",
        "\r\n",
        "        embeddings.set_shape(shape=position_ids.shape.as_list() + [self.hidden_size])\r\n",
        "\r\n",
        "        return embeddings\r\n",
        "\r\n",
        "\r\n",
        "class TFRobertaEmbeddings(tf.keras.layers.Layer):\r\n",
        "    \"\"\"\r\n",
        "    Same as BertEmbeddings with a tiny tweak for positional embeddings indexing.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.padding_idx = 1\r\n",
        "        self.word_embeddings = TFRobertaWordEmbeddings(\r\n",
        "            vocab_size=config.vocab_size,\r\n",
        "            hidden_size=config.hidden_size,\r\n",
        "            initializer_range=config.initializer_range,\r\n",
        "            name=\"word_embeddings\",\r\n",
        "        )\r\n",
        "        self.position_embeddings = TFRobertaPositionEmbeddings(\r\n",
        "            max_position_embeddings=config.max_position_embeddings,\r\n",
        "            hidden_size=config.hidden_size,\r\n",
        "            initializer_range=config.initializer_range,\r\n",
        "            name=\"position_embeddings\",\r\n",
        "        )\r\n",
        "        self.token_type_embeddings = TFRobertaTokenTypeEmbeddings(\r\n",
        "            type_vocab_size=config.type_vocab_size,\r\n",
        "            hidden_size=config.hidden_size,\r\n",
        "            initializer_range=config.initializer_range,\r\n",
        "            name=\"token_type_embeddings\",\r\n",
        "        )\r\n",
        "        self.embeddings_sum = tf.keras.layers.Add()\r\n",
        "        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\r\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\r\n",
        "\r\n",
        "    def create_position_ids_from_input_ids(self, input_ids):\r\n",
        "        \"\"\"\r\n",
        "        Replace non-padding symbols with their position numbers. Position numbers begin at padding_idx+1. Padding\r\n",
        "        symbols are ignored. This is modified from fairseq's `utils.make_positions`.\r\n",
        "        Args:\r\n",
        "            input_ids: tf.Tensor\r\n",
        "        Returns: tf.Tensor\r\n",
        "        \"\"\"\r\n",
        "        input_ids_shape = shape_list(tensor=input_ids)\r\n",
        "\r\n",
        "        # multiple choice has 3 dimensions\r\n",
        "        if len(input_ids_shape) == 3:\r\n",
        "            input_ids = tf.reshape(\r\n",
        "                tensor=input_ids, shape=(input_ids_shape[0] * input_ids_shape[1], input_ids_shape[2])\r\n",
        "            )\r\n",
        "\r\n",
        "        mask = tf.cast(x=tf.math.not_equal(x=input_ids, y=self.padding_idx), dtype=input_ids.dtype)\r\n",
        "        incremental_indices = tf.math.cumsum(x=mask, axis=1) * mask\r\n",
        "\r\n",
        "        return incremental_indices + self.padding_idx\r\n",
        "\r\n",
        "    def create_position_ids_from_inputs_embeds(self, inputs_embeds):\r\n",
        "        \"\"\"\r\n",
        "        We are provided embeddings directly. We cannot infer which are padded so just generate sequential position ids.\r\n",
        "        Args:\r\n",
        "            inputs_embeds: tf.Tensor\r\n",
        "        Returns: tf.Tensor\r\n",
        "        \"\"\"\r\n",
        "        batch_size, seq_length = shape_list(tensor=inputs_embeds)[:2]\r\n",
        "        position_ids = tf.range(start=self.padding_idx + 1, limit=seq_length + self.padding_idx + 1)[tf.newaxis, :]\r\n",
        "\r\n",
        "        return tf.tile(input=position_ids, multiples=(batch_size, 1))\r\n",
        "\r\n",
        "    def call(self, input_ids=None, position_ids=None, token_type_ids=None, inputs_embeds=None, training=False):\r\n",
        "        \"\"\"\r\n",
        "        Applies embedding based on inputs tensor.\r\n",
        "        Returns:\r\n",
        "            final_embeddings (:obj:`tf.Tensor`): output embedding tensor.\r\n",
        "        \"\"\"\r\n",
        "        assert not (input_ids is None and inputs_embeds is None)\r\n",
        "\r\n",
        "        if input_ids is not None:\r\n",
        "            inputs_embeds = self.word_embeddings(input_ids=input_ids)\r\n",
        "\r\n",
        "        if token_type_ids is None:\r\n",
        "            input_shape = shape_list(tensor=inputs_embeds)[:-1]\r\n",
        "            token_type_ids = tf.fill(dims=input_shape, value=0)\r\n",
        "\r\n",
        "        if position_ids is None:\r\n",
        "            if input_ids is not None:\r\n",
        "                # Create the position ids from the input token ids. Any padded tokens remain padded.\r\n",
        "                position_ids = self.create_position_ids_from_input_ids(input_ids=input_ids)\r\n",
        "            else:\r\n",
        "                position_ids = self.create_position_ids_from_inputs_embeds(inputs_embeds=inputs_embeds)\r\n",
        "\r\n",
        "        position_embeds = self.position_embeddings(position_ids=position_ids)\r\n",
        "        token_type_embeds = self.token_type_embeddings(token_type_ids=token_type_ids)\r\n",
        "        final_embeddings = self.embeddings_sum(inputs=[inputs_embeds, position_embeds, token_type_embeds])\r\n",
        "        final_embeddings = self.LayerNorm(inputs=final_embeddings)\r\n",
        "        final_embeddings = self.dropout(inputs=final_embeddings, training=training)\r\n",
        "\r\n",
        "        return final_embeddings\r\n",
        "\r\n",
        "\r\n",
        "# Copied from transformers.models.bert.modeling_tf_bert.TFBertPooler\r\n",
        "class TFRobertaPooler(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.dense = tf.keras.layers.Dense(\r\n",
        "            config.hidden_size,\r\n",
        "            kernel_initializer=get_initializer(config.initializer_range),\r\n",
        "            activation=\"tanh\",\r\n",
        "            name=\"dense\",\r\n",
        "        )\r\n",
        "\r\n",
        "    def call(self, hidden_states):\r\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\r\n",
        "        # to the first token.\r\n",
        "        first_token_tensor = hidden_states[:, 0]\r\n",
        "        pooled_output = self.dense(first_token_tensor)\r\n",
        "\r\n",
        "        return pooled_output\r\n",
        "\r\n",
        "\r\n",
        "# Copied from transformers.models.bert.modeling_tf_bert.TFBertSelfAttention with Bert->Roberta\r\n",
        "class TFRobertaSelfAttention(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\r\n",
        "            raise ValueError(\r\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number \"\r\n",
        "                f\"of attention heads ({config.num_attention_heads})\"\r\n",
        "            )\r\n",
        "\r\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\r\n",
        "\r\n",
        "        self.query = tf.keras.layers.experimental.EinsumDense(\r\n",
        "            equation=\"abc,cde->abde\",\r\n",
        "            output_shape=(None, config.num_attention_heads, self.attention_head_size),\r\n",
        "            bias_axes=\"de\",\r\n",
        "            kernel_initializer=get_initializer(initializer_range=config.initializer_range),\r\n",
        "            name=\"query\",\r\n",
        "        )\r\n",
        "        self.key = tf.keras.layers.experimental.EinsumDense(\r\n",
        "            equation=\"abc,cde->abde\",\r\n",
        "            output_shape=(None, config.num_attention_heads, self.attention_head_size),\r\n",
        "            bias_axes=\"de\",\r\n",
        "            kernel_initializer=get_initializer(initializer_range=config.initializer_range),\r\n",
        "            name=\"key\",\r\n",
        "        )\r\n",
        "        self.value = tf.keras.layers.experimental.EinsumDense(\r\n",
        "            equation=\"abc,cde->abde\",\r\n",
        "            output_shape=(None, config.num_attention_heads, self.attention_head_size),\r\n",
        "            bias_axes=\"de\",\r\n",
        "            kernel_initializer=get_initializer(initializer_range=config.initializer_range),\r\n",
        "            name=\"value\",\r\n",
        "        )\r\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.attention_probs_dropout_prob)\r\n",
        "\r\n",
        "    def call(self, hidden_states, attention_mask=None, head_mask=None, output_attentions=False, training=False):\r\n",
        "        query_layer = self.query(inputs=hidden_states)\r\n",
        "        key_layer = self.key(inputs=hidden_states)\r\n",
        "        value_layer = self.value(inputs=hidden_states)\r\n",
        "\r\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw\r\n",
        "        # attention scores.\r\n",
        "        dk = tf.cast(x=self.attention_head_size, dtype=query_layer.dtype)\r\n",
        "        query_layer = tf.multiply(x=query_layer, y=tf.math.rsqrt(x=dk))\r\n",
        "        attention_scores = tf.einsum(\"aecd,abcd->acbe\", key_layer, query_layer)\r\n",
        "\r\n",
        "        if attention_mask is not None:\r\n",
        "            # Apply the attention mask is (precomputed for all layers in TFRobertaModel call() function)\r\n",
        "            attention_scores = attention_scores + attention_mask\r\n",
        "\r\n",
        "        # Normalize the attention scores to probabilities.\r\n",
        "        attention_probs = tf.nn.softmax(logits=attention_scores, axis=-1)\r\n",
        "\r\n",
        "        # This is actually dropping out entire tokens to attend to, which might\r\n",
        "        # seem a bit unusual, but is taken from the original Transformer paper.\r\n",
        "        attention_probs = self.dropout(attention_probs, training=training)\r\n",
        "\r\n",
        "        # Mask heads if we want to\r\n",
        "        if head_mask is not None:\r\n",
        "            attention_scores = attention_scores * head_mask\r\n",
        "\r\n",
        "        attention_output = tf.einsum(\"acbe,aecd->abcd\", attention_probs, value_layer)\r\n",
        "        outputs = (attention_output, attention_probs) if output_attentions else (attention_output,)\r\n",
        "\r\n",
        "        return outputs\r\n",
        "\r\n",
        "\r\n",
        "# Copied from transformers.models.bert.modeling_tf_bert.TFBertSelfOutput\r\n",
        "class TFRobertaSelfOutput(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        if config.hidden_size % config.num_attention_heads != 0:\r\n",
        "            raise ValueError(\r\n",
        "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number \"\r\n",
        "                f\"of attention heads ({config.num_attention_heads})\"\r\n",
        "            )\r\n",
        "\r\n",
        "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\r\n",
        "        self.all_head_size = config.num_attention_heads * self.attention_head_size\r\n",
        "\r\n",
        "        self.dense = tf.keras.layers.experimental.EinsumDense(\r\n",
        "            equation=\"abcd,cde->abe\",\r\n",
        "            output_shape=(None, self.all_head_size),\r\n",
        "            bias_axes=\"e\",\r\n",
        "            kernel_initializer=get_initializer(initializer_range=config.initializer_range),\r\n",
        "            name=\"dense\",\r\n",
        "        )\r\n",
        "        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\r\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\r\n",
        "\r\n",
        "    def call(self, hidden_states, input_tensor, training=False):\r\n",
        "        hidden_states = self.dense(inputs=hidden_states)\r\n",
        "        hidden_states = self.dropout(inputs=hidden_states, training=training)\r\n",
        "        hidden_states = self.LayerNorm(inputs=hidden_states + input_tensor)\r\n",
        "\r\n",
        "        return hidden_states\r\n",
        "\r\n",
        "\r\n",
        "# Copied from transformers.models.bert.modeling_tf_bert.TFBertAttention with Bert->Roberta\r\n",
        "class TFRobertaAttention(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        #self.self_attention = TFRobertaSelfAttention(config, name=\"self\")\r\n",
        "        \r\n",
        "        # Either merge Performer Config w/ normal config or enable choosing Performer\r\n",
        "        # Currently manually add performer == True to config\r\n",
        "        self.perf_attn = config.performer\r\n",
        "        if self.perf_attn == True:\r\n",
        "\r\n",
        "            self.num_attention_heads = config.num_attention_heads\r\n",
        "\r\n",
        "            performer_config = PerformerAttentionConfig(\r\n",
        "                                num_heads=config.num_attention_heads,\r\n",
        "                                d_model=config.hidden_size,\r\n",
        "                                kernel_type='exp',\r\n",
        "                                num_random_features=300,\r\n",
        "                                use_linear_layers=False\r\n",
        "                                )\r\n",
        "\r\n",
        "            self.self_attention = TFPerformerAttention(performer_config, name=\"self\")\r\n",
        "\r\n",
        "        else: \r\n",
        "            self.self_attention = TFRobertaSelfAttention(config, name=\"self\")\r\n",
        "\r\n",
        "\r\n",
        "        self.dense_output = TFRobertaSelfOutput(config, name=\"output\")\r\n",
        "\r\n",
        "    def prune_heads(self, heads):\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "    def call(self, input_tensor, attention_mask, head_mask, output_attentions, training=False):\r\n",
        "\r\n",
        "\r\n",
        "        if self.perf_attn:\r\n",
        "            self_outputs = self.self_attention(\r\n",
        "                input_tensor, input_tensor, input_tensor, attention_mask, head_mask, output_attentions\r\n",
        "            )\r\n",
        "        \r\n",
        "        else:\r\n",
        "            self_outputs = self.self_attention(\r\n",
        "            input_tensor, attention_mask, head_mask, output_attentions, training=training\r\n",
        "            )\r\n",
        "\r\n",
        "\r\n",
        "        attention_output = self.dense_output(self_outputs[0], input_tensor, training=training)\r\n",
        "        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\r\n",
        "\r\n",
        "        return outputs\r\n",
        "\r\n",
        "\r\n",
        "# Copied from transformers.models.bert.modeling_tf_bert.TFBertIntermediate\r\n",
        "class TFRobertaIntermediate(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.dense = tf.keras.layers.experimental.EinsumDense(\r\n",
        "            equation=\"abc,cd->abd\",\r\n",
        "            output_shape=(None, config.intermediate_size),\r\n",
        "            bias_axes=\"d\",\r\n",
        "            kernel_initializer=get_initializer(initializer_range=config.initializer_range),\r\n",
        "            name=\"dense\",\r\n",
        "        )\r\n",
        "\r\n",
        "        if isinstance(config.hidden_act, str):\r\n",
        "            self.intermediate_act_fn = get_tf_activation(activation_string=config.hidden_act)\r\n",
        "        else:\r\n",
        "            self.intermediate_act_fn = config.hidden_act\r\n",
        "\r\n",
        "    def call(self, hidden_states):\r\n",
        "        hidden_states = self.dense(inputs=hidden_states)\r\n",
        "        hidden_states = self.intermediate_act_fn(hidden_states)\r\n",
        "\r\n",
        "        return hidden_states\r\n",
        "\r\n",
        "\r\n",
        "# Copied from transformers.models.bert.modeling_tf_bert.TFBertOutput\r\n",
        "class TFRobertaOutput(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.dense = tf.keras.layers.experimental.EinsumDense(\r\n",
        "            equation=\"abc,cd->abd\",\r\n",
        "            bias_axes=\"d\",\r\n",
        "            output_shape=(None, config.hidden_size),\r\n",
        "            kernel_initializer=get_initializer(config.initializer_range),\r\n",
        "            name=\"dense\",\r\n",
        "        )\r\n",
        "        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\r\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\r\n",
        "\r\n",
        "    def call(self, hidden_states, input_tensor, training=False):\r\n",
        "        hidden_states = self.dense(inputs=hidden_states)\r\n",
        "        hidden_states = self.dropout(inputs=hidden_states, training=training)\r\n",
        "        hidden_states = self.LayerNorm(inputs=hidden_states + input_tensor)\r\n",
        "\r\n",
        "        return hidden_states\r\n",
        "\r\n",
        "\r\n",
        "# Copied from transformers.models.bert.modeling_tf_bert.TFBertLayer with Bert->Roberta\r\n",
        "class TFRobertaLayer(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.attention = TFRobertaAttention(config, name=\"attention\")\r\n",
        "        self.intermediate = TFRobertaIntermediate(config, name=\"intermediate\")\r\n",
        "        self.bert_output = TFRobertaOutput(config, name=\"output\")\r\n",
        "\r\n",
        "    def call(self, hidden_states, attention_mask, head_mask, output_attentions, training=False):\r\n",
        "        attention_outputs = self.attention(\r\n",
        "            hidden_states, attention_mask, head_mask, output_attentions, training=training\r\n",
        "        )\r\n",
        "        attention_output = attention_outputs[0]\r\n",
        "        intermediate_output = self.intermediate(attention_output)\r\n",
        "        layer_output = self.bert_output(intermediate_output, attention_output, training=training)\r\n",
        "        outputs = (layer_output,) + attention_outputs[1:]  # add attentions if we output them\r\n",
        "\r\n",
        "        return outputs\r\n",
        "\r\n",
        "\r\n",
        "# Copied from transformers.models.bert.modeling_tf_bert.TFBertEncoder with Bert->Roberta\r\n",
        "class TFRobertaEncoder(tf.keras.layers.Layer):\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.layer = [TFRobertaLayer(config, name=\"layer_._{}\".format(i)) for i in range(config.num_hidden_layers)]\r\n",
        "\r\n",
        "    def call(\r\n",
        "        self,\r\n",
        "        hidden_states,\r\n",
        "        attention_mask,\r\n",
        "        head_mask,\r\n",
        "        output_attentions,\r\n",
        "        output_hidden_states,\r\n",
        "        return_dict,\r\n",
        "        training=False,\r\n",
        "    ):\r\n",
        "        all_hidden_states = () if output_hidden_states else None\r\n",
        "        all_attentions = () if output_attentions else None\r\n",
        "\r\n",
        "        for i, layer_module in enumerate(self.layer):\r\n",
        "            if output_hidden_states:\r\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\r\n",
        "\r\n",
        "            layer_outputs = layer_module(\r\n",
        "                hidden_states, attention_mask, head_mask[i], output_attentions, training=training\r\n",
        "            )\r\n",
        "            hidden_states = layer_outputs[0]\r\n",
        "\r\n",
        "            if output_attentions:\r\n",
        "                all_attentions = all_attentions + (layer_outputs[1],)\r\n",
        "\r\n",
        "        # Add last layer\r\n",
        "        if output_hidden_states:\r\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\r\n",
        "\r\n",
        "        if not return_dict:\r\n",
        "            return tuple(v for v in [hidden_states, all_hidden_states, all_attentions] if v is not None)\r\n",
        "\r\n",
        "        return TFBaseModelOutput(\r\n",
        "            last_hidden_state=hidden_states, hidden_states=all_hidden_states, attentions=all_attentions\r\n",
        "        )\r\n",
        "\r\n",
        "\r\n",
        "#@keras_serializable\r\n",
        "class TFRobertaMainLayer(tf.keras.layers.Layer):\r\n",
        "    config_class = RobertaConfig\r\n",
        "\r\n",
        "    def __init__(self, config, add_pooling_layer=True, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.config = config\r\n",
        "        self.num_hidden_layers = config.num_hidden_layers\r\n",
        "        self.initializer_range = config.initializer_range\r\n",
        "        self.output_attentions = config.output_attentions\r\n",
        "        self.output_hidden_states = config.output_hidden_states\r\n",
        "        self.return_dict = config.use_return_dict\r\n",
        "        self.encoder = TFRobertaEncoder(config, name=\"encoder\")\r\n",
        "        self.pooler = TFRobertaPooler(config, name=\"pooler\") if add_pooling_layer else None\r\n",
        "        # The embeddings must be the last declaration in order to follow the weights order\r\n",
        "        self.embeddings = TFRobertaEmbeddings(config, name=\"embeddings\")\r\n",
        "\r\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertMainLayer.get_input_embeddings\r\n",
        "    def get_input_embeddings(self):\r\n",
        "        return self.embeddings.word_embeddings\r\n",
        "\r\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertMainLayer.set_input_embeddings\r\n",
        "    def set_input_embeddings(self, value):\r\n",
        "        self.embeddings.word_embeddings.weight = value\r\n",
        "        self.embeddings.word_embeddings.vocab_size = shape_list(value)[0]\r\n",
        "\r\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertMainLayer._prune_heads\r\n",
        "    def _prune_heads(self, heads_to_prune):\r\n",
        "        \"\"\"\r\n",
        "        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\r\n",
        "        class PreTrainedModel\r\n",
        "        \"\"\"\r\n",
        "        raise NotImplementedError\r\n",
        "\r\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertMainLayer.call\r\n",
        "    def call(\r\n",
        "        self,\r\n",
        "        input_ids=None,\r\n",
        "        attention_mask=None,\r\n",
        "        token_type_ids=None,\r\n",
        "        position_ids=None,\r\n",
        "        head_mask=None,\r\n",
        "        inputs_embeds=None,\r\n",
        "        output_attentions=None,\r\n",
        "        output_hidden_states=None,\r\n",
        "        return_dict=None,\r\n",
        "        training=False,\r\n",
        "        **kwargs,\r\n",
        "    ):\r\n",
        "        inputs = input_processing(\r\n",
        "            func=self.call,\r\n",
        "            config=self.config,\r\n",
        "            input_ids=input_ids,\r\n",
        "            attention_mask=attention_mask,\r\n",
        "            token_type_ids=token_type_ids,\r\n",
        "            position_ids=position_ids,\r\n",
        "            head_mask=head_mask,\r\n",
        "            inputs_embeds=inputs_embeds,\r\n",
        "            output_attentions=output_attentions,\r\n",
        "            output_hidden_states=output_hidden_states,\r\n",
        "            return_dict=return_dict,\r\n",
        "            training=training,\r\n",
        "            kwargs_call=kwargs,\r\n",
        "        )\r\n",
        "\r\n",
        "        if inputs[\"input_ids\"] is not None and inputs[\"inputs_embeds\"] is not None:\r\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\r\n",
        "        elif inputs[\"input_ids\"] is not None:\r\n",
        "            input_shape = shape_list(inputs[\"input_ids\"])\r\n",
        "        elif inputs[\"inputs_embeds\"] is not None:\r\n",
        "            input_shape = shape_list(inputs[\"inputs_embeds\"])[:-1]\r\n",
        "        else:\r\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\r\n",
        "\r\n",
        "        if inputs[\"attention_mask\"] is None:\r\n",
        "            inputs[\"attention_mask\"] = tf.fill(input_shape, 1)\r\n",
        "\r\n",
        "        if inputs[\"token_type_ids\"] is None:\r\n",
        "            inputs[\"token_type_ids\"] = tf.fill(input_shape, 0)\r\n",
        "\r\n",
        "        embedding_output = self.embeddings(\r\n",
        "            inputs[\"input_ids\"],\r\n",
        "            inputs[\"position_ids\"],\r\n",
        "            inputs[\"token_type_ids\"],\r\n",
        "            inputs[\"inputs_embeds\"],\r\n",
        "            training=inputs[\"training\"],\r\n",
        "        )\r\n",
        "\r\n",
        "        # We create a 3D attention mask from a 2D tensor mask.\r\n",
        "        # Sizes are [batch_size, 1, 1, to_seq_length]\r\n",
        "        # So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\r\n",
        "        # this attention mask is more simple than the triangular masking of causal attention\r\n",
        "        # used in OpenAI GPT, we just need to prepare the broadcast dimension here.\r\n",
        "        extended_attention_mask = inputs[\"attention_mask\"][:, tf.newaxis, tf.newaxis, :]\r\n",
        "\r\n",
        "        # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\r\n",
        "        # masked positions, this operation will create a tensor which is 0.0 for\r\n",
        "        # positions we want to attend and -10000.0 for masked positions.\r\n",
        "        # Since we are adding it to the raw scores before the softmax, this is\r\n",
        "        # effectively the same as removing these entirely.\r\n",
        "        extended_attention_mask = tf.cast(extended_attention_mask, embedding_output.dtype)\r\n",
        "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\r\n",
        "\r\n",
        "        # Prepare head mask if needed\r\n",
        "        # 1.0 in head_mask indicate we keep the head\r\n",
        "        # attention_probs has shape bsz x n_heads x N x N\r\n",
        "        # input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\r\n",
        "        # and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\r\n",
        "        if inputs[\"head_mask\"] is not None:\r\n",
        "            raise NotImplementedError\r\n",
        "        else:\r\n",
        "            inputs[\"head_mask\"] = [None] * self.num_hidden_layers\r\n",
        "            # head_mask = tf.constant([0] * self.num_hidden_layers)\r\n",
        "\r\n",
        "        encoder_outputs = self.encoder(\r\n",
        "            embedding_output,\r\n",
        "            extended_attention_mask,\r\n",
        "            inputs[\"head_mask\"],\r\n",
        "            inputs[\"output_attentions\"],\r\n",
        "            inputs[\"output_hidden_states\"],\r\n",
        "            inputs[\"return_dict\"],\r\n",
        "            training=inputs[\"training\"],\r\n",
        "        )\r\n",
        "\r\n",
        "        sequence_output = encoder_outputs[0]\r\n",
        "        pooled_output = self.pooler(sequence_output) if self.pooler is not None else None\r\n",
        "\r\n",
        "        if not inputs[\"return_dict\"]:\r\n",
        "            return (\r\n",
        "                sequence_output,\r\n",
        "                pooled_output,\r\n",
        "            ) + encoder_outputs[1:]\r\n",
        "\r\n",
        "        return TFBaseModelOutputWithPooling(\r\n",
        "            last_hidden_state=sequence_output,\r\n",
        "            pooler_output=pooled_output,\r\n",
        "            hidden_states=encoder_outputs.hidden_states,\r\n",
        "            attentions=encoder_outputs.attentions,\r\n",
        "        )\r\n",
        "\r\n",
        "\r\n",
        "class TFRobertaPreTrainedModel(TFPreTrainedModel):\r\n",
        "    \"\"\"\r\n",
        "    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\r\n",
        "    models.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    config_class = RobertaConfig\r\n",
        "    base_model_prefix = \"roberta\"\r\n",
        "\r\n",
        "    @tf.function(\r\n",
        "        input_signature=[\r\n",
        "            {\r\n",
        "                \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\r\n",
        "                \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),\r\n",
        "            }\r\n",
        "        ]\r\n",
        "    )\r\n",
        "    def serving(self, inputs):\r\n",
        "        output = self.call(inputs)\r\n",
        "\r\n",
        "        return self.serving_output(output)\r\n",
        "\r\n",
        "\r\n",
        "ROBERTA_START_DOCSTRING = r\"\"\"\r\n",
        "    This model inherits from :class:`~transformers.TFPreTrainedModel`. Check the superclass documentation for the\r\n",
        "    generic methods the library implements for all its model (such as downloading or saving, resizing the input\r\n",
        "    embeddings, pruning heads etc.)\r\n",
        "    This model is also a `tf.keras.Model <https://www.tensorflow.org/api_docs/python/tf/keras/Model>`__ subclass. Use\r\n",
        "    it as a regular TF 2.0 Keras Model and refer to the TF 2.0 documentation for all matter related to general usage\r\n",
        "    and behavior.\r\n",
        "    .. note::\r\n",
        "        TF 2.0 models accepts two formats as inputs:\r\n",
        "        - having all inputs as keyword arguments (like PyTorch models), or\r\n",
        "        - having all inputs as a list, tuple or dict in the first positional arguments.\r\n",
        "        This second option is useful when using :meth:`tf.keras.Model.fit` method which currently requires having all\r\n",
        "        the tensors in the first argument of the model call function: :obj:`model(inputs)`.\r\n",
        "        If you choose this second option, there are three possibilities you can use to gather all the input Tensors in\r\n",
        "        the first positional argument :\r\n",
        "        - a single Tensor with :obj:`input_ids` only and nothing else: :obj:`model(inputs_ids)`\r\n",
        "        - a list of varying length with one or several input Tensors IN THE ORDER given in the docstring:\r\n",
        "          :obj:`model([input_ids, attention_mask])` or :obj:`model([input_ids, attention_mask, token_type_ids])`\r\n",
        "        - a dictionary with one or several input Tensors associated to the input names given in the docstring:\r\n",
        "          :obj:`model({\"input_ids\": input_ids, \"token_type_ids\": token_type_ids})`\r\n",
        "    Parameters:\r\n",
        "        config (:class:`~transformers.RobertaConfig`): Model configuration class with all the parameters of the\r\n",
        "            model. Initializing with a config file does not load the weights associated with the model, only the\r\n",
        "            configuration. Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model\r\n",
        "            weights.\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "ROBERTA_INPUTS_DOCSTRING = r\"\"\"\r\n",
        "    Args:\r\n",
        "        input_ids (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`({0})`):\r\n",
        "            Indices of input sequence tokens in the vocabulary.\r\n",
        "            Indices can be obtained using :class:`~transformers.RobertaTokenizer`. See\r\n",
        "            :func:`transformers.PreTrainedTokenizer.__call__` and :func:`transformers.PreTrainedTokenizer.encode` for\r\n",
        "            details.\r\n",
        "            `What are input IDs? <../glossary.html#input-ids>`__\r\n",
        "        attention_mask (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`({0})`, `optional`):\r\n",
        "            Mask to avoid performing attention on padding token indices. Mask values selected in ``[0, 1]``:\r\n",
        "            - 1 for tokens that are **not masked**,\r\n",
        "            - 0 for tokens that are **masked**.\r\n",
        "            `What are attention masks? <../glossary.html#attention-mask>`__\r\n",
        "        token_type_ids (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`({0})`, `optional`):\r\n",
        "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in ``[0,\r\n",
        "            1]``:\r\n",
        "            - 0 corresponds to a `sentence A` token,\r\n",
        "            - 1 corresponds to a `sentence B` token.\r\n",
        "            `What are token type IDs? <../glossary.html#token-type-ids>`__\r\n",
        "        position_ids (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`({0})`, `optional`):\r\n",
        "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range ``[0,\r\n",
        "            config.max_position_embeddings - 1]``.\r\n",
        "            `What are position IDs? <../glossary.html#position-ids>`__\r\n",
        "        head_mask (:obj:`Numpy array` or :obj:`tf.Tensor` of shape :obj:`(num_heads,)` or :obj:`(num_layers, num_heads)`, `optional`):\r\n",
        "            Mask to nullify selected heads of the self-attention modules. Mask values selected in ``[0, 1]``:\r\n",
        "            - 1 indicates the head is **not masked**,\r\n",
        "            - 0 indicates the head is **masked**.\r\n",
        "        inputs_embeds (:obj:`tf.Tensor` of shape :obj:`({0}, hidden_size)`, `optional`):\r\n",
        "            Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded representation.\r\n",
        "            This is useful if you want more control over how to convert :obj:`input_ids` indices into associated\r\n",
        "            vectors than the model's internal embedding lookup matrix.\r\n",
        "        output_attentions (:obj:`bool`, `optional`):\r\n",
        "            Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under returned\r\n",
        "            tensors for more detail.\r\n",
        "        output_hidden_states (:obj:`bool`, `optional`):\r\n",
        "            Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors for\r\n",
        "            more detail.\r\n",
        "        return_dict (:obj:`bool`, `optional`):\r\n",
        "            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\r\n",
        "        training (:obj:`bool`, `optional`, defaults to :obj:`False`):\r\n",
        "            Whether or not to use the model in training mode (some modules like dropout modules have different\r\n",
        "            behaviors between training and evaluation).\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "\r\n",
        "@add_start_docstrings(\r\n",
        "    \"The bare RoBERTa Model transformer outputting raw hidden-states without any specific head on top.\",\r\n",
        "    ROBERTA_START_DOCSTRING,\r\n",
        ")\r\n",
        "class TFRobertaModel(TFRobertaPreTrainedModel):\r\n",
        "    def __init__(self, config, *inputs, **kwargs):\r\n",
        "        super().__init__(config, *inputs, **kwargs)\r\n",
        "        self.roberta = TFRobertaMainLayer(config, name=\"roberta\")\r\n",
        "\r\n",
        "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\r\n",
        "    @add_code_sample_docstrings(\r\n",
        "        tokenizer_class=_TOKENIZER_FOR_DOC,\r\n",
        "        checkpoint=\"roberta-base\",\r\n",
        "        output_type=TFBaseModelOutputWithPooling,\r\n",
        "        config_class=_CONFIG_FOR_DOC,\r\n",
        "    )\r\n",
        "    def call(\r\n",
        "        self,\r\n",
        "        input_ids=None,\r\n",
        "        attention_mask=None,\r\n",
        "        token_type_ids=None,\r\n",
        "        position_ids=None,\r\n",
        "        head_mask=None,\r\n",
        "        inputs_embeds=None,\r\n",
        "        output_attentions=None,\r\n",
        "        output_hidden_states=None,\r\n",
        "        return_dict=None,\r\n",
        "        training=False,\r\n",
        "        **kwargs,\r\n",
        "    ):\r\n",
        "        inputs = input_processing(\r\n",
        "            func=self.call,\r\n",
        "            config=self.config,\r\n",
        "            input_ids=input_ids,\r\n",
        "            attention_mask=attention_mask,\r\n",
        "            token_type_ids=token_type_ids,\r\n",
        "            position_ids=position_ids,\r\n",
        "            head_mask=head_mask,\r\n",
        "            inputs_embeds=inputs_embeds,\r\n",
        "            output_attentions=output_attentions,\r\n",
        "            output_hidden_states=output_hidden_states,\r\n",
        "            return_dict=return_dict,\r\n",
        "            training=training,\r\n",
        "            kwargs_call=kwargs,\r\n",
        "        )\r\n",
        "        outputs = self.roberta(\r\n",
        "            input_ids=inputs[\"input_ids\"],\r\n",
        "            attention_mask=inputs[\"attention_mask\"],\r\n",
        "            token_type_ids=inputs[\"token_type_ids\"],\r\n",
        "            position_ids=inputs[\"position_ids\"],\r\n",
        "            head_mask=inputs[\"head_mask\"],\r\n",
        "            inputs_embeds=inputs[\"inputs_embeds\"],\r\n",
        "            output_attentions=inputs[\"output_attentions\"],\r\n",
        "            output_hidden_states=inputs[\"output_hidden_states\"],\r\n",
        "            return_dict=inputs[\"return_dict\"],\r\n",
        "            training=inputs[\"training\"],\r\n",
        "        )\r\n",
        "\r\n",
        "        return outputs\r\n",
        "\r\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertModel.serving_output\r\n",
        "    def serving_output(self, output):\r\n",
        "        hs = tf.convert_to_tensor(output.hidden_states) if self.config.output_hidden_states else None\r\n",
        "        attns = tf.convert_to_tensor(output.attentions) if self.config.output_attentions else None\r\n",
        "\r\n",
        "        return TFBaseModelOutputWithPooling(\r\n",
        "            last_hidden_state=output.last_hidden_state,\r\n",
        "            pooler_output=output.pooler_output,\r\n",
        "            hidden_states=hs,\r\n",
        "            attentions=attns,\r\n",
        "        )\r\n",
        "\r\n",
        "\r\n",
        "class TFRobertaLMHead(tf.keras.layers.Layer):\r\n",
        "    \"\"\"Roberta Head for masked language modeling.\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, config, input_embeddings, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "\r\n",
        "        self.vocab_size = config.vocab_size\r\n",
        "        self.hidden_size = config.hidden_size\r\n",
        "        self.dense = tf.keras.layers.Dense(\r\n",
        "            config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"\r\n",
        "        )\r\n",
        "        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"layer_norm\")\r\n",
        "        self.act = get_tf_activation(\"gelu\")\r\n",
        "\r\n",
        "        # The output weights are the same as the input embeddings, but there is\r\n",
        "        # an output-only bias for each token.\r\n",
        "        self.decoder = input_embeddings\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        self.bias = self.add_weight(shape=(self.vocab_size,), initializer=\"zeros\", trainable=True, name=\"bias\")\r\n",
        "\r\n",
        "        super().build(input_shape)\r\n",
        "\r\n",
        "    def get_output_embeddings(self):\r\n",
        "        return self.decoder\r\n",
        "\r\n",
        "    def set_output_embeddings(self, value):\r\n",
        "        self.decoder.weight = value\r\n",
        "        self.decoder.vocab_size = shape_list(value)[0]\r\n",
        "\r\n",
        "    def get_bias(self):\r\n",
        "        return {\"bias\": self.bias}\r\n",
        "\r\n",
        "    def set_bias(self, value):\r\n",
        "        self.bias = value[\"bias\"]\r\n",
        "        self.vocab_size = shape_list(value[\"bias\"])[0]\r\n",
        "\r\n",
        "    def call(self, hidden_states):\r\n",
        "        hidden_states = self.dense(hidden_states)\r\n",
        "        hidden_states = self.act(hidden_states)\r\n",
        "        hidden_states = self.layer_norm(hidden_states)\r\n",
        "\r\n",
        "        # project back to size of vocabulary with bias\r\n",
        "        seq_length = shape_list(tensor=hidden_states)[1]\r\n",
        "        hidden_states = tf.reshape(tensor=hidden_states, shape=[-1, self.hidden_size])\r\n",
        "        hidden_states = tf.matmul(a=hidden_states, b=self.decoder.weight, transpose_b=True)\r\n",
        "        hidden_states = tf.reshape(tensor=hidden_states, shape=[-1, seq_length, self.vocab_size])\r\n",
        "        hidden_states = tf.nn.bias_add(value=hidden_states, bias=self.bias)\r\n",
        "\r\n",
        "        return hidden_states\r\n",
        "\r\n",
        "\r\n",
        "@add_start_docstrings(\"\"\"RoBERTa Model with a `language modeling` head on top. \"\"\", ROBERTA_START_DOCSTRING)\r\n",
        "class TFRobertaForMaskedLM(TFRobertaPreTrainedModel, TFMaskedLanguageModelingLoss):\r\n",
        "    # names with a '.' represents the authorized unexpected/missing layers when a TF model is loaded from a PT model\r\n",
        "    _keys_to_ignore_on_load_unexpected = [r\"pooler\", r\"lm_head.decoder.weight\"]\r\n",
        "\r\n",
        "    def __init__(self, config, *inputs, **kwargs):\r\n",
        "        super().__init__(config, *inputs, **kwargs)\r\n",
        "\r\n",
        "        self.roberta = TFRobertaMainLayer(config, add_pooling_layer=False, name=\"roberta\")\r\n",
        "        self.lm_head = TFRobertaLMHead(config, self.roberta.embeddings.word_embeddings, name=\"lm_head\")\r\n",
        "\r\n",
        "    def get_lm_head(self):\r\n",
        "        return self.lm_head\r\n",
        "\r\n",
        "    def get_prefix_bias_name(self):\r\n",
        "        warnings.warn(\"The method get_prefix_bias_name is deprecated. Please use `get_bias` instead.\", FutureWarning)\r\n",
        "        return self.name + \"/\" + self.lm_head.name\r\n",
        "\r\n",
        "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\r\n",
        "    @add_code_sample_docstrings(\r\n",
        "        tokenizer_class=_TOKENIZER_FOR_DOC,\r\n",
        "        checkpoint=\"roberta-base\",\r\n",
        "        output_type=TFMaskedLMOutput,\r\n",
        "        config_class=_CONFIG_FOR_DOC,\r\n",
        "    )\r\n",
        "    def call(\r\n",
        "        self,\r\n",
        "        input_ids=None,\r\n",
        "        attention_mask=None,\r\n",
        "        token_type_ids=None,\r\n",
        "        position_ids=None,\r\n",
        "        head_mask=None,\r\n",
        "        inputs_embeds=None,\r\n",
        "        output_attentions=None,\r\n",
        "        output_hidden_states=None,\r\n",
        "        return_dict=None,\r\n",
        "        labels=None,\r\n",
        "        training=False,\r\n",
        "        **kwargs,\r\n",
        "    ):\r\n",
        "        r\"\"\"\r\n",
        "        labels (:obj:`tf.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\r\n",
        "            Labels for computing the masked language modeling loss. Indices should be in ``[-100, 0, ...,\r\n",
        "            config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are ignored\r\n",
        "            (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``\r\n",
        "        \"\"\"\r\n",
        "        inputs = input_processing(\r\n",
        "            func=self.call,\r\n",
        "            config=self.config,\r\n",
        "            input_ids=input_ids,\r\n",
        "            attention_mask=attention_mask,\r\n",
        "            token_type_ids=token_type_ids,\r\n",
        "            position_ids=position_ids,\r\n",
        "            head_mask=head_mask,\r\n",
        "            inputs_embeds=inputs_embeds,\r\n",
        "            output_attentions=output_attentions,\r\n",
        "            output_hidden_states=output_hidden_states,\r\n",
        "            return_dict=return_dict,\r\n",
        "            labels=labels,\r\n",
        "            training=training,\r\n",
        "            kwargs_call=kwargs,\r\n",
        "        )\r\n",
        "        outputs = self.roberta(\r\n",
        "            inputs[\"input_ids\"],\r\n",
        "            attention_mask=inputs[\"attention_mask\"],\r\n",
        "            token_type_ids=inputs[\"token_type_ids\"],\r\n",
        "            position_ids=inputs[\"position_ids\"],\r\n",
        "            head_mask=inputs[\"head_mask\"],\r\n",
        "            inputs_embeds=inputs[\"inputs_embeds\"],\r\n",
        "            output_attentions=inputs[\"output_attentions\"],\r\n",
        "            output_hidden_states=inputs[\"output_hidden_states\"],\r\n",
        "            return_dict=inputs[\"return_dict\"],\r\n",
        "            training=inputs[\"training\"],\r\n",
        "        )\r\n",
        "\r\n",
        "        sequence_output = outputs[0]\r\n",
        "        prediction_scores = self.lm_head(sequence_output)\r\n",
        "\r\n",
        "        loss = None if inputs[\"labels\"] is None else self.compute_loss(inputs[\"labels\"], prediction_scores)\r\n",
        "\r\n",
        "        if not inputs[\"return_dict\"]:\r\n",
        "            output = (prediction_scores,) + outputs[2:]\r\n",
        "            return ((loss,) + output) if loss is not None else output\r\n",
        "\r\n",
        "        return TFMaskedLMOutput(\r\n",
        "            loss=loss,\r\n",
        "            logits=prediction_scores,\r\n",
        "            hidden_states=outputs.hidden_states,\r\n",
        "            attentions=outputs.attentions,\r\n",
        "        )\r\n",
        "\r\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertForMaskedLM.serving_output\r\n",
        "    def serving_output(self, output):\r\n",
        "        hs = tf.convert_to_tensor(output.hidden_states) if self.config.output_hidden_states else None\r\n",
        "        attns = tf.convert_to_tensor(output.attentions) if self.config.output_attentions else None\r\n",
        "\r\n",
        "        return TFMaskedLMOutput(logits=output.logits, hidden_states=hs, attentions=attns)\r\n",
        "\r\n",
        "\r\n",
        "class TFRobertaClassificationHead(tf.keras.layers.Layer):\r\n",
        "    \"\"\"Head for sentence-level classification tasks.\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, config, **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "        self.dense = tf.keras.layers.Dense(\r\n",
        "            config.hidden_size,\r\n",
        "            kernel_initializer=get_initializer(config.initializer_range),\r\n",
        "            activation=\"tanh\",\r\n",
        "            name=\"dense\",\r\n",
        "        )\r\n",
        "        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\r\n",
        "        self.out_proj = tf.keras.layers.Dense(\r\n",
        "            config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"out_proj\"\r\n",
        "        )\r\n",
        "\r\n",
        "    def call(self, features, training=False):\r\n",
        "        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\r\n",
        "        x = self.dropout(x, training=training)\r\n",
        "        x = self.dense(x)\r\n",
        "        x = self.dropout(x, training=training)\r\n",
        "        x = self.out_proj(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "@add_start_docstrings(\r\n",
        "    \"\"\"\r\n",
        "    RoBERTa Model transformer with a sequence classification/regression head on top (a linear layer on top of the\r\n",
        "    pooled output) e.g. for GLUE tasks.\r\n",
        "    \"\"\",\r\n",
        "    ROBERTA_START_DOCSTRING,\r\n",
        ")\r\n",
        "class TFRobertaForSequenceClassification(TFRobertaPreTrainedModel, TFSequenceClassificationLoss):\r\n",
        "    # names with a '.' represents the authorized unexpected/missing layers when a TF model is loaded from a PT model\r\n",
        "    _keys_to_ignore_on_load_unexpected = [r\"pooler\", r\"lm_head\"]\r\n",
        "\r\n",
        "    def __init__(self, config, *inputs, **kwargs):\r\n",
        "        super().__init__(config, *inputs, **kwargs)\r\n",
        "        self.num_labels = config.num_labels\r\n",
        "\r\n",
        "        self.roberta = TFRobertaMainLayer(config, add_pooling_layer=False, name=\"roberta\")\r\n",
        "        self.classifier = TFRobertaClassificationHead(config, name=\"classifier\")\r\n",
        "\r\n",
        "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\r\n",
        "    @add_code_sample_docstrings(\r\n",
        "        tokenizer_class=_TOKENIZER_FOR_DOC,\r\n",
        "        checkpoint=\"roberta-base\",\r\n",
        "        output_type=TFSequenceClassifierOutput,\r\n",
        "        config_class=_CONFIG_FOR_DOC,\r\n",
        "    )\r\n",
        "    def call(\r\n",
        "        self,\r\n",
        "        input_ids=None,\r\n",
        "        attention_mask=None,\r\n",
        "        token_type_ids=None,\r\n",
        "        position_ids=None,\r\n",
        "        head_mask=None,\r\n",
        "        inputs_embeds=None,\r\n",
        "        output_attentions=None,\r\n",
        "        output_hidden_states=None,\r\n",
        "        return_dict=None,\r\n",
        "        labels=None,\r\n",
        "        training=False,\r\n",
        "        **kwargs,\r\n",
        "    ):\r\n",
        "        r\"\"\"\r\n",
        "        labels (:obj:`tf.Tensor` of shape :obj:`(batch_size,)`, `optional`):\r\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\r\n",
        "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\r\n",
        "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\r\n",
        "        \"\"\"\r\n",
        "        inputs = input_processing(\r\n",
        "            func=self.call,\r\n",
        "            config=self.config,\r\n",
        "            input_ids=input_ids,\r\n",
        "            attention_mask=attention_mask,\r\n",
        "            token_type_ids=token_type_ids,\r\n",
        "            position_ids=position_ids,\r\n",
        "            head_mask=head_mask,\r\n",
        "            inputs_embeds=inputs_embeds,\r\n",
        "            output_attentions=output_attentions,\r\n",
        "            output_hidden_states=output_hidden_states,\r\n",
        "            return_dict=return_dict,\r\n",
        "            labels=labels,\r\n",
        "            training=training,\r\n",
        "            kwargs_call=kwargs,\r\n",
        "        )\r\n",
        "        outputs = self.roberta(\r\n",
        "            inputs[\"input_ids\"],\r\n",
        "            attention_mask=inputs[\"attention_mask\"],\r\n",
        "            token_type_ids=inputs[\"token_type_ids\"],\r\n",
        "            position_ids=inputs[\"position_ids\"],\r\n",
        "            head_mask=inputs[\"head_mask\"],\r\n",
        "            inputs_embeds=inputs[\"inputs_embeds\"],\r\n",
        "            output_attentions=inputs[\"output_attentions\"],\r\n",
        "            output_hidden_states=inputs[\"output_hidden_states\"],\r\n",
        "            return_dict=inputs[\"return_dict\"],\r\n",
        "            training=inputs[\"training\"],\r\n",
        "        )\r\n",
        "        sequence_output = outputs[0]\r\n",
        "        logits = self.classifier(sequence_output, training=inputs[\"training\"])\r\n",
        "\r\n",
        "        loss = None if inputs[\"labels\"] is None else self.compute_loss(inputs[\"labels\"], logits)\r\n",
        "\r\n",
        "        if not inputs[\"return_dict\"]:\r\n",
        "            output = (logits,) + outputs[2:]\r\n",
        "            return ((loss,) + output) if loss is not None else output\r\n",
        "\r\n",
        "        return TFSequenceClassifierOutput(\r\n",
        "            loss=loss,\r\n",
        "            logits=logits,\r\n",
        "            hidden_states=outputs.hidden_states,\r\n",
        "            attentions=outputs.attentions,\r\n",
        "        )\r\n",
        "\r\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification.serving_output\r\n",
        "    def serving_output(self, output):\r\n",
        "        hs = tf.convert_to_tensor(output.hidden_states) if self.config.output_hidden_states else None\r\n",
        "        attns = tf.convert_to_tensor(output.attentions) if self.config.output_attentions else None\r\n",
        "\r\n",
        "        return TFSequenceClassifierOutput(logits=output.logits, hidden_states=hs, attentions=attns)\r\n",
        "\r\n",
        "\r\n",
        "@add_start_docstrings(\r\n",
        "    \"\"\"\r\n",
        "    Roberta Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a\r\n",
        "    softmax) e.g. for RocStories/SWAG tasks.\r\n",
        "    \"\"\",\r\n",
        "    ROBERTA_START_DOCSTRING,\r\n",
        ")\r\n",
        "class TFRobertaForMultipleChoice(TFRobertaPreTrainedModel, TFMultipleChoiceLoss):\r\n",
        "    # names with a '.' represents the authorized unexpected/missing layers when a TF model is loaded from a PT model\r\n",
        "    _keys_to_ignore_on_load_unexpected = [r\"lm_head\"]\r\n",
        "    _keys_to_ignore_on_load_missing = [r\"dropout\"]\r\n",
        "\r\n",
        "    def __init__(self, config, *inputs, **kwargs):\r\n",
        "        super().__init__(config, *inputs, **kwargs)\r\n",
        "\r\n",
        "        self.roberta = TFRobertaMainLayer(config, name=\"roberta\")\r\n",
        "        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\r\n",
        "        self.classifier = tf.keras.layers.Dense(\r\n",
        "            1, kernel_initializer=get_initializer(config.initializer_range), name=\"classifier\"\r\n",
        "        )\r\n",
        "\r\n",
        "    @property\r\n",
        "    def dummy_inputs(self):\r\n",
        "        \"\"\"\r\n",
        "        Dummy inputs to build the network.\r\n",
        "        Returns:\r\n",
        "            tf.Tensor with dummy inputs\r\n",
        "        \"\"\"\r\n",
        "        return {\"input_ids\": tf.constant(MULTIPLE_CHOICE_DUMMY_INPUTS)}\r\n",
        "\r\n",
        "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, num_choices, sequence_length\"))\r\n",
        "    @add_code_sample_docstrings(\r\n",
        "        tokenizer_class=_TOKENIZER_FOR_DOC,\r\n",
        "        checkpoint=\"roberta-base\",\r\n",
        "        output_type=TFMultipleChoiceModelOutput,\r\n",
        "        config_class=_CONFIG_FOR_DOC,\r\n",
        "    )\r\n",
        "    def call(\r\n",
        "        self,\r\n",
        "        input_ids=None,\r\n",
        "        attention_mask=None,\r\n",
        "        token_type_ids=None,\r\n",
        "        position_ids=None,\r\n",
        "        head_mask=None,\r\n",
        "        inputs_embeds=None,\r\n",
        "        output_attentions=None,\r\n",
        "        output_hidden_states=None,\r\n",
        "        return_dict=None,\r\n",
        "        labels=None,\r\n",
        "        training=False,\r\n",
        "        **kwargs,\r\n",
        "    ):\r\n",
        "        r\"\"\"\r\n",
        "        labels (:obj:`tf.Tensor` of shape :obj:`(batch_size,)`, `optional`):\r\n",
        "            Labels for computing the multiple choice classification loss. Indices should be in ``[0, ...,\r\n",
        "            num_choices]`` where :obj:`num_choices` is the size of the second dimension of the input tensors. (See\r\n",
        "            :obj:`input_ids` above)\r\n",
        "        \"\"\"\r\n",
        "        inputs = input_processing(\r\n",
        "            func=self.call,\r\n",
        "            config=self.config,\r\n",
        "            input_ids=input_ids,\r\n",
        "            attention_mask=attention_mask,\r\n",
        "            token_type_ids=token_type_ids,\r\n",
        "            position_ids=position_ids,\r\n",
        "            head_mask=head_mask,\r\n",
        "            inputs_embeds=inputs_embeds,\r\n",
        "            output_attentions=output_attentions,\r\n",
        "            output_hidden_states=output_hidden_states,\r\n",
        "            return_dict=return_dict,\r\n",
        "            labels=labels,\r\n",
        "            training=training,\r\n",
        "            kwargs_call=kwargs,\r\n",
        "        )\r\n",
        "\r\n",
        "        if inputs[\"input_ids\"] is not None:\r\n",
        "            num_choices = shape_list(inputs[\"input_ids\"])[1]\r\n",
        "            seq_length = shape_list(inputs[\"input_ids\"])[2]\r\n",
        "        else:\r\n",
        "            num_choices = shape_list(inputs_embeds)[1]\r\n",
        "            seq_length = shape_list(inputs_embeds)[2]\r\n",
        "\r\n",
        "        flat_input_ids = tf.reshape(inputs[\"input_ids\"], (-1, seq_length)) if inputs[\"input_ids\"] is not None else None\r\n",
        "        flat_attention_mask = (\r\n",
        "            tf.reshape(inputs[\"attention_mask\"], (-1, seq_length)) if inputs[\"attention_mask\"] is not None else None\r\n",
        "        )\r\n",
        "        flat_token_type_ids = (\r\n",
        "            tf.reshape(inputs[\"token_type_ids\"], (-1, seq_length)) if inputs[\"token_type_ids\"] is not None else None\r\n",
        "        )\r\n",
        "        flat_position_ids = (\r\n",
        "            tf.reshape(inputs[\"position_ids\"], (-1, seq_length)) if inputs[\"position_ids\"] is not None else None\r\n",
        "        )\r\n",
        "        outputs = self.roberta(\r\n",
        "            flat_input_ids,\r\n",
        "            flat_attention_mask,\r\n",
        "            flat_token_type_ids,\r\n",
        "            flat_position_ids,\r\n",
        "            inputs[\"head_mask\"],\r\n",
        "            inputs[\"inputs_embeds\"],\r\n",
        "            inputs[\"output_attentions\"],\r\n",
        "            inputs[\"output_hidden_states\"],\r\n",
        "            return_dict=inputs[\"return_dict\"],\r\n",
        "            training=inputs[\"training\"],\r\n",
        "        )\r\n",
        "        pooled_output = outputs[1]\r\n",
        "        pooled_output = self.dropout(pooled_output, training=inputs[\"training\"])\r\n",
        "        logits = self.classifier(pooled_output)\r\n",
        "        reshaped_logits = tf.reshape(logits, (-1, num_choices))\r\n",
        "\r\n",
        "        loss = None if inputs[\"labels\"] is None else self.compute_loss(inputs[\"labels\"], reshaped_logits)\r\n",
        "\r\n",
        "        if not inputs[\"return_dict\"]:\r\n",
        "            output = (reshaped_logits,) + outputs[2:]\r\n",
        "            return ((loss,) + output) if loss is not None else output\r\n",
        "\r\n",
        "        return TFMultipleChoiceModelOutput(\r\n",
        "            loss=loss,\r\n",
        "            logits=reshaped_logits,\r\n",
        "            hidden_states=outputs.hidden_states,\r\n",
        "            attentions=outputs.attentions,\r\n",
        "        )\r\n",
        "\r\n",
        "    @tf.function(\r\n",
        "        input_signature=[\r\n",
        "            {\r\n",
        "                \"input_ids\": tf.TensorSpec((None, None, None), tf.int32, name=\"input_ids\"),\r\n",
        "                \"attention_mask\": tf.TensorSpec((None, None, None), tf.int32, name=\"attention_mask\"),\r\n",
        "            }\r\n",
        "        ]\r\n",
        "    )\r\n",
        "    def serving(self, inputs):\r\n",
        "        output = self.call(inputs)\r\n",
        "\r\n",
        "        return self.serving_output(output)\r\n",
        "\r\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertForMultipleChoice.serving_output\r\n",
        "    def serving_output(self, output):\r\n",
        "        hs = tf.convert_to_tensor(output.hidden_states) if self.config.output_hidden_states else None\r\n",
        "        attns = tf.convert_to_tensor(output.attentions) if self.config.output_attentions else None\r\n",
        "\r\n",
        "        return TFMultipleChoiceModelOutput(logits=output.logits, hidden_states=hs, attentions=attns)\r\n",
        "\r\n",
        "\r\n",
        "@add_start_docstrings(\r\n",
        "    \"\"\"\r\n",
        "    RoBERTa Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for\r\n",
        "    Named-Entity-Recognition (NER) tasks.\r\n",
        "    \"\"\",\r\n",
        "    ROBERTA_START_DOCSTRING,\r\n",
        ")\r\n",
        "class TFRobertaForTokenClassification(TFRobertaPreTrainedModel, TFTokenClassificationLoss):\r\n",
        "    # names with a '.' represents the authorized unexpected/missing layers when a TF model is loaded from a PT model\r\n",
        "    _keys_to_ignore_on_load_unexpected = [r\"pooler\", r\"lm_head\"]\r\n",
        "    _keys_to_ignore_on_load_missing = [r\"dropout\"]\r\n",
        "\r\n",
        "    def __init__(self, config, *inputs, **kwargs):\r\n",
        "        super().__init__(config, *inputs, **kwargs)\r\n",
        "        self.num_labels = config.num_labels\r\n",
        "\r\n",
        "        self.roberta = TFRobertaMainLayer(config, add_pooling_layer=False, name=\"roberta\")\r\n",
        "        self.dropout = tf.keras.layers.Dropout(config.hidden_dropout_prob)\r\n",
        "        self.classifier = tf.keras.layers.Dense(\r\n",
        "            config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"classifier\"\r\n",
        "        )\r\n",
        "\r\n",
        "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\r\n",
        "    @add_code_sample_docstrings(\r\n",
        "        tokenizer_class=_TOKENIZER_FOR_DOC,\r\n",
        "        checkpoint=\"roberta-base\",\r\n",
        "        output_type=TFTokenClassifierOutput,\r\n",
        "        config_class=_CONFIG_FOR_DOC,\r\n",
        "    )\r\n",
        "    def call(\r\n",
        "        self,\r\n",
        "        input_ids=None,\r\n",
        "        attention_mask=None,\r\n",
        "        token_type_ids=None,\r\n",
        "        position_ids=None,\r\n",
        "        head_mask=None,\r\n",
        "        inputs_embeds=None,\r\n",
        "        output_attentions=None,\r\n",
        "        output_hidden_states=None,\r\n",
        "        return_dict=None,\r\n",
        "        labels=None,\r\n",
        "        training=False,\r\n",
        "        **kwargs,\r\n",
        "    ):\r\n",
        "        r\"\"\"\r\n",
        "        labels (:obj:`tf.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\r\n",
        "            Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\r\n",
        "            1]``.\r\n",
        "        \"\"\"\r\n",
        "        inputs = input_processing(\r\n",
        "            func=self.call,\r\n",
        "            config=self.config,\r\n",
        "            input_ids=input_ids,\r\n",
        "            attention_mask=attention_mask,\r\n",
        "            token_type_ids=token_type_ids,\r\n",
        "            position_ids=position_ids,\r\n",
        "            head_mask=head_mask,\r\n",
        "            inputs_embeds=inputs_embeds,\r\n",
        "            output_attentions=output_attentions,\r\n",
        "            output_hidden_states=output_hidden_states,\r\n",
        "            return_dict=return_dict,\r\n",
        "            labels=labels,\r\n",
        "            training=training,\r\n",
        "            kwargs_call=kwargs,\r\n",
        "        )\r\n",
        "        outputs = self.roberta(\r\n",
        "            inputs[\"input_ids\"],\r\n",
        "            attention_mask=inputs[\"attention_mask\"],\r\n",
        "            token_type_ids=inputs[\"token_type_ids\"],\r\n",
        "            position_ids=inputs[\"position_ids\"],\r\n",
        "            head_mask=inputs[\"head_mask\"],\r\n",
        "            inputs_embeds=inputs[\"inputs_embeds\"],\r\n",
        "            output_attentions=inputs[\"output_attentions\"],\r\n",
        "            output_hidden_states=inputs[\"output_hidden_states\"],\r\n",
        "            return_dict=inputs[\"return_dict\"],\r\n",
        "            training=inputs[\"training\"],\r\n",
        "        )\r\n",
        "        sequence_output = outputs[0]\r\n",
        "\r\n",
        "        sequence_output = self.dropout(sequence_output, training=inputs[\"training\"])\r\n",
        "        logits = self.classifier(sequence_output)\r\n",
        "\r\n",
        "        loss = None if inputs[\"labels\"] is None else self.compute_loss(inputs[\"labels\"], logits)\r\n",
        "\r\n",
        "        if not inputs[\"return_dict\"]:\r\n",
        "            output = (logits,) + outputs[2:]\r\n",
        "            return ((loss,) + output) if loss is not None else output\r\n",
        "\r\n",
        "        return TFTokenClassifierOutput(\r\n",
        "            loss=loss,\r\n",
        "            logits=logits,\r\n",
        "            hidden_states=outputs.hidden_states,\r\n",
        "            attentions=outputs.attentions,\r\n",
        "        )\r\n",
        "\r\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertForTokenClassification.serving_output\r\n",
        "    def serving_output(self, output):\r\n",
        "        hs = tf.convert_to_tensor(output.hidden_states) if self.config.output_hidden_states else None\r\n",
        "        attns = tf.convert_to_tensor(output.attentions) if self.config.output_attentions else None\r\n",
        "\r\n",
        "        return TFTokenClassifierOutput(logits=output.logits, hidden_states=hs, attentions=attns)\r\n",
        "\r\n",
        "\r\n",
        "@add_start_docstrings(\r\n",
        "    \"\"\"\r\n",
        "    RoBERTa Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear\r\n",
        "    layers on top of the hidden-states output to compute `span start logits` and `span end logits`).\r\n",
        "    \"\"\",\r\n",
        "    ROBERTA_START_DOCSTRING,\r\n",
        ")\r\n",
        "class TFRobertaForQuestionAnswering(TFRobertaPreTrainedModel, TFQuestionAnsweringLoss):\r\n",
        "    # names with a '.' represents the authorized unexpected/missing layers when a TF model is loaded from a PT model\r\n",
        "    _keys_to_ignore_on_load_unexpected = [r\"pooler\", r\"lm_head\"]\r\n",
        "\r\n",
        "    def __init__(self, config, *inputs, **kwargs):\r\n",
        "        super().__init__(config, *inputs, **kwargs)\r\n",
        "        self.num_labels = config.num_labels\r\n",
        "\r\n",
        "        self.roberta = TFRobertaMainLayer(config, add_pooling_layer=False, name=\"roberta\")\r\n",
        "        self.qa_outputs = tf.keras.layers.Dense(\r\n",
        "            config.num_labels, kernel_initializer=get_initializer(config.initializer_range), name=\"qa_outputs\"\r\n",
        "        )\r\n",
        "\r\n",
        "    @add_start_docstrings_to_model_forward(ROBERTA_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\r\n",
        "    @add_code_sample_docstrings(\r\n",
        "        tokenizer_class=_TOKENIZER_FOR_DOC,\r\n",
        "        checkpoint=\"roberta-base\",\r\n",
        "        output_type=TFQuestionAnsweringModelOutput,\r\n",
        "        config_class=_CONFIG_FOR_DOC,\r\n",
        "    )\r\n",
        "    def call(\r\n",
        "        self,\r\n",
        "        input_ids=None,\r\n",
        "        attention_mask=None,\r\n",
        "        token_type_ids=None,\r\n",
        "        position_ids=None,\r\n",
        "        head_mask=None,\r\n",
        "        inputs_embeds=None,\r\n",
        "        output_attentions=None,\r\n",
        "        output_hidden_states=None,\r\n",
        "        return_dict=None,\r\n",
        "        start_positions=None,\r\n",
        "        end_positions=None,\r\n",
        "        training=False,\r\n",
        "        **kwargs,\r\n",
        "    ):\r\n",
        "        r\"\"\"\r\n",
        "        start_positions (:obj:`tf.Tensor` of shape :obj:`(batch_size,)`, `optional`):\r\n",
        "            Labels for position (index) of the start of the labelled span for computing the token classification loss.\r\n",
        "            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\r\n",
        "            sequence are not taken into account for computing the loss.\r\n",
        "        end_positions (:obj:`tf.Tensor` of shape :obj:`(batch_size,)`, `optional`):\r\n",
        "            Labels for position (index) of the end of the labelled span for computing the token classification loss.\r\n",
        "            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\r\n",
        "            sequence are not taken into account for computing the loss.\r\n",
        "        \"\"\"\r\n",
        "        inputs = input_processing(\r\n",
        "            func=self.call,\r\n",
        "            config=self.config,\r\n",
        "            input_ids=input_ids,\r\n",
        "            attention_mask=attention_mask,\r\n",
        "            token_type_ids=token_type_ids,\r\n",
        "            position_ids=position_ids,\r\n",
        "            head_mask=head_mask,\r\n",
        "            inputs_embeds=inputs_embeds,\r\n",
        "            output_attentions=output_attentions,\r\n",
        "            output_hidden_states=output_hidden_states,\r\n",
        "            return_dict=return_dict,\r\n",
        "            start_positions=start_positions,\r\n",
        "            end_positions=end_positions,\r\n",
        "            training=training,\r\n",
        "            kwargs_call=kwargs,\r\n",
        "        )\r\n",
        "        outputs = self.roberta(\r\n",
        "            inputs[\"input_ids\"],\r\n",
        "            attention_mask=inputs[\"attention_mask\"],\r\n",
        "            token_type_ids=inputs[\"token_type_ids\"],\r\n",
        "            position_ids=inputs[\"position_ids\"],\r\n",
        "            head_mask=inputs[\"head_mask\"],\r\n",
        "            inputs_embeds=inputs[\"inputs_embeds\"],\r\n",
        "            output_attentions=inputs[\"output_attentions\"],\r\n",
        "            output_hidden_states=inputs[\"output_hidden_states\"],\r\n",
        "            return_dict=inputs[\"return_dict\"],\r\n",
        "            training=inputs[\"training\"],\r\n",
        "        )\r\n",
        "        sequence_output = outputs[0]\r\n",
        "\r\n",
        "        logits = self.qa_outputs(sequence_output)\r\n",
        "        start_logits, end_logits = tf.split(logits, 2, axis=-1)\r\n",
        "        start_logits = tf.squeeze(start_logits, axis=-1)\r\n",
        "        end_logits = tf.squeeze(end_logits, axis=-1)\r\n",
        "\r\n",
        "        loss = None\r\n",
        "        if inputs[\"start_positions\"] is not None and inputs[\"end_positions\"] is not None:\r\n",
        "            labels = {\"start_position\": inputs[\"start_positions\"]}\r\n",
        "            labels[\"end_position\"] = inputs[\"end_positions\"]\r\n",
        "            loss = self.compute_loss(labels, (start_logits, end_logits))\r\n",
        "\r\n",
        "        if not inputs[\"return_dict\"]:\r\n",
        "            output = (start_logits, end_logits) + outputs[2:]\r\n",
        "            return ((loss,) + output) if loss is not None else output\r\n",
        "\r\n",
        "        return TFQuestionAnsweringModelOutput(\r\n",
        "            loss=loss,\r\n",
        "            start_logits=start_logits,\r\n",
        "            end_logits=end_logits,\r\n",
        "            hidden_states=outputs.hidden_states,\r\n",
        "            attentions=outputs.attentions,\r\n",
        "        )\r\n",
        "\r\n",
        "    # Copied from transformers.models.bert.modeling_tf_bert.TFBertForQuestionAnswering.serving_output\r\n",
        "    def serving_output(self, output):\r\n",
        "        hs = tf.convert_to_tensor(output.hidden_states) if self.config.output_hidden_states else None\r\n",
        "        attns = tf.convert_to_tensor(output.attentions) if self.config.output_attentions else None\r\n",
        "\r\n",
        "        return TFQuestionAnsweringModelOutput(\r\n",
        "            start_logits=output.start_logits, end_logits=output.end_logits, hidden_states=hs, attentions=attns\r\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwY6hwRequwH"
      },
      "source": [
        "#### Static Exec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSoNibT-k8fb"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import math\r\n",
        "import transformers\r\n",
        "from transformers import BertConfig, RobertaConfig\r\n",
        "from datasets import load_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385,
          "referenced_widgets": [
            "568322d56fb64758a5ecf8c6d8786cc8",
            "c321328f0b2e40978237638f26c151a5",
            "16ddcb359e7b4295910bccff5c61f335",
            "7217f962054842799d48b6b558996053",
            "8b499effc4914a7db2a943ef40945768",
            "94ddbe80ba0041209301cf506593c441",
            "08fafe75321045279e6c70b06052a81b",
            "6bac16ec0e1d46688ba31bcd81202dd7",
            "c197461d1ff449ceb6f179452110b144",
            "e2d2bfde68294103b752104e3f38097a",
            "60eeca88fb6647cda5e42bb12a2178b7",
            "702df702f21a4c4e8e50e3be7f715c6e",
            "88c3b9a1c5d44212a5e289c913fb49e2",
            "d9c6c575ce7245b6987b3ea84ab470a1",
            "19ef250902e54880a5059a4e89124c67",
            "8bc630b2bf3441ccaa3945156c66f6c3",
            "b5bd0e32b99743508baa38a048374ab4",
            "57b613711bf14e87afe277b156fe5178",
            "ed5a35ae95744dfe8c8eb1acf468f976",
            "ae5822b03a794e0e915b7dfa525e821c",
            "3ee47c744b1d4b31be1a47b5bf84ebec",
            "37670b532a3c4e8b8d12062bac375d95",
            "993bad1ce23b4b81a7dda9e6252d1eb5",
            "d0f2347a456f40ae80291e27bff8eff2",
            "2db23a2814474cafae655348e4ed5108",
            "aafde8d1f7d24e649e6c08124f6165c5",
            "9e611828f721498e86da2c50793f26d1",
            "4aa41639b5f2425593a96b48fdba9845",
            "1bb64d0a991545499216867caee3ccff",
            "68e49526016b44919f91300161fafbb8",
            "35e1649ba23a4cb8ae6f51bb942a5a20",
            "d06e37f3a45e45239d1134b2872afd8f",
            "ef09d7c9ca0441779ad44e3dfd54bbca",
            "dcf45aad48cb48319c5acae2dddb1988",
            "b55aff28610e484892c41d45b04f3b89",
            "e12ac23fd6434e60b428eaa415f6ec50",
            "718a4b616e444f0dbe69cdbc57571568",
            "6e4fa47a6f0b4d7ca3535ba0d11dbc82",
            "e8aedd780d064644a38b0072590788cb",
            "d9368b07041545daa76d7c9a2a8b8deb",
            "a0fa85e402a34724bd541535e58c80c0",
            "6d4251ed6fbc4c188593697a57230847",
            "8019e8b59a8f4909bf8895af95ea8ef2",
            "5f415b97c5504a96ab043fd1c25d24da",
            "ba5a2e7351ef4f62ad0f5b1df814c275",
            "3658d96f6e164ad29cdceea61051a9a7",
            "6088f03a11574df6817ca1ed2ff6bcf1",
            "f88961e613df46c9b87828cbbd20ee18",
            "e4f80d88ef564cd09713001d81934760",
            "8a282c3590ba4cbfb14398e2a866e3ad",
            "2645ba4a104347eab7a844cd296539fd",
            "a9b4289851a94b0bb80f3dd252808335",
            "3e5c53175d5749c9ae56ab85370f9045",
            "475a27b6d1a24d9ca27f77894ef8a647",
            "4a4eed4ad781483cb58127dfcc98252a",
            "22c98f8644a5466e89f2a17e1123080d",
            "d18ae16c5bbd4c379f828edaa9b1e90f",
            "02e4f4f9aa03476ea682a68a93d8879a",
            "f8c23830bac64699ad05f0477b98dfd0",
            "af9965a753f24379b5bbb4ac104ce212",
            "05ac339a51b54f5e85ad8ed6941b7d46",
            "f22c1ff2783741098b863f0f7b2e09dc",
            "46f8933245c74a20b3c8c526f1e03023",
            "61be8844dbff4cceb124a5564006d9d4",
            "b483d61fb0c54cb7842aa53d39691ed5",
            "acad8bd5b50f45d8bb17e22c5f2e8299",
            "a7f22a5b22f34be0bcb177cf4d25b62f",
            "7816db73e742409c846ed6ecc171a6ff",
            "57c1fd09f3ea4fb58ebc630e45a61ba7",
            "b7de8697aeba425d838903bdf3da17a6",
            "56f78d3a6c014dbbb832246e648a8f9a",
            "38355d10c07d4936b4f55fd977d6b1bc"
          ]
        },
        "id": "j_fIK9Djk934",
        "outputId": "65858860-df06-4ad0-b9b5-d95bd600c721"
      },
      "source": [
        "train_ds = load_dataset('c3', 'mixed', split='train')\r\n",
        "\r\n",
        "print(\"Example: \", next(iter(train_ds)))\r\n",
        "\r\n",
        "def prepare_dict(example):\r\n",
        "    example[\"text\"] = example[\"documents\"][0]\r\n",
        "    return example\r\n",
        "\r\n",
        "train_ds = train_ds.map(prepare_dict)\r\n",
        "#train_ds = train_ds.select(range(10)) # Small sample size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "568322d56fb64758a5ecf8c6d8786cc8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2491.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c197461d1ff449ceb6f179452110b144",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1798.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading and preparing dataset c3/mixed (download: 5.23 MiB, generated: 4.30 MiB, post-processed: Unknown size, total: 9.53 MiB) to /root/.cache/huggingface/datasets/c3/mixed/1.0.0/6bcfb26ae1bd77bd57d300c2504900834cc29aaa092eb87c4d91d7960a3c2d8c...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5bd0e32b99743508baa38a048374ab4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1153662.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2db23a2814474cafae655348e4ed5108",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=381112.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef09d7c9ca0441779ad44e3dfd54bbca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=390071.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0fa85e402a34724bd541535e58c80c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4f80d88ef564cd09713001d81934760",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d18ae16c5bbd4c379f828edaa9b1e90f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset c3 downloaded and prepared to /root/.cache/huggingface/datasets/c3/mixed/1.0.0/6bcfb26ae1bd77bd57d300c2504900834cc29aaa092eb87c4d91d7960a3c2d8c. Subsequent calls will reuse this data.\n",
            "Example:  {'document_id': 'm13-70', 'documents': ['许多动物的某些器官感觉特别灵敏，它们能比人类提前知道一些灾害事件的发生，例如，海洋中的水母能预报风暴，老鼠能事先躲避矿井崩塌或有害气体，等等。地震往往能使一些动物的某些感觉器官受到刺激而发生异常反应。如一个地区的重力发生变异，某些动物可能通过它们的平衡器官感觉到；一种振动异常，某些动物的听觉器官也许能够察觉出来。地震前地下岩层早已在逐日缓慢活动，而断层面之间又具有强大的摩擦力。这种摩擦力会产生一种低于人的听觉所能感觉到的低频声波。人对每秒20次以上的声波才能感觉到，而动物则不然。那些感觉十分灵敏的动物，在感触到这种低声波时，便会惊恐万状，以至出现冬蛇出洞、鱼跃水面等异常现象。'], 'questions': {'answer': ['比人的灵敏', '水母', '20次以上', '害怕'], 'choice': [['没有人的灵敏', '和人的差不多', '和人的一样好', '比人的灵敏'], ['蛇', '老鼠', '水母', '鱼'], ['20次', '20次以上', '20次以下', '以上都对'], ['兴奋', '逃跑', '跳跃', '害怕']], 'question': ['动物的器官感觉与人的相比有什么不同?', '录音中提到能预报风暴的动物是什么?', '低频声波至少要达到每秒多少次才能被人感觉到?', '动物感觉到低频声波时会有怎样的表现?']}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b483d61fb0c54cb7842aa53d39691ed5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3138.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "21918dda4c7e47efa352821504fbae13",
            "57fef615ca9547fd97f8b897014006c1",
            "a579ef37937545ff8d635340e3cf0c90",
            "8c670412622a4b46896a8a8ef5f32578",
            "d1ed8f2b1ce642549fa245b0295a243c",
            "4393b5ab57104262a99312eb5c6fe3e3",
            "7ca9773aa9f94e258f9d463e7e5d9598",
            "c276c070caa14c69a1cebef75a18ca7c",
            "057c9a87a44a49299776c7868af8d183",
            "b23ae96d04e0452389c7b01ba3713f0e",
            "951493546e0c4323a7b56f5addc0bb86",
            "3279160bbaa141529ae23c90b1e0cbe5",
            "fbe7712db72845f6ae57bc3ac3a59044",
            "f32008f9e04b43408aabeed7f921bb0a",
            "494f16ccf18f436c8512f45494f1c6af",
            "9d3579f3106f40a5bfb76808f5256287",
            "6f4da41b4b5744da913ff07a24d72f3b",
            "6233ecdbb1a9445b8186fe046a63864d",
            "5d313110761b4bbdb25f4d0113338253",
            "2e16a035d2194664af1f253e0853d0ca",
            "af0084681d5f42ba8374c2e0b9b75c15",
            "5436a00c2faf40d295057c5ea0bccb64",
            "47100ecd5e48476fb1c4e77b4a070454",
            "2fabfd0d6ce14dd5b60b10bba9acfaf7",
            "9962520077da4aecb473a36ec48ed99d",
            "c1396643605643449373a1f556d75a60",
            "03db9554d4c14282ac7549d8475ae167",
            "092303ffa2be4c3bad630a0a1bdf1203",
            "a77adb7390bf48ddbc28542790ba95a5",
            "0a6a143447cc4559887bdad2efb248e5",
            "8eee2f7d988541aaae3a9638f6db6970",
            "5369bb8eb859478f86ba12fcb66a1ae6",
            "d3273f1da65e432f9d9dcf93e14a07dc",
            "b253d683e9834c458804fab249a10d96",
            "903596cf4f9940f4b14a4277d0312b8d",
            "369fba7e21814c4f87b773518ad2fea1",
            "70f8eb70939444dd8a34b7c9db6aefaa",
            "1147ec61e02a4faa92033e8ef623af23",
            "e49d9a21b1d842ecae8c60ff0fe47826",
            "718e818c54d14271adbf3f3c8566308c"
          ]
        },
        "id": "VTnu-H4hlCuT",
        "outputId": "679dcd73-fe0b-4bca-99a6-81c93504be76"
      },
      "source": [
        "tokenizer = WWMTokenizer(col=\"text\", seq_len=512)\r\n",
        "\r\n",
        "train_ds = train_ds.map(tokenizer.tokenize_pretraining)\r\n",
        "\r\n",
        "train_ds = tokenizer.to_tf_dataset(train_ds)\r\n",
        "\r\n",
        "train_ds = train_ds.shuffle(1000).batch(1)\r\n",
        "\r\n",
        "print(\"Example: \", next(iter(train_ds)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21918dda4c7e47efa352821504fbae13",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=624.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "057c9a87a44a49299776c7868af8d183",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f4da41b4b5744da913ff07a24d72f3b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=268943.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9962520077da4aecb473a36ec48ed99d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=164437832.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3273f1da65e432f9d9dcf93e14a07dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=3138.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Example:  {'input_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
            "array([[  101,  3300,   671,  1921,  8024,   678,  4708,  7433,  8024,\n",
            "         2769,  2828,  6756,   977,  1762,  7716, 19719,  3178, 19861,\n",
            "         5023,  2571, 19263,   678, 17465,  4638,   103, 14408,   103,\n",
            "          103, 16255,  3633, 16278,  7353, 19875,  4638,   103,  2792,\n",
            "         2207, 15167,  3123, 15167,  4638,  3198, 20370,  8024,   103,\n",
            "          103,  2111, 15151,  4959,   103,  7433, 19189,   510,  2802,\n",
            "         4708,  7433, 13892,   103,  7770, 20827, 14126, 14126,  1765,\n",
            "          794,  2110, 16470,  7027,  6624,  1139, 16398,   511,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]],\n",
            "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0]], dtype=int32)>, 'lm_label_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
            "array([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  3301, 14408,   511,\n",
            "         6821, 16255,  -100,  -100,  -100,  -100,  -100,   671,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  2523,\n",
            "        14971,  -100,  -100,  -100,  4708,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  8024,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]],\n",
            "      dtype=int32)>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiFynjJdti2L"
      },
      "source": [
        "### Modelling - Static ###\r\n",
        "\r\n",
        "class Wrapper(tf.keras.Model):\r\n",
        "    def __init__(self, model, *args, **kwargs):\r\n",
        "        super().__init__(*args, **kwargs)\r\n",
        "        self.model = model\r\n",
        "        # Track loss (Loss itself its CategoricalCrossEnt.)\r\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name='loss') \r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def train_step(self, data):\r\n",
        "        # Data is a dictionary\r\n",
        "        y = data[\"lm_label_ids\"]\r\n",
        "        x = data\r\n",
        "\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            # Forward pass\r\n",
        "            y_pred = self.model(x, training=True)\r\n",
        "            # Compute the loss value.\r\n",
        "            y_pred = y_pred.logits\r\n",
        "            loss = self.compute_loss(y, y_pred)\r\n",
        "            # Reduce loss to single digit\r\n",
        "            loss = tf.reduce_mean(loss)\r\n",
        "\r\n",
        "        # Compute gradients\r\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\r\n",
        "        # Update weights\r\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n",
        "        # Update loss tracker\r\n",
        "        self.loss_tracker.update_state(loss)  \r\n",
        "        # Update metrics\r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "    def test_step(self, data):\r\n",
        "        # Data is a dictionary\r\n",
        "        y = data[\"lm_label_ids\"]\r\n",
        "        x = data\r\n",
        "\r\n",
        "        # Compute predictions\r\n",
        "        y_pred = self.model(x, training=False)\r\n",
        "        y_pred = y_pred.logits\r\n",
        "        loss = self.compute_loss(y, y_pred)\r\n",
        "\r\n",
        "        # Updates the metrics tracking the loss\r\n",
        "        self.loss_tracker.update_state(loss)  \r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "    def compute_loss(self, labels, logits):\r\n",
        "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "            from_logits=True, reduction=tf.keras.losses.Reduction.NONE\r\n",
        "        )\r\n",
        "        # make sure only labels that are not equal to -100 do affect loss\r\n",
        "        active_loss = tf.not_equal(tf.reshape(labels, (-1,)), -100)\r\n",
        "        reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[2])), active_loss)\r\n",
        "        labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\r\n",
        "\r\n",
        "        return loss_fn(labels, reduced_logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1Y_ThCyt4uK"
      },
      "source": [
        "def shape_list(tensor: tf.Tensor):\r\n",
        "    \"\"\"\r\n",
        "    Deal with dynamic shape in tensorflow cleanly.\r\n",
        "    Args:\r\n",
        "        tensor (:obj:`tf.Tensor`): The tensor we want the shape of.\r\n",
        "    Returns:\r\n",
        "        :obj:`List[int]`: The shape of the tensor as a list.\r\n",
        "\r\n",
        "    ### TODO: Move to compute_loss\r\n",
        "    \"\"\"\r\n",
        "    dynamic = tf.shape(tensor)\r\n",
        "\r\n",
        "    if tensor.shape == tf.TensorShape(None):\r\n",
        "        return dynamic\r\n",
        "\r\n",
        "    static = tensor.shape.as_list()\r\n",
        "\r\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNDKjcVKt-_h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "c475871932b445bfb429dc9717ec8b09",
            "1e93243c3eef4c0190f68e064a06552c",
            "817d82183113409b90656ee9587b897a",
            "2e8bfbf265e441eca19fa4241bbedf40",
            "dbd029a116e748febd6484e562be5d4c",
            "beaf0858ba19499cbe27930d4ab4a51d",
            "3bb04dbe3e4a4d9185ad1c6cfd2a40cc",
            "b85b3a1d41164996a3ab423c48577d58"
          ]
        },
        "outputId": "8b67f930-2483-4bd5-feed-49b49eb905e8"
      },
      "source": [
        "config = RobertaConfig.from_pretrained(\"roberta-base\")    #(\"bert-base-chinese\")\r\n",
        "config.performer = True\r\n",
        "base_model = TFRobertaForMaskedLM(config)\r\n",
        "model = Wrapper(base_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c475871932b445bfb429dc9717ec8b09",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eM3TrmLlYmA",
        "outputId": "a462bebe-0731-463d-a4f0-3a7ba59fe5cf"
      },
      "source": [
        "### Modelling - Static ###\r\n",
        "\r\n",
        "# Use tensorboard for evaluation if multiple epochs\r\n",
        "from datetime import datetime\r\n",
        "%load_ext tensorboard\r\n",
        "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\r\n",
        "\r\n",
        "# \"Friendlier\" metric as only looks whether ground truth is in models top 5 preds\r\n",
        "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')]\r\n",
        "\r\n",
        "learning_rate = 1e-5\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\r\n",
        "\r\n",
        "model.compile(optimizer=optimizer, metrics=metrics)\r\n",
        "\r\n",
        "model.fit(train_ds, epochs=10, callbacks=[tensorboard_callback])\r\n",
        "\r\n",
        "#TYPES: <class 'tensorflow.python.framework.ops.Tensor'> <class 'tensorflow.python.framework.ops.Tensor'>"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3138/3138 [==============================] - 290s 84ms/step - accuracy: 0.0329 - loss: 7.1358\n",
            "Epoch 2/10\n",
            "3138/3138 [==============================] - 271s 83ms/step - accuracy: 0.0216 - loss: 6.4045\n",
            "Epoch 3/10\n",
            "3138/3138 [==============================] - 271s 83ms/step - accuracy: 0.0130 - loss: 6.1632\n",
            "Epoch 4/10\n",
            "3138/3138 [==============================] - 271s 83ms/step - accuracy: 0.0196 - loss: 5.9907\n",
            "Epoch 5/10\n",
            "3138/3138 [==============================] - 271s 83ms/step - accuracy: 0.0403 - loss: 5.8535\n",
            "Epoch 6/10\n",
            "3138/3138 [==============================] - 270s 83ms/step - accuracy: 0.0526 - loss: 5.7346\n",
            "Epoch 7/10\n",
            "3138/3138 [==============================] - 270s 83ms/step - accuracy: 0.0949 - loss: 5.6222\n",
            "Epoch 8/10\n",
            "3138/3138 [==============================] - 270s 83ms/step - accuracy: 0.0195 - loss: 5.5201\n",
            "Epoch 9/10\n",
            "3138/3138 [==============================] - 268s 82ms/step - accuracy: 0.0183 - loss: 5.4165\n",
            "Epoch 10/10\n",
            "3138/3138 [==============================] - 267s 82ms/step - accuracy: 0.0153 - loss: 5.3264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f676b55cd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrRexMN9lhie",
        "outputId": "8dcbb67b-e069-4583-9ee6-095f603fd3b7"
      },
      "source": [
        "### Evaluation ###\r\n",
        "\r\n",
        "example = next(iter(train_ds)) \r\n",
        "input_ids = example[\"input_ids\"]\r\n",
        "\r\n",
        "print(\"Inputs: \", tokenizer.tokenizer_cn.decode(input_ids.numpy()[0]))\r\n",
        "\r\n",
        "logits = model.model.predict(example).logits\r\n",
        "\r\n",
        "tensor = tf.math.argmax(\r\n",
        "              logits, axis=-1, output_type=tf.dtypes.int64, name=None\r\n",
        "          )\r\n",
        "\r\n",
        "preds = tokenizer.tokenizer_cn.decode(tensor[0])\r\n",
        "\r\n",
        "print(\"Preds: \", preds)\r\n",
        "\r\n",
        "# [PAD] are not predicted for \r\n",
        "x = tf.where(example[\"lm_label_ids\"][0] > 0, example[\"lm_label_ids\"][0], 0)\r\n",
        "print(\"Solutions:\",tokenizer.tokenizer_cn.decode(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs:  [CLS] 人才 其实 [MASK]攤 分为 两 [MASK] ： 一 类 是 自 [MASK] 之 才 ， 另 一 类 是 被用 [MASK] 才 。 少数 [MASK] 属于 自用 之 才 ， 这种 人 大多 可以 成为 [MASK]轿 ， [MASK]洋 善于 扬长避短 ， 能 独立 创建 一个 自己 [MASK] [MASK]sn ； 多数 人 都 是 被用 之 才 ， 需要 借助 别人 的 舞台 来 唱戏 [MASK] 能否 成功 取决于 有 没 有 [MASK]合 他 的 舞台 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "Preds:  还 人才 其实 不以 分为 两 ， ： 一 类 是 自 ， 之 才 ， 另 一 类 是 被用 ， 才 。 少数 ， 属于 自用 之 才 ， 这种 人 大多 可以 成为 ， 我 ， ，们 善于 也长 还 有 ， 能 不活 创 他 一个 自己 的 ，们 ； 多数 人 都 是 被用 之 才 ， 需要 得助 别人 的 我 [UNK] 来 唱儿 。 能否 成功 取 。于 有 没 有 的合 他 的 我台 。 。 ， 的 ， 的 了 ， ， ， 的 [UNK] 一 ， ， 出 ， [UNK]到 我 的 ， ， 不子 。 ， ， 。 的 ， ， 了 ， 我 了 ， 一 ， 一 ， ， 就 ， ， 的 不 一 是 ， 的 的 去 了 的 ， ， ， 。 的 人 ， 的 ， ， ， ， 的 ， 有 ， ， ， 的 的 ， ， ， 。 ， ， 说 ， ， 的 的 ， ， 。 在 不 ， ， 不 ， 的 ， 一 ， ， 不 ， ， 不 ， 的 ， 的 ， 的 他 。 的 的 ， ， 了 ， ， ， ， 的 是 ， ， 一 ， ， ， ， 的 不 ， ， ， ， 一 ， 一 的 我 ， ， ， ， 一 [UNK] ， ， ， ， 的 的 一 ， ， 了 。 有 ， 是 我 ，子 ， 的 不 ， ， ， 。 ， ， 的 不 ， 。 的 ， ， ， ， ， ， 一 的 自 ， ， 的 的 。 ， 。 。 的 了 。 ， [UNK] 的 的 [UNK] 一 ， ， 不 在 的 的 ， ， ， ， 的 了 ， 。 的 不 我 的 。 不 ， 的 的 ， 的 在 ， 。 了 就 ， ， 我 。 ， 了 我 ， ， 。 了 ， 一 是 的 。 的 不 ， 是 在 ， 的 ， ， 一 了 不 ， ， 我 ， 的 有 ， ， 了 ， ， 有 我 ， ， 。 。 。 。 我 一 ， ， ， 是 在 。 的 我 ， ， ， 一 不 我 ， ， ， ， 的 我 的 。 ， 不 ， ， 。 ， ， ， 。 自 ， 在 ， ， ， 。 ， ， 就 的 。 ， 的 。 ， 。 在 ， 。 ， ， 是 ， ， 的 ， 。 是 。 ， [UNK] 了 了 的 大 的 。 ， ， ， 。 的 去 的 我 。 。 的 ， 的 ， 的 我 是 的 。 ， ， ， 我 你 ， 的 。 一 。 了 ， 、 ， 的 ， 我 [UNK] ， ， 了 的 在 我 的 ， 我 的 就\n",
            "Solutions: [PAD] [PAD] [PAD] [PAD] [PAD] 可以 [PAD] [PAD] [PAD] 类 [PAD] [PAD] [PAD] [PAD] 自用 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 之 [PAD] [PAD] [PAD] [PAD] 人 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 老板 [PAD] 他们 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 的 舞台 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] ， [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 适合 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_f9LsrRENXE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}