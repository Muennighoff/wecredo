{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ClueCloud_Perf.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzaNBthJ_P1e"
      },
      "source": [
        "##### If TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-40rjaD_PFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1767972-a220-4912-e96d-5cebb180ab66"
      },
      "source": [
        "# If this cell takes very long to run; factory reset and run this cell the very first\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "tf.keras.backend.clear_session()\r\n",
        "\r\n",
        "try:\r\n",
        "    # Locate TPU\r\n",
        "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\r\n",
        "    # Establish communication / Locates TPU on the network\r\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER)\r\n",
        "    # Connect\r\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\r\n",
        "    # Start TPU\r\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\r\n",
        "    # Set strategy\r\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(resolver)\r\n",
        "\r\n",
        "    print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\r\n",
        "\r\n",
        "except ValueError:\r\n",
        "    print(\"No TPU found\")\r\n",
        "\r\n",
        "# Check devices\r\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.114.242.210:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.114.242.210:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of accelerators:  8\n",
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBuflW94Doku"
      },
      "source": [
        "##### Setup Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQpLNMiNDfbL",
        "outputId": "56685db5-1f59-43ee-fdd3-c222b8b2512c"
      },
      "source": [
        "!git clone https://github.com/Muennighoff/cn_performer\r\n",
        "%cd cn_performer\r\n",
        "!pip3 install -q -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cn_performer'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 63 (delta 17), reused 55 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n",
            "/content/cn_performer\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 6.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 5.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 19.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 53.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 44.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 44.8MB/s \n",
            "\u001b[?25h  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etG39du5ZCNF"
      },
      "source": [
        "##### Download Data - Only if preprocess locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NULT3DewYsm6"
      },
      "source": [
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "!gcloud init"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j30-1zVXZK7T",
        "outputId": "3eb1a9a6-3ab9-450d-e200-a212944244d4"
      },
      "source": [
        "# 4 Files to speed up\r\n",
        "!mkdir ./data/\r\n",
        "!gsutil cp gs://clue-corpus2020/CLUECorpus2020/train_clue_pretrain_train_0000.zip ./data/\r\n",
        "!gsutil cp gs://clue-corpus2020/CLUECorpus2020/train_clue_pretrain_train_0001.zip ./data/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./data/’: File exists\n",
            "Copying gs://clue-corpus2020/CLUECorpus2020/train_clue_pretrain_train_0000.zip...\n",
            "/\n",
            "Operation completed over 1 objects/1.0 GiB.                                      \n",
            "Copying gs://clue-corpus2020/CLUECorpus2020/train_clue_pretrain_train_0001.zip...\n",
            "- [1 files][  1.0 GiB/  1.0 GiB]   40.1 MiB/s                                   \n",
            "Operation completed over 1 objects/1.0 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5XqZJddiv2V"
      },
      "source": [
        "!du -sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71UA9GRHi0kW"
      },
      "source": [
        "!unzip ./data/*1.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FVY545yZFuZ"
      },
      "source": [
        "##### Prepare Data - Only if preprocess locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3aXQWCpIjUC",
        "outputId": "9143623f-ff23-4a12-82f7-9ae616c12a6e"
      },
      "source": [
        "#### Get current CKPT (i.e. how many files alrdy written)\r\n",
        "!gsutil cp gs://exp_niklas/tokenized/clue/checkpoint.txt ./clue_tokenized/"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://exp_niklas/tokenized/clue/checkpoint.txt...\n",
            "/ [1 files][    5.0 B/    5.0 B]                                                \n",
            "Operation completed over 1 objects/5.0 B.                                        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myh9WxgGfWT6"
      },
      "source": [
        "# Metadata\r\n",
        "dataset_path = \"data\"\r\n",
        "dataset_name = \"clue\"\r\n",
        "out_name = dataset_name + \"_tokenized\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06K3yH7ZTplf",
        "outputId": "623f67a1-03e9-473b-9161-7cc8260e460e"
      },
      "source": [
        "!cat clue_tokenized/processed*.txt"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/cn_performer/data/clue_pretrain_0000047.txt, /content/cn_performer/data/clue_pretrain_0000472.txt, /content/cn_performer/data/clue_pretrain_0000046.txt, /content/cn_performer/data/clue_pretrain_0000371.txt, "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gbwcgUEIVVV",
        "outputId": "f0ee5b54-b8f5-4426-9d1a-1ec8be00ecd4"
      },
      "source": [
        "# Launch tokenization & turning into .tfrecords\r\n",
        "!python data/create_tfrecords.py --processes 2 --files_per 1 --input_dir /content/cn_performer/$dataset_path --output_dir $out_name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-18 16:27:51.473887: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "Writing TFRecord Files to clue_tokenized. Parsed 0 input files. files_written : 0it [00:00, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1757507 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1718165 > 512). Running this sequence through the model will result in indexing errors\n",
            "Writing TFRecord Files to clue_tokenized. Parsed 3 input files. files_written : : 2417it [4:12:35,  6.23s/it]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdleXfpxEVT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43de2fd-8aea-475d-ca80-5ea592f2c0f3"
      },
      "source": [
        "# Put tokenized data into bucket\r\n",
        "\r\n",
        "path_to_cloud_bucket = 'gs://exp_niklas/tokenized/'\r\n",
        "\r\n",
        "copy_loc = path_to_cloud_bucket + dataset_name\r\n",
        "!gsutil cp -r /content/cn_performer/$out_name $copy_loc\r\n",
        "!gsutil ls $path_to_cloud_bucket\r\n",
        "!gsutil ls $copy_loc"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file:///content/cn_performer/clue_tokenized/clue_10_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_2_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_1_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_5_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "- [4 files][ 85.2 KiB/ 85.2 KiB]                                                \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_14_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_2_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_9_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_12_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_11_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_3_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_18_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_17_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_0_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_13_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_8_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_16_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_3_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_6_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_6_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_11_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_17_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_15_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_14_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_8_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_7_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_7_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_15_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_4_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_10_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_1_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_4_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/checkpoint.txt [Content-Type=text/plain]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_12_1_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/cn_performer/clue_tokenized/clue_5_0_1.tfrecords [Content-Type=application/octet-stream]...\n",
            "Caught CTRL-C (signal 2) - exiting\n",
            "^C\n",
            "gs://exp_niklas/tokenized/\n",
            "gs://exp_niklas/tokenized//\n",
            "gs://exp_niklas/tokenized/clue/\n",
            "gs://exp_niklas/tokenized/clue/checkpoint.txt\n",
            "gs://exp_niklas/tokenized/clue/clue_0_0_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_0_1_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_1_0_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_1_1_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_2_0_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_2_1_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_3_0_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_3_1_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_4_0_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_4_1_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_5_0_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_5_1_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_6_0_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_6_1_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_7_0_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_7_1_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_8_0_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_8_1_1000.tfrecords\n",
            "gs://exp_niklas/tokenized/clue/clue_tokenized/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0184eVWkEyTK"
      },
      "source": [
        "##### Read Data in from Cloud / Local"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjkYkB9JE-j-"
      },
      "source": [
        "# Load back in\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "\r\n",
        "def read_tfrecord(name, batch_size=8):\r\n",
        "    train_ds = tf.data.TFRecordDataset(name)\r\n",
        "\r\n",
        "    # Describe fts for successful decoding\r\n",
        "    txt_feature_description = {\r\n",
        "        'input_ids': tf.io.FixedLenFeature([2048], tf.int64, default_value=[0]*2048),\r\n",
        "        'labels': tf.io.FixedLenFeature([2048], tf.int64, default_value=[0]*2048),\r\n",
        "        #\"input_ids\": tf.io.VarLenFeature(tf.int64),\r\n",
        "        #\"labels\": tf.io.VarLenFeature(tf.int64)\r\n",
        "    }\r\n",
        "\r\n",
        "    def _parse_txt_function(example_proto):\r\n",
        "      return tf.io.parse_single_example(example_proto, txt_feature_description)\r\n",
        "\r\n",
        "    parsed_ds = train_ds.map(_parse_txt_function)\r\n",
        "\r\n",
        "    parsed_ds = parsed_ds.shuffle(1000).batch(batch_size)\r\n",
        "\r\n",
        "    return parsed_ds"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iorDWfYzNRN5"
      },
      "source": [
        "# Load 200MB Files from Cloud Bucket\r\n",
        "FILENAME_PATTERN = f\"gs://exp_niklas/clue_tokenized200/*.tfrecords\"\r\n",
        "#FILENAME_PATTERN = \"clue_tokenized/*\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCxRZKkFM5PB"
      },
      "source": [
        "filenames = tf.io.gfile.glob(FILENAME_PATTERN)\r\n",
        "train_ds = read_tfrecord(filenames, batch_size=8)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQPNAWEXFFG_"
      },
      "source": [
        "##### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf0DbX7AFi8x"
      },
      "source": [
        "!pip uninstall -q transformers -y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Ujf7fGFZVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de256951-e04c-4dff-8076-618860b830d8"
      },
      "source": [
        "!git clone https://github.com/Muennighoff/transformers.git\r\n",
        "!cd trans*; pip install -q -e '.[dev]'\r\n",
        "%cd transformers/src\r\n",
        "\r\n",
        "!pip install -q datasets\r\n",
        "\r\n",
        "import os\r\n",
        "import sys\r\n",
        "import tensorflow as tf\r\n",
        "from transformers import DistilBertPerformerConfig, TFDistilBertPerformerForMaskedLM\r\n",
        "\r\n",
        "%cd content/cn_performer"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 62411, done.\u001b[K\n",
            "remote: Total 62411 (delta 0), reused 0 (delta 0), pack-reused 62411\u001b[K\n",
            "Receiving objects: 100% (62411/62411), 47.54 MiB | 23.20 MiB/s, done.\n",
            "Resolving deltas: 100% (44190/44190), done.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 5.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 6.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.4MB 120kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 33.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 38.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 4.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 36.2MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 112kB 47.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2MB 39.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 52.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 13.4MB 39.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 491kB 46.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 54.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 4.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 64.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 10.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 8.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 7.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 8.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 14.5MB 30.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 747kB 45.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 38.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.7MB 95.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.4MB/s \n",
            "\u001b[?25h  Building wheel for black (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytest-forked 1.3.0 has requirement pytest>=3.10, but you'll have pytest 3.6.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytest-xdist 2.2.1 has requirement pytest>=6.0.0, but you'll have pytest 3.6.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: black 20.8b1 has requirement regex>=2020.1.8, but you'll have regex 2019.12.20 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imWchdqbFD1w"
      },
      "source": [
        "# Train\r\n",
        "\r\n",
        "def create_model():\r\n",
        "    \"\"\"\r\n",
        "    Creates Model\r\n",
        "    \"\"\"\r\n",
        "    config = DistilBertPerformerConfig()\r\n",
        "\r\n",
        "    print(\"PRE_CONF:\", config)\r\n",
        "\r\n",
        "    config.embedding_size = 2048\r\n",
        "    config.max_position_embeddings = 2048\r\n",
        "\r\n",
        "    config.vocab_size = 21128 # BERT CN Vocab only has 21128\r\n",
        "\r\n",
        "    print(\"POST_CONF:\", config)\r\n",
        "    \r\n",
        "    base_model = TFDistilBertPerformerForMaskedLM(config)\r\n",
        "    model = Wrapper(base_model)\r\n",
        "    return model\r\n",
        "\r\n",
        "### Modelling - Static ###\r\n",
        "\r\n",
        "class Wrapper(tf.keras.Model):\r\n",
        "    def __init__(self, model, *args, **kwargs):\r\n",
        "        super().__init__(*args, **kwargs)\r\n",
        "        self.model = model\r\n",
        "        # Track loss (Loss itself its CategoricalCrossEnt.)\r\n",
        "        self.loss_tracker = tf.keras.metrics.Mean(name='loss') \r\n",
        "\r\n",
        "    @tf.function\r\n",
        "    def train_step(self, data):\r\n",
        "        # Data is a dictionary\r\n",
        "        y = data[\"labels\"]\r\n",
        "        x = data\r\n",
        "\r\n",
        "        with tf.GradientTape() as tape:\r\n",
        "            # Forward pass\r\n",
        "            y_pred = self.model(x, training=True)\r\n",
        "            # Compute the loss value.\r\n",
        "            y_pred = y_pred.logits\r\n",
        "            loss = self.compute_loss(y, y_pred)\r\n",
        "            # Reduce loss to single digit\r\n",
        "            loss = tf.reduce_mean(loss)\r\n",
        "\r\n",
        "        # Compute gradients\r\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\r\n",
        "        # Update weights\r\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n",
        "        # Update loss tracker\r\n",
        "        self.loss_tracker.update_state(loss)  \r\n",
        "        # Update metrics\r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "    def test_step(self, data):\r\n",
        "        # Data is a dictionary\r\n",
        "        y = data[\"labels\"]\r\n",
        "        x = data\r\n",
        "\r\n",
        "        # Compute predictions\r\n",
        "        y_pred = self.model(x, training=False)\r\n",
        "        y_pred = y_pred.logits\r\n",
        "        loss = self.compute_loss(y, y_pred)\r\n",
        "\r\n",
        "        # Updates the metrics tracking the loss\r\n",
        "        self.loss_tracker.update_state(loss)  \r\n",
        "        self.compiled_metrics.update_state(y, y_pred)\r\n",
        "\r\n",
        "        return {m.name: m.result() for m in self.metrics}\r\n",
        "\r\n",
        "    def compute_loss(self, labels, logits):\r\n",
        "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "            from_logits=True, reduction=tf.keras.losses.Reduction.NONE\r\n",
        "        )\r\n",
        "        # make sure only labels that are not equal to -100 do affect loss\r\n",
        "        active_loss = tf.not_equal(tf.reshape(labels, (-1,)), -100)\r\n",
        "        reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[2])), active_loss)\r\n",
        "        labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\r\n",
        "\r\n",
        "        return loss_fn(labels, reduced_logits)\r\n",
        "        \r\n",
        "def shape_list(tensor: tf.Tensor):\r\n",
        "    \"\"\"\r\n",
        "    Deal with dynamic shape in tensorflow cleanly.\r\n",
        "    Args:\r\n",
        "        tensor (:obj:`tf.Tensor`): The tensor we want the shape of.\r\n",
        "    Returns:\r\n",
        "        :obj:`List[int]`: The shape of the tensor as a list.\r\n",
        "\r\n",
        "    ### TODO: Move to compute_loss\r\n",
        "    \"\"\"\r\n",
        "    dynamic = tf.shape(tensor)\r\n",
        "\r\n",
        "    if tensor.shape == tf.TensorShape(None):\r\n",
        "        return dynamic\r\n",
        "\r\n",
        "    static = tensor.shape.as_list()\r\n",
        "\r\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_cJ2zf15ZLFL",
        "outputId": "ff86e793-d369-4d9c-849f-2598dcc31637"
      },
      "source": [
        "with strategy.scope():\r\n",
        "  \r\n",
        "    model = create_model()\r\n",
        "\r\n",
        "    learning_rate = 1e-5\r\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate)\r\n",
        "    model.compile(optimizer=optimizer,\r\n",
        "                  metrics=['sparse_categorical_accuracy'])\r\n",
        "\r\n",
        "model.fit(train_ds,\r\n",
        "          epochs=5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PRE_CONF: DistilBertPerformerConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbertperformer\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"performer_attention_config\": {\n",
            "    \"attention_dropout\": 0.1,\n",
            "    \"causal\": false,\n",
            "    \"d_model\": 768,\n",
            "    \"feature_redraw_interval\": 100,\n",
            "    \"kernel_epsilon\": 0.0001,\n",
            "    \"kernel_type\": \"exp\",\n",
            "    \"linear_layer_names\": [\n",
            "      \"q_linear\",\n",
            "      \"k_linear\",\n",
            "      \"v_linear\",\n",
            "      \"out_linear\"\n",
            "    ],\n",
            "    \"normalization_stabilizer\": 1e-06,\n",
            "    \"normalize_output\": true,\n",
            "    \"num_heads\": 12,\n",
            "    \"num_random_features\": null,\n",
            "    \"orthogonal_feature_algorithm\": \"auto\",\n",
            "    \"redraw_stochastically\": false,\n",
            "    \"redraw_verbose\": false,\n",
            "    \"regularize_feature_norms\": true,\n",
            "    \"use_linear_layers\": true,\n",
            "    \"use_orthogonal_features\": true,\n",
            "    \"use_recurrent_decoding\": false,\n",
            "    \"use_thick_features\": false\n",
            "  },\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"transformers_version\": \"4.4.0.dev0\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "POST_CONF: DistilBertPerformerConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"embedding_size\": 2048,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 2048,\n",
            "  \"model_type\": \"distilbertperformer\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"performer_attention_config\": {\n",
            "    \"attention_dropout\": 0.1,\n",
            "    \"causal\": false,\n",
            "    \"d_model\": 768,\n",
            "    \"feature_redraw_interval\": 100,\n",
            "    \"kernel_epsilon\": 0.0001,\n",
            "    \"kernel_type\": \"exp\",\n",
            "    \"linear_layer_names\": [\n",
            "      \"q_linear\",\n",
            "      \"k_linear\",\n",
            "      \"v_linear\",\n",
            "      \"out_linear\"\n",
            "    ],\n",
            "    \"normalization_stabilizer\": 1e-06,\n",
            "    \"normalize_output\": true,\n",
            "    \"num_heads\": 12,\n",
            "    \"num_random_features\": null,\n",
            "    \"orthogonal_feature_algorithm\": \"auto\",\n",
            "    \"redraw_stochastically\": false,\n",
            "    \"redraw_verbose\": false,\n",
            "    \"regularize_feature_norms\": true,\n",
            "    \"use_linear_layers\": true,\n",
            "    \"use_orthogonal_features\": true,\n",
            "    \"use_recurrent_decoding\": false,\n",
            "    \"use_thick_features\": false\n",
            "  },\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"transformers_version\": \"4.4.0.dev0\",\n",
            "  \"vocab_size\": 21128\n",
            "}\n",
            "\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f4a7d02b6c8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f4a9a50f2a0> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f4a7d02b6c8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f4a9a50f2a0> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f4a7d02b6c8>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <cyfunction Socket.send at 0x7f4a9a50f2a0> is not a module, class, method, function, traceback, frame, or code object\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f4a982e5c80> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f4a982e5c80> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f4a982e5c80> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2452s 235ms/step - sparse_categorical_accuracy: 0.0157 - loss: 6.2256\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 2325s 232ms/step - sparse_categorical_accuracy: 0.0214 - loss: 5.9140\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 2322s 232ms/step - sparse_categorical_accuracy: 0.0215 - loss: 5.8568\n",
            "Epoch 4/5\n",
            " 5415/10000 [===============>..............] - ETA: 17:43 - sparse_categorical_accuracy: 0.0215 - loss: 5.8216"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9d2a394c3f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m model.fit(train_ds,\n\u001b[0;32m---> 11\u001b[0;31m           epochs=5)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lNMEJvNZSmb",
        "outputId": "2444836e-bfff-4b0b-8c84-544c37ad8f6a"
      },
      "source": [
        "### Evaluation ###\r\n",
        "\r\n",
        "from data.tokenization import Tokenizer\r\n",
        "\r\n",
        "example = next(iter(train_ds))\r\n",
        "input_ids = example[\"input_ids\"]\r\n",
        "\r\n",
        "tokenizer = Tokenizer()\r\n",
        "\r\n",
        "print(\"Inputs: \", tokenizer.tokenizer_cn.decode(input_ids.numpy()[0]))\r\n",
        "\r\n",
        "# Somehow model.model.predict returns None\r\n",
        "logits = model.model(example).logits\r\n",
        "\r\n",
        "tensor = tf.math.argmax(\r\n",
        "              logits, axis=-1, output_type=tf.dtypes.int64, name=None\r\n",
        "          )\r\n",
        "\r\n",
        "preds = tokenizer.tokenizer_cn.decode(tensor[0])\r\n",
        "\r\n",
        "print(\"Preds: \", preds)\r\n",
        "\r\n",
        "# [PAD] are not predicted for \r\n",
        "x = tf.where(example[\"labels\"][0] > 0, example[\"labels\"][0], 0)\r\n",
        "print(\"Solutions:\",tokenizer.tokenizer_cn.decode(x))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs:  [CLS] 特 点, 这 款 机 [MASK] 可 以 加 工 [MASK] 有 外 轮 廓, [MASK] 灵 活 快 速 地 制 作 通 孔 q2 [UNK] [MASK] 最 高 的 人 体 工 程 学 效 果 和 质 [MASK] 。 汽 [MASK] 工 业 生 产 热 成 型 零 件 [MASK] 旨 在 实 现 最 [MASK] 生 产 效 率 和 加 工 可 靠 性 。 [MASK] [MASK] [MASK] [MASK] 激 光 加 工 机 [MASK] [UNK] 可 满 足 这 [MASK] 要 求 和 在 例 如 连 续 [MASK] [MASK] 和 批 [MASK] [MASK] 产 中 切 割 [UNK] 柱 [MASK] 同 时, 当 部 件 [MASK] [MASK] 必 须 [MASK] 应 新 要 [MASK] 时, 设 [MASK] 足 够 灵 活 。 通 快 客 户 [MASK] 以 [MASK] 靠 各 种 各 样 的 机 床 尺 寸 [MASK] 为 每 个 要 求 [MASK] 工 艺 、 价 [MASK] ) 和 用 途玛 材 料 、 加 工 [MASK] 间 )鹅 到啻 适 的 系 统 [MASK] 通 快 整 个 机 床 组 合 的 多 样 性 和 技 术 状 [MASK] 在 市 场 上 独 [MASK] 坷 二 。 购 买 通 快 激 光 加 工 机 床 时, 客 户 [MASK] 以 选 择 各 [MASK] 光 [MASK], 其 范 围 比 竞 争 对 手 广 泛 得 多 。 与 我 叱 的 产 品 专 [MASK] 一 起, 根 据 要 求 和 待 加 工 材 [MASK] 决 定 哪 种 通 [MASK] 光 源 最 适 合 集 成 到 机 床 中 。 通 快 提 [MASK] 适 合 每 种 应 用 的 光 学 元 件 。 因 此, 可 以 在 [MASK] 床 中 [MASK] 用 聚 焦 [MASK] 头 、 智 能 可 编 程 振 镜 ( [MASK] 镜 头 ) 和 用 于 激 [MASK] [MASK] 属 熔 覆 的 适 配 器 。 通 快 传 感 系 统 可 [MASK] 保 激 光 加 工 过 程 的 最 佳 过 程 [MASK] 控 和 控 制 [MASK] 因 此 [MASK] [MASK] 户 可 以 从 显 [MASK] 提 高 的 加 工 [MASK] [MASK] 性 以 及 无 缝 记 录 和 可 追 溯 性 中 [MASK] [MASK] 。 这 [MASK] [MASK] 完 美 匹 配 \" 只 剩 下 三 个 问 题 : [MASK] 我 们 的 机 床 查 [MASK] 器 中, 您 只 需 向 我 们 提 供 关 于 [MASK] 需 流 程 [MASK] 加 工 空 间 和 自 [MASK] [MASK] 的 三 个 答 案 [UNK] [MASK] 您 [MASK] 会 获痿 最 [MASK] 合 您 [MASK] 求 的 机 床 的 第 一 个 建 [MASK] 。 马 上 尝 试 一 下! 大 [MASK] 加 工 空 间 的 尺 寸 [MASK] 超 过 4000x2000x750 [MASK] 。 此 类 空 间 用 于 [MASK] [MASK] 激 光 加 工 车 身 [MASK] 件 等 大 威 成 型 部 件 。 不 论 是 大 型 的 [MASK] 司, 还 是 小 型 的 公 司, 只 要 你 是 一 个 有 目 标, 有 理 想 的 公 司 [MASK] 那 么, 宣 传 对 于 你 这 个嫚 [MASK] 来 说 就 非 常 的 重 [MASK], [MASK] 其 是 在 今 [MASK]揖 业 [MASK] 越 来 越 多, 越 [MASK] 越 多 的 公 司 成 立 a9 中 国 这 片 土 地 上 面 [MASK] 公 司 与 公 司 间 的 竞 争 也 越 来 越 大, 这 个 时 候 你 再 不 加 大 宣 传 力 度, 那 [MASK], 你 的 公 [MASK] [MASK] 有 被 淘 [MASK] 的 份, 毕 竟 物 竞 天 择, 适 者 生 存 。 所 以 今 天 小 编 为 [MASK] 家 介 绍 和 关 [MASK] 宣 [MASK] 片 方 面 [MASK] 问 题 。 宣 传 片 不 用 我 说, 相 信 [MASK] 家 都 知 道 广 告 [MASK] [MASK] 起 到 一 个 很 [MASK] 的 宣 传 效 果 [MASK] 所 以, 公 司 [MASK] [MASK] 片 能 够 把 你 这 个 公 司 的 知 名 度 大 大 的 提 高, 那 么 什 么 [MASK] 的 公 司 宣 传 片 才 能 够 让睦 户 满 意, [MASK] 能 [MASK] 让 客 户 选 择 你 呢? 其 实 [MASK] 就 涉 [MASK] 到 一 个 成 语, [MASK] 个 [MASK] 语 就 是 [MASK] [MASK] 下 药, 想 [MASK] 让 客 户 选 择 [MASK] [MASK] 首 先 [MASK] 就 必 [MASK] 要 了 解 到 这 [MASK] 客 户 的 喜 [MASK], 天 下 [MASK] 有 [MASK] [MASK] 的 两 片 树 叶, 也 没 有 [MASK] 个 相 同 的 人, 所 以 不 同 的 人 有 着⒉ 同 的 喜 好, 都 是 需 要 你 去 [MASK] 解 的 。 其 次 就 是 中 国 是 一 个 地 大 物 博 的 国 家, 有 很 多 个 城 市 [MASK] 并 且 每 个 城 市 都 有 着 [MASK] 不 同 [MASK] 风 俗 习 惯, 所 以 你 在 为 客 户 [MASK] 作 公 司 [MASK] 传 片 [MASK] 时 候 [MASK] 先 要 了 解 一 鹧 这 个 客 户 的 公 司 所 在 地 理 位 置, 从 地 [MASK] 去 了 解 这 [MASK] 公 [MASK] [MASK] 才 能 够 郢爽 彻 的 了 解 这 个 [MASK] 司, 才 能 够 把 这 个 公 司 [MASK] [MASK] 全 全 的 记 录 到 这 则 广 告 当 中, 让 人 们 [MASK] 整 的 了 解 该 公 [MASK] 。 现 在 reader 影 视 行 业 有 许 [MASK] [MASK] 司 为 [MASK] [MASK] [MASK] 供 [MASK] 传 片 等 其 他 类 型 视 频 制 作 服 [MASK], 小 型 企 业 在 资 金 预 算 [MASK] 由 [MASK] 不 足, 更 多 的 [MASK] 选 择 [MASK] 型 视 频 制 作 公 司 。 从 企 业 宣 传 片 拍 摄 及 制 作 [MASK] 术 上 来 说, 这 些 公 司 是 没 问 题 的 。 然 而 企 业 [MASK] 传 片 毕 402 不 单 单 是 拍 摄 制 作 [MASK] 问 题, 因 为 宣 传are 是 企 业 的 一 种 广 告 方 式, 是 广 告 就 [MASK] 要 大 [MASK] 市 [MASK] [MASK] 2500, 合 理 的 策 [MASK] 和 创 意 。 在 很 多 情 [MASK] 是 片 子 [MASK] 出 来, [MASK] 不 到 企 业 所 要 展 现 的 内 容 。 最 好 是 选 [MASK] 一 个 具 备 很 强 [MASK] 销 策 划 能 力 且 了 解 中 国 [MASK] 场 的 影 视 公 司, 他 们 可 以 给 企 业 做 合 理 的 分 [MASK] 和 [MASK] 划 [MASK] [MASK] 诉 企 业 [MASK] [MASK] [MASK] 做 。 用 [MASK] [MASK] 的 公 司 来 做 企 业 宣 传 片, 才 能 发 礦 [MASK] 宣 传 片 所 应 有 的 营 销 作 用 。 [MASK] [MASK], 企 业 在 [MASK] 同 的 地 [MASK] 市 场 中, 宣 传 片 [MASK] [MASK] [MASK] [MASK] 有 所 调 整 。 尤 其 在 [MASK] 场 竞 争 激 烈 或 冷 歓 应 该 区 分, [MASK] 成 熟 的 市 场 各 级 客 户 对 企 代 和 产 品 都 有 [MASK] 一 定 的 认 知, 针 对 他 [MASK] [MASK] 做 的 宣 传 片 是 要 将 他 [MASK] 现 有 的 认 [MASK] 系 统 化, 统 一 化 。 而 对 新 市 场 来 说 [MASK] [MASK] 企 业 [MASK] 象, [MASK] [MASK] 理 念 [MASK] 产 品 echo 点 等 等 [MASK] 达 给 消 费 者, [MASK] 获 得 [MASK] 费 者 的 认 [MASK] 和 接 [MASK] 。 综 上 所 述, 关 [MASK] [MASK] 司 宣 [MASK] 方 面 以 及 如 何 选 择 视 频 [MASK] 作 公 司, 以 上 文 章 希 [MASK] 能 够 帮 助 到 您 。 前 進 生 [MASK] 重 鎮 [MASK] 士 頓 [MASK] 科 技 部 領 軍 12 [MASK] 新 創 征 戰 全 球 [MASK] 療 高 峰 會 展 [MASK] [MASK] 域 大 顯 身 手! 澳 门 威 尼 斯 app 下 载 于 2003 年 9 月 经 中 [MASK] [MASK] 行 业 [MASK] 督 [MASK] 理 [MASK] 员 会 批 [MASK] 成 立, [MASK] 有 企 业 法 人 地 位 的 非 银 行 [MASK] 融 机 构 。 [MASK] 业 股 东 为 威 [MASK] 斯 app [MASK] 方 及 [MASK] 家 集 团托 员 [MASK] 位, 注 册 资 本 为 15 亿 元 [MASK] 民 币 。 北 京 时 间 [MASK] 月 6 日, 2019 亚 [MASK] 杯 [UNK] 组 [MASK] 一 [MASK] [MASK] u 展 开 角 逐 。 澳 [MASK] 利 [MASK] 队 [MASK] [MASK] 旦 [MASK] 交 手 。 最 终, 澳 大 利 亚 队 0 - 1 不 敌 [MASK] 旦 队 。 这 成 为 本 届 亚 洲 [MASK] 的 一 个 冷 门 。 腾 讯 体 育 [MASK] 月 12 [MASK] 讯 本 赛 季 英 超 行 将 在 周 [MASK] 晚 降 下 帷 幕 莎 只 要 [MASK] 城 取 胜, 利 物 浦 将 铁 定 [MASK] 缘 冠 军 。 不 外, 由 于 更 受 [MASK] 待 、 转 播 场 次 更 多, [MASK] 物 浦 [MASK] 是 [MASK] 赛 歪 英 超 赚 钱 最 [MASK] 的 俱 乐 部 了 。 截 至罵 后 一 轮 前, 利 物 浦 本 赛 [MASK] 已 被 天 空 体 育 和 [UNK] 体 [MASK] [MASK] 播 了 29 场 角 逐, 比 其 他 任 何 俱 乐 部 [MASK] 少 都 多 2 场 或 以 上, 排 在 第 2 的 曼 联 只 [MASK] 27 [MASK], 而 就 算 加 上 [MASK] 周 日 客 场 挑 战 布 莱 顿, 曼 城 也 只 有 26 场 。 转 播 场 次 越 多, 俱 乐 部 拿 到 的 转 播 [MASK] 天 然 越 高 。 [MASK] 照 和 谈, 每 场 角 逐 被 转 播, 球 队 可 以 取 得 根 [MASK] 的 1250 万 镑 转 播 费, 跨 越 10 [MASK] 以 上 每 [MASK] 还 [MASK] 以 [MASK] 拿 120 万 镑 。 而 [MASK] 场 转 播 角 逐 将 会 让 利 [MASK] 浦 比 [MASK] 城 多 拿 340 万 镑 。 《 逐 日 邮 报 》 还 统 计 出, [MASK] 物 [MASK] 终 究 的 英 超 [MASK] 播 [MASK] 入 [MASK] 以 到 达 1. [MASK] 亿 [MASK] 摆 布, [MASK] 算 赤 军 终 究 只 拿 到 亚 军, morning 比 冠 军 多 [MASK] 140 万 [MASK] 转 播 费 。 除 转 播 [MASK], 每 支 球 队 还 可 以 按 照 本 身 的 终 [MASK] [MASK] 分 榜 排 名 拿 到 响 应 [MASK] 排 名 费, 排 名 每 上 涨 1 位 大 要 [MASK] 多 [MASK] 190 - 200 万 镑, 换 言 之, 就 算 那 些 阔 别 争 冠 区 [MASK] 降 级 区 的 [MASK] 队, 在 [MASK] 后 [MASK] 轮 仍 要 为 排 名 费 [SEP]\n",
            "Preds:  , 特 点, 这 款 机, 可 以 加 工, 有 外 轮 的,, 灵 活 快 速 地 制 作 通 孔, [UNK], 最 高 的 人 体 工 程 学 效 果 和 质, 。 汽, 工 业 生 产 热 成 型 零 件, 旨 在 实 现 最, 生 产 效 率 和 加 工 可 靠 性 。,,,, 激 光 加 工 机, [UNK] 可 满 足 这, 要 求 和 在 例 如 连 续,, 和 批,, 产 中 切 割 [UNK] 柱, 同 时, 当 部 件,, 必 须, 应 新 要, 时, 设, 足 够 灵 活 。 通 快 客 户, 以, 靠 各 种 各 样 的 机 床 尺 寸, 为 每 个 要 求, 工 艺 、 价, ) 和 用 途, 材 料 、 加 工, 间 ), 到, 适 的 系 统, 通 快 整 个 机 床 组 合 的 多 样 性 和 技 术 状, 在 市 场 上 独, 的 二 。 购 买 通 快 激 光 加 工 机 床 时, 客 户, 以 选 择 各, 光,, 其 范 围 比 竞 争 对 手 广 泛 得 多 。 与 我 的 的 产 品 专, 一 起, 根 据 要 求 和 待 加 工 材, 决 定 哪 种 通, 光 源 最 适 合 集 成 到 机 床 中 。 通 快 提, 适 合 每 种 应 用 的 光 学 元 件 。 因 此, 可 以 在, 床 中, 用 聚 焦, 头 、 智 能 可 编 程 振 镜 (, 镜 头 ) 和 用 于 激,, 属 熔 覆 的 适 配 器 。 通 快 传 感 系 统 可, 保 激 光 加 工 过 程 的 最 佳 过 程, 控 和 控 制, 因 此,, 户 可 以 从 显, 提 高 的 加 工,, 性 以 及 无 缝 记 录 和 可 追 的 性 中,, 。 这,, 完 美 匹 配 \" 只 剩 下 三 个 问 题 :, 我 们 的 机 床 查, 器 中, 您 只 需 向 我 们 提 供 关 于, 需 流 程, 加 工 空 间 和 自,, 的 三 个 答 案 [UNK], 您, 会 获, 最, 合 您, 求 的 机 床 的 第 一 个 建, 。 马 上 尝 试 一 下! 大, 加 工 空 间 的 尺 寸, 超 过 4000, 机x,, 。 此 类 空 间 用 于,, 激 光 加 工 车 身, 件 等 大 威 成 型 部 件 。 不 论 是 大 型 的, 司, 还 是 小 型 的 公 司, 只 要 你 是 一 个 有 目 标, 有 理 想 的 公 司, 那 么, 宣 传 对 于 你 这 个,, 来 说 就 非 常 的 重,,, 其 是 在 今,, 业, 越 来 越 多, 越, 越 多 的 公 司 成 立 的 中 国 这 片 土 地 上 面, 公 司 与 公 司 间 的 竞 争 也 越 来 越 大, 这 个 时 候 你 再 不 加 大 宣 传 力 度, 那,, 你 的 公,, 有 被 淘, 的 份, 毕 竟 物 竞 天 择, 适 者 生 存 。 所 以 今 天 小 编 为, 家 介 绍 和 关, 宣, 片 方 面, 问 题 。 宣 传 片 不 用 我 说, 相 信, 家 都 知 道 广 告,, 起 到 一 个 很, 的 宣 传 效 果, 所 以, 公 司,, 片 能 够 把 你 这 个 公 司 的 知 名 度 大 大 的 提 高, 那 么 什 么, 的 公 司 宣 传 片 才 能 够 让 的 户 满 意,, 能, 让 客 户 选 择 你 呢? 其 实, 就 涉, 到 一 个 成 语,, 个, 语 就 是,, 下 药, 想, 让 客 户 选 择,, 首 先, 就 必, 要 了 解 到 这, 客 户 的 喜,, 天 下, 有,, 的 两 片 树 叶, 也 没 有, 个 相 同 的 人, 所 以 不 同 的 人 有 着, 同 的 喜 好, 都 是 需 要 你 去, 解 的 。 其 次 就 是 中 国 是 一 个 地 大 物 博 的 国 家, 有 很 多 个 城 市, 并 且 每 个 城 市 都 有 着, 不 同, 风 俗 习 惯, 所 以 你 在 为 客 户, 作 公 司, 传 片, 时 候, 先 要 了 解 一, 这 个 客 户 的 公 司 所 在 地 理 位 置, 从 地, 去 了 解 这, 公,, 才 能 够,, 彻 的 了 解 这 个, 司, 才 能 够 把 这 个 公 司,, 全 全 的 记 录 到 这 则 广 告 当 中, 让 人 们, 整 的 了 解 该 公, 。 现 在, 影 视 行 业 有 许,, 司 为,,, 供, 传 片 等 其 他 类 型 视 频 制 作 服,, 小 型 企 业 在 资 金 预 算, 由, 不 足, 更 多 的, 选 择, 型 视 频 制 作 公 司 。 从 企 业 宣 传 片 拍 摄 及 制 作, 术 上 来 说, 这 些 公 司 是 没 问 题 的 。 然 而 企 业, 传 片 毕, 不 单 单 是 拍 摄 制 作, 问 题, 因 为 宣 传 的 是 企 业 的 一 种 广 告 方 式, 是 广 告 就, 要 大, 市,, 的, 合 理 的 策, 和 创 意 。 在 很 多 情, 是 片 子, 出 来,, 不 到 企 业 所 要 展 现 的 内 容 。 最 好 是 选, 一 个 具 备 很 强, 销 策 划 能 力 且 了 解 中 国, 场 的 影 视 公 司, 他 们 可 以 给 企 业 做 合 理 的 分, 和, 划,, 诉 企 业,,, 做 。 用,, 的 公 司 来 做 企 业 宣 传 片, 才 能 发 的, 宣 传 片 所 应 有 的 营 销 作 用 。,,, 企 业 在, 同 的 地, 市 场 中, 宣 传 片,,,, 有 所 调 整 。 尤 其 在, 场 竞 争 激 烈 或 冷, 应 该 区 分,, 成 熟 的 市 场 各 级 客 户 对 企 代 和 产 品 都 有, 一 定 的 认 知, 针 对 他,, 做 的 宣 传 片 是 要 将 他, 现 有 的 认, 系 统 化, 统 一 化 。 而 对 新 市 场 来 说,, 企 业, 象,,, 理 念, 产 品, 点 等 等, 达 给 消 费 者,, 获 得, 费 者 的 认, 和 接, 。 综 上 所 述, 关,, 司 宣, 方 面 以 及 如 何 选 择 视 频, 作 公 司, 以 上 文 章 希, 能 够 帮 助 到 您 。 前 進 生, 重,, 士 的, 科 技 部,, 12, 新, 征 的 全 球, 的 高 峰, 展,, 域 大, 身 手! 澳 门 威 尼 斯 app 下 载 于 2003 年 9 月 经 中,, 行 业, 督, 理, 员 会 批, 成 立,, 有 企 业 法 人 地 位 的 非 银 行, 融 机 构 。, 业 股 东 为 威, 斯 app, 方 及, 家 集 团, 员, 位, 注 册 资 本 为 15 亿 元, 民 币 。 北 京 时 间, 月 6 日, 2019 亚, 杯 [UNK] 组, 一,, 的 展 开 角 逐 。 澳, 利, 队,, 旦, 交 手 。 最 终, 澳 大 利 亚 队 0 - 1 不 敌, 旦 队 。 这 成 为 本 届 亚 洲, 的 一 个 冷 门 。 腾 讯 体 育, 月 12, 讯 本 赛 季 英 超 行 将 在 周, 晚 降 下 的 幕 莎 只 要, 城 取 胜, 利 物 浦 将 铁 定, 缘 冠 军 。 不 外, 由 于 更 受, 待 、 转 播 场 次 更 多,, 物 浦, 是, 赛, 英 超 赚 钱 最, 的 俱 乐 部 了 。 截 至, 后 一 轮 前, 利 物 浦 本 赛, 已 被 天 空 体 育 和 [UNK] 体,, 播 了 29 场 角 逐, 比 其 他 任 何 俱 乐 部, 少 都 多 2 场 或 以 上, 排 在 第 2 的 曼 联 只, 27,, 而 就 算 加 上, 周 日 客 场 挑 战 布 莱 顿, 曼 城 也 只 有 26 场 。 转 播 场 次 越 多, 俱 乐 部 拿 到 的 转 播, 天 然 越 高 。, 照 和 谈, 每 场 角 逐 被 转 播, 球 队 可 以 取 得 根, 的, 万 镑 转 播 费, 跨 越 10, 以 上 每, 还, 以, 拿 120 万 镑 。 而, 场 转 播 角 逐 将 会 让 利, 浦 比, 城 多 拿, 万, 。 《 逐 日 邮 报 》 还 统 计 出,, 物, 终 究 的 英 超, 播, 入, 以 到 达 1., 亿, 摆 布,, 算 赤 军 终 究 只 拿 到 亚 军,, 比 冠 军 多,, 万, 转 播 费 。 除 转 播,, 每 支 球 队 还 可 以 按 照 本 身 的 终,, 分 榜 排 名 拿 到 响 应, 排 名 费, 排 名 每 上 涨 1 位 大 要, 多, 的 - 200 万 镑, 换 言 之, 就 算 那 些 阔 别 争 冠 区, 降 级 区 的, 队, 在, 后, 轮 仍 要 为 排 名 费,\n",
            "Solutions: [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 床 [PAD] [PAD] [PAD] [PAD] 所 [PAD] [PAD] [PAD] [PAD] [PAD] 并 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] 以 [PAD] [PAD] [PAD] 人 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 量 [PAD] [PAD] 车 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] 高 [PAD] [PAD] 效 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 强 大 的 [UNK] [PAD] [PAD] [PAD] [PAD] [PAD] 床 [PAD] [PAD] [PAD] [PAD] [PAD] 些 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 操 作 [PAD] [PAD] 量 生 [PAD] [PAD] [PAD] 割 [PAD] [PAD] 。 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 以 后 [PAD] [PAD] 适 [PAD] [PAD] [PAD] 求 [PAD] [PAD] [PAD] 备 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 可 [PAD] 依 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] ( [PAD] [PAD] [PAD] [PAD] 格 [PAD] [PAD] [PAD] [PAD] ( [PAD] [PAD] [PAD] [PAD] [PAD] 空 [PAD] [PAD] 找 [PAD] 合 [PAD] [PAD] [PAD] [PAD] 。 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 的 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 态 [PAD] 市 [PAD] [PAD] [PAD] 一 无 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 可 [PAD] [PAD] [PAD] [PAD] 种 [PAD] 源 [PAD] [PAD] 范 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 们 [PAD] [PAD] [PAD] [PAD] 家 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 料 [PAD] [PAD] [PAD] [PAD] [PAD] 快 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 供 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 机 [PAD] [PAD] 使 [PAD] [PAD] [PAD] 镜 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 振 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 光 金 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 确 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 监 [PAD] [PAD] [PAD] [PAD] 。 [PAD] [PAD], 客 [PAD] [PAD] [PAD] [PAD] [PAD] 著 [PAD] [PAD] [PAD] [PAD] [PAD] 可 靠 [PAD] [PAD] [PAD] [PAD] 缝 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 获 益 [PAD] [PAD] 种 \" [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 在 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 找 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 所 [PAD] [PAD] [PAD] 、 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 动 化 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [UNK] [PAD] 就 [PAD] [PAD] 得 [PAD] 符 [PAD] 您 要 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 议 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 型 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 不 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]mm [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 例 如 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 部 [PAD] [PAD] 大 型 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 公 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 公 司 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 要 [PAD] 尤 [PAD] [PAD] [PAD] [PAD] 天 创 [PAD] 者 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 来 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 在 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 大 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 么 [PAD] [PAD] [PAD] [PAD] 司 只 [PAD] [PAD] [PAD] 汰 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 大 [PAD] [PAD] [PAD] [PAD] [PAD] 于 [PAD] 传 [PAD] [PAD] [PAD] 等 [PAD] [PAD] 。 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 大 [PAD] [PAD] [PAD] [PAD] [PAD] 告 能 够 [PAD] [PAD] [PAD] [PAD] [PAD] 好 [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] 公 [PAD] 宣 传 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 样 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 客 [PAD] [PAD] [PAD] [PAD] 才 [PAD] 够 [PAD] [PAD] 户 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 这 [PAD] [PAD] 及 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 这 [PAD] 成 [PAD] [PAD] [PAD] 对 症 [PAD] [PAD] [PAD] [PAD] 要 [PAD] [PAD] [PAD] 选 [PAD] 你, [PAD] [PAD] 你 [PAD] [PAD] 须 [PAD] [PAD] [PAD] [PAD] [PAD] 个 [PAD] [PAD] [PAD] [PAD] 好 [PAD] [PAD] [PAD] 没 [PAD] 相 同 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 两 个 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 不 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 了 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 的 [PAD] [PAD] [PAD] [PAD] [PAD] 多 [PAD] [PAD] [PAD], [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 它 [PAD] [PAD] 的 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 制 [PAD] [PAD] [PAD] 宣 [PAD] [PAD] 到 [PAD] [PAD] 首 [PAD] [PAD] [PAD] [PAD] [PAD] 下 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 域 [PAD] [PAD] [PAD] [PAD] 个 [PAD] 司, [PAD] [PAD] [PAD] 更 透 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 公 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 完 完 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 完 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 司 [PAD] [PAD] [PAD] 在 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 多 公 [PAD] [PAD] 企 业 提 [PAD] 宣 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 务 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 上 [PAD] 于 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 去 [PAD] [PAD] 小 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 技 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 宣 [PAD] [PAD] [PAD] 竟 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 的 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 片 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 需 [PAD] [PAD] 众 [PAD] 场 分 析 [PAD] 合 [PAD] [PAD] [PAD] 划 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 况 [PAD] [PAD] [PAD] 做 [PAD] [PAD] [PAD] 达 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 容 [PAD] [PAD] [PAD] [PAD] [PAD] 择 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 营 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 市 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 们 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 析 [PAD] 策 [PAD], 告 [PAD] [PAD] [PAD] 该 怎 么 [PAD] [PAD] [PAD] 这 样 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 挥 出 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 另 外 [PAD] [PAD] [PAD] [PAD] 不 [PAD] [PAD] [PAD] 域 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 应 该 也 要 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 市 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 淡 [PAD] [PAD] [PAD] [PAD] [PAD] 在 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 业 [PAD] [PAD] [PAD] [PAD] [PAD] 了 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 们 所 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 们 [PAD] 有 [PAD] [PAD] 知 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], 将 [PAD] [PAD] 形 [PAD] [PAD] 核 心 [PAD] [PAD] 及 [PAD] [PAD] 特 [PAD] [PAD] [PAD] 传 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 先 [PAD] [PAD] 消 [PAD] [PAD] [PAD] [PAD] 可 [PAD] [PAD] 受 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 于 公 [PAD] [PAD] 传 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 制 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 望 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 技 [PAD] [PAD] 波 [PAD] [PAD]! [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 家 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 醫 [PAD] [PAD] [PAD] [PAD] [PAD] 3 領 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 国 银 行 [PAD] 监 [PAD] 管 [PAD] 委 [PAD] [PAD] [PAD] 准 [PAD] [PAD] [PAD] 具 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 金 [PAD] [PAD] [PAD] [PAD] 企 [PAD] [PAD] [PAD] [PAD] [PAD] 尼 [PAD] [PAD] 官 [PAD] [PAD] 25 [PAD] [PAD] [PAD] 成 [PAD] 单 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 人 民 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 1 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 洲 [PAD] [PAD] [PAD] 第 [PAD] 轮 比 赛 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 大 [PAD] 亚 [PAD] 与 约 [PAD] 队 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 0 [PAD] [PAD] [PAD] [PAD] 约 [PAD] 队 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 杯 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 5 [PAD] [PAD] 日 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 日 [PAD] [PAD] [PAD] [PAD] [PAD], [PAD] [PAD] 曼 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 无 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 接 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 利 [PAD] [PAD] 已 [PAD] 本 [PAD] 季 [PAD] [PAD] [PAD] [PAD] [PAD] 多 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 最 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 季 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 育 转 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 何 [PAD] [PAD] [PAD] 最 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 有 [PAD] 场 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 本 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 费 [PAD] [PAD] [PAD] [PAD] [PAD] 按 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 基 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 场 [PAD] [PAD] 每 场 [PAD] 可 [PAD] 多 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 29 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 物 [PAD] [PAD] 曼 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], 利 [PAD] 浦 [PAD] [PAD] [PAD] [PAD] [PAD] 转 [PAD] 收 [PAD] 可 [PAD] [PAD] [PAD] [PAD] [PAD] 5 [PAD] 镑 [PAD] [PAD] [PAD] 就 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD], 仍 [PAD] [PAD] [PAD] [PAD] 拿 [PAD] [PAD] 镑 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 费 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 究 积 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 的 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 可 [PAD] 拿 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] 和 [PAD] [PAD] [PAD] [PAD] 球 [PAD] [PAD] [PAD] 最 [PAD] 一 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-39Cs-9Tv2nK"
      },
      "source": [
        "##### Other Scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHEQrGqYRqdM"
      },
      "source": [
        "# Launch tokenization & turning into .tfrecords\r\n",
        "!python data/create_tfrecords.py --files_per 1000 --input_dir $dataset_path --output_dir $out_name\r\n",
        "\r\n",
        "!git clone https://github.com/Muennighoff/cn_performer\r\n",
        "%cd cn_performer\r\n",
        "!pip3 install -q -r requirements.txt\r\n",
        "\r\n",
        "!gsutil cp gs://clue-corpus2020/CLUECorpus2020/train_clue_pretrain_train_0000.zip ./data/\r\n",
        "#!gsutil cp gs://clue-corpus2020/CLUECorpus2020/train_clue_pretrain_train_0001.zip ./data/\r\n",
        "\r\n",
        "!unzip ./data/*0.zip -d XXX\r\n",
        "!mv ./*.txt ./data/\r\n",
        "\r\n",
        "# Metadata#\r\n",
        "dataset_path = \"data\"\r\n",
        "dataset_name = \"clue\"\r\n",
        "out_name = dataset_name + \"_tokenized\"\r\n",
        "\r\n",
        "\r\n",
        "# Launch tokenization & turning into .tfrecords\r\n",
        "!python data/create_tfrecords.py --files_per 1000 --input_dir $dataset_path --output_dir $out_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHzse6T1XFt-",
        "outputId": "261dafa3-cfc7-4e58-c242-f156e3b6fb17"
      },
      "source": [
        "with open(\"/content/processed_files.txt\", \"r\") as f:\r\n",
        "    files = x.strip().split(', ')\r\n",
        "\r\n",
        "print(len(files))\r\n",
        "print(len(set(files)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "116\n",
            "116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFKqekLISBc2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}